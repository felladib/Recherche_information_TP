{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ryan\\AppData\\Local\\Temp\\ipykernel_4672\\1542263649.py\", line 3, in <module>\n",
      "    from nltk.tokenize import RegexpTokenizer\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\__init__.py\", line 133, in <module>\n",
      "    from nltk.collocations import *\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\collocations.py\", line 36, in <module>\n",
      "    from nltk.metrics import (\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\metrics\\__init__.py\", line 18, in <module>\n",
      "    from nltk.metrics.association import (\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\metrics\\association.py\", line 26, in <module>\n",
      "    from scipy.stats import fisher_exact\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\stats\\__init__.py\", line 606, in <module>\n",
      "    from ._stats_py import *\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\stats\\_stats_py.py\", line 37, in <module>\n",
      "    from scipy import sparse\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\__init__.py\", line 134, in __getattr__\n",
      "    return _importlib.import_module(f'scipy.{name}')\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 295, in <module>\n",
      "    from ._csr import *\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ryan\\AppData\\Local\\Temp\\ipykernel_4672\\1542263649.py\", line 3, in <module>\n",
      "    from nltk.tokenize import RegexpTokenizer\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\__init__.py\", line 133, in <module>\n",
      "    from nltk.collocations import *\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\collocations.py\", line 36, in <module>\n",
      "    from nltk.metrics import (\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\metrics\\__init__.py\", line 38, in <module>\n",
      "    from nltk.metrics.scores import (\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\metrics\\scores.py\", line 15, in <module>\n",
      "    from scipy.stats.stats import betai\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\stats\\__init__.py\", line 606, in <module>\n",
      "    from ._stats_py import *\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\stats\\_stats_py.py\", line 37, in <module>\n",
      "    from scipy import sparse\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\__init__.py\", line 134, in __getattr__\n",
      "    return _importlib.import_module(f'scipy.{name}')\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 295, in <module>\n",
      "    from ._csr import *\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ryan\\AppData\\Local\\Temp\\ipykernel_4672\\1542263649.py\", line 3, in <module>\n",
      "    from nltk.tokenize import RegexpTokenizer\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\chunk\\__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\chunk\\api.py\", line 15, in <module>\n",
      "    from nltk.parse import ParserI\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\parse\\__init__.py\", line 100, in <module>\n",
      "    from nltk.parse.transitionparser import TransitionParser\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\nltk\\parse\\transitionparser.py\", line 17, in <module>\n",
      "    from scipy import sparse\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\__init__.py\", line 134, in __getattr__\n",
      "    return _importlib.import_module(f'scipy.{name}')\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 295, in <module>\n",
      "    from ._csr import *\n",
      "  File \"c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# from collections import Counter\n",
    "\n",
    "# # Fonction pour lire les termes dans le fichier descripteur\n",
    "# def lire_termes(fichier_descripteur):\n",
    "#     termes = []\n",
    "#     with open(fichier_descripteur, 'r', encoding='utf-8') as f:\n",
    "#         for ligne in f:\n",
    "#             _, terme = ligne.strip().split(' ', 1)\n",
    "#             termes.append(terme)\n",
    "#     return termes\n",
    "\n",
    "# # Fonction pour calculer les fréquences et le poids des termes\n",
    "# def calculer_frequence_et_poids(documents):\n",
    "#     termes_tous_docs = []  # Tous les termes de tous les documents\n",
    "#     occurrences_termes_par_doc = {}  # Occurrences par document\n",
    "\n",
    "#     # Étape 1 : Collecter les occurrences dans chaque document\n",
    "#     for doc in documents:\n",
    "#         fichier_descripteur = os.path.join(descripteur_path, f\"{doc}_descripteur.txt\")\n",
    "#         termes = lire_termes(fichier_descripteur)\n",
    "        \n",
    "#         termes_tous_docs.extend(termes)\n",
    "#         occurrences_termes_par_doc[doc] = Counter(termes)\n",
    "\n",
    "#     # Total de documents\n",
    "#     total_docs = len(documents)\n",
    "\n",
    "#     # Calculer la fréquence totale dans tous les documents\n",
    "#     occurrences_totales = Counter(termes_tous_docs)\n",
    "\n",
    "#     # Initialiser les dictionnaires pour stocker les fréquences et les poids\n",
    "#     index_inverse = {\n",
    "#         'Porter': {}\n",
    "#     }\n",
    "\n",
    "#     # Étape 2 : Calculer les fréquences et le poids pour chaque terme\n",
    "#     for doc, termes_counts in occurrences_termes_par_doc.items():\n",
    "#         for terme, count in termes_counts.items():\n",
    "#             # Fréquence dans le document (count / total termes du document)\n",
    "#             freq_doc = count / sum(termes_counts.values())\n",
    "\n",
    "#             # Fréquence du terme dans la collection\n",
    "#             freq_collection = occurrences_totales[terme] / sum(occurrences_totales.values())\n",
    "\n",
    "#             # Calcul du poids (exemple avec TF-IDF)\n",
    "#             poids = freq_doc * (1 / freq_collection) if freq_collection != 0 else 0\n",
    "\n",
    "#             # Enregistrer les valeurs dans le dictionnaire\n",
    "#             if terme not in index_inverse['Porter']:\n",
    "#                 index_inverse['Porter'][terme] = [0, 0, 0]\n",
    "            \n",
    "#             index_inverse['Porter'][terme] = [freq_doc, freq_collection, poids]\n",
    "\n",
    "#     return index_inverse\n",
    "\n",
    "# # chemin vers les fichiers descripteurs\n",
    "# descripteur_path = '../Descripteurs/lancaster'\n",
    "# documents = [doc.replace('_descripteur.txt', '') for doc in os.listdir(descripteur_path) if doc.endswith('_descripteur.txt')]\n",
    "\n",
    "# # Calcul des fréquences et poids\n",
    "# index_inverse = calculer_frequence_et_poids(documents)\n",
    "\n",
    "# # Sauvegarder dans un fichier JSON\n",
    "# output_path = '../Inverse/index_inverse_termes.json'\n",
    "# with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(index_inverse, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# print(f\"Les résultats ont été sauvegardés dans {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Fonction pour lire les termes dans le fichier descripteur\n",
    "def lire_termes(fichier_descripteur):\n",
    "    termes = []\n",
    "    with open(fichier_descripteur, 'r', encoding='utf-8') as f:\n",
    "        for ligne in f:\n",
    "            _, terme = ligne.strip().split(' ', 1)\n",
    "            termes.append(terme)\n",
    "    return termes # return tout les terme par document\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour calculer les fréquences et le poids des termes\n",
    "def calculer_frequence_et_poids(documents):\n",
    "    termes_tous_docs = []  # Tous les termes de tous les documents\n",
    "    occurrences_termes_par_doc = {}  # Occurrences par document\n",
    "\n",
    "    # Étape 1 : Collecter les occurrences dans chaque document\n",
    "    for doc in documents:\n",
    "        \n",
    "        fichier_descripteur = os.path.join(descripteur_path, f\"{doc}_descripteur.txt\")\n",
    "        # return tous les termes \n",
    "        termes = lire_termes(fichier_descripteur)\n",
    "        \n",
    "        # stocker tous les termes\n",
    "        termes_tous_docs.extend(termes)\n",
    "        occurrences_termes_par_doc[doc] = Counter(termes)\n",
    "        \n",
    "        i=0\n",
    "        for key , val in occurrences_termes_par_doc:\n",
    "            print(f'key :{key} , value:{val}')\n",
    "            i=+1\n",
    "            \n",
    "\n",
    "    # Total de documents\n",
    "    total_docs = len(documents)\n",
    "\n",
    "    # Calculer le nombre de documents contenant chaque terme\n",
    "    docs_contenant_terme = Counter(term for termes_counts in occurrences_termes_par_doc.values() for term in termes_counts)\n",
    "\n",
    "    # Initialiser les dictionnaires pour stocker les fréquences et les poids\n",
    "    index_inverse = {\n",
    "        'Porter': {},\n",
    "        'Lancaster': {}\n",
    "    }\n",
    "\n",
    "    # Étape 2 : Calculer les fréquences et le poids pour chaque terme\n",
    "    for doc, termes_counts in occurrences_termes_par_doc.items():\n",
    "        max_freq = max(termes_counts.values())  # fréquence maximale dans le document\n",
    "        \n",
    "        for terme, count in termes_counts.items():\n",
    "            # Fréquence normalisée dans le document\n",
    "            freq_doc = count / max_freq\n",
    "\n",
    "            # Fréquence du terme dans tous les documents (TF-IDF)\n",
    "            idf = math.log10((total_docs / (docs_contenant_terme[terme] + 1)) + 1)\n",
    "\n",
    "            # Calcul du poids\n",
    "            poids = freq_doc * idf\n",
    "\n",
    "            # Enregistrer les valeurs dans le dictionnaire\n",
    "            if terme not in index_inverse['Porter']:\n",
    "                index_inverse['Porter'][terme] = [0, 0, 0]\n",
    "            \n",
    "            index_inverse['Porter'][terme] = [freq_doc, docs_contenant_terme[terme] / total_docs, poids]\n",
    "\n",
    "    return index_inverse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Chemin vers les fichiers descripteurs\n",
    "descripteur_path = '../Descripteurs/lancaster'\n",
    "\n",
    "documents = [doc.replace('_descripteur.txt', '') for doc in os.listdir(descripteur_path) if doc.endswith('_descripteur.txt')]\n",
    "\n",
    "# Calcul des fréquences et poids\n",
    "index_inverse = calculer_frequence_et_poids(documents)\n",
    "\n",
    "# Sauvegarder dans un fichier JSON\n",
    "output_path = '../Inverse/index_inverse_termes.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(index_inverse, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Les résultats ont été sauvegardés dans {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
