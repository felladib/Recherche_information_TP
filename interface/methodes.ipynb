{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk import FreqDist\n",
    "\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "PORTER_STEMMER = nltk.PorterStemmer()\n",
    "LANCASTER_STEMMER = nltk.LancasterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processing_args():\n",
    "    tokenization = \"Split\"\n",
    "    normalization = \"None\",\n",
    "    file_type = \"TPD\"\n",
    "    return tokenization, normalization, file_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(doc_path, tokenization, normalization):\n",
    "    with open(doc_path, 'r') as file:\n",
    "        text = file.read()\n",
    "        \n",
    "    # Tokenization\n",
    "    if tokenization == \"Split\":\n",
    "        tokens = text.split()\n",
    "    else:\n",
    "        exp_reg = nltk.RegexpTokenizer(r'\\d+(?:\\.\\d+)?x\\d+|\\d+(?:\\.\\d+)|\\w+(?:-\\w+)*|(?:[A-Z]\\.)+|\\w+')\n",
    "        tokens = exp_reg.tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [term for term in tokens if term.lower() not in STOPWORDS]\n",
    "\n",
    "    # Normalization\n",
    "    if normalization == \"Porter\":\n",
    "        tokens = [PORTER_STEMMER.stem(term) for term in tokens]\n",
    "    elif normalization == \"Lancaster\":\n",
    "        tokens = [LANCASTER_STEMMER.stem(term) for term in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_global_term_frequencies(tokenization, normalization):\n",
    "    global_term_frequencies = defaultdict(int)\n",
    "\n",
    "    for doc_name in os.listdir('Collections'):\n",
    "        doc_path = os.path.join('Collections', doc_name)\n",
    "        tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "        unique_terms = set(tokens)\n",
    "\n",
    "        for term in unique_terms:\n",
    "            global_term_frequencies[term] += 1\n",
    "            \n",
    "    return global_term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Display_TPD_result(query, terms_freq, global_term_frequencies, N):\n",
    "    max_freq = max(terms_freq.values())\n",
    "\n",
    "    for idx, (term, freq) in enumerate(terms_freq.items(), start=1):\n",
    "        poids = (freq / max_freq) * math.log10((N / global_term_frequencies[term]) + 1)\n",
    "        print(idx, query, term, freq, format(poids, '.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(query):\n",
    "    tokenization, normalization, file_type = get_processing_args()\n",
    "   \n",
    "    global_term_frequencies = build_global_term_frequencies(tokenization, normalization)  # Calculate global term frequencies\n",
    "    N = len(os.listdir('Collections'))\n",
    "    \n",
    "    if file_type == \"TPD\":\n",
    "        doc_path = os.path.join('Collections', f\"{query}.txt\")\n",
    "        tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "        terms_freq = FreqDist(tokens)\n",
    "\n",
    "        Display_TPD_result(query, terms_freq, global_term_frequencies, N)\n",
    "        \n",
    "    else :\n",
    "        i=0\n",
    "        for doc_name in os.listdir('Collections'):\n",
    "            doc_path = os.path.join('Collections', doc_name)\n",
    "            Tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "            terms_freq = FreqDist(Tokens)\n",
    "\n",
    "            max_freq = max(terms_freq.values())\n",
    "            for term, freq in terms_freq.items():  \n",
    "                if term == query:  # Check if the term is the specific query term\n",
    "                    poids = ((freq / max_freq) * math.log10((N / global_term_frequencies[term]) + 1))\n",
    "                    i+=1\n",
    "                    print(f\"{i} Term: {term}, Document: {os.path.splitext(doc_name)[0]}, Frequency: {freq}, Weight: {format(poids, '.4f')}\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_args(query, raw, processed):\n",
    "    if raw:\n",
    "        doc_path = os.path.join('Collections', f\"{query}.txt\")\n",
    "        with open(doc_path, 'r') as file:\n",
    "            text = file.read()\n",
    "        print(text)\n",
    "    elif processed:\n",
    "        text_processing(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D5 secondary 2 0.1408\n",
      "2 D5 flow 5 0.1427\n",
      "3 D5 fields 1 0.0704\n",
      "4 D5 embedded 3 0.2113\n",
      "5 D5 hypersonic 3 0.1505\n",
      "6 D5 shock 5 0.2509\n",
      "7 D5 layers 1 0.0704\n",
      "8 D5 . 12 0.3010\n",
      "9 D5 ramp 2 0.1408\n",
      "10 D5 compression 2 0.1408\n",
      "11 D5 surface 3 0.1505\n",
      "12 D5 located 1 0.0704\n",
      "13 D5 locally 1 0.0704\n",
      "14 D5 supersonic 1 0.0704\n",
      "15 D5 region 1 0.0502\n",
      "16 D5 behind 1 0.0704\n",
      "17 D5 bow 2 0.1408\n",
      "18 D5 wave, 2 0.1408\n",
      "19 D5 generates 1 0.0704\n",
      "20 D5 wave 2 0.1003\n",
      "21 D5 disturbance 1 0.0704\n",
      "22 D5 may 1 0.0704\n",
      "23 D5 viewed 1 0.0704\n",
      "24 D5 newtonian 7 0.4930\n",
      "25 D5 impact 1 0.0704\n",
      "26 D5 layer 2 0.0663\n",
      "27 D5 thin 1 0.0704\n",
      "28 D5 examination 1 0.0704\n",
      "29 D5 applicability 1 0.0704\n",
      "30 D5 theory 4 0.2007\n",
      "31 D5 cones 1 0.0704\n",
      "32 D5 wedges 1 0.0704\n",
      "33 D5 uniform 1 0.0502\n",
      "34 D5 streams 1 0.0704\n",
      "35 D5 suggests 1 0.0704\n",
      "36 D5 expected 1 0.0704\n",
      "37 D5 give 1 0.0502\n",
      "38 D5 useful 1 0.0704\n",
      "39 D5 approximation 1 0.0704\n",
      "40 D5 pressures 4 0.2817\n",
      "41 D5 pressure 6 0.3010\n",
      "42 D5 equation 1 0.0502\n",
      "43 D5 based 1 0.0704\n",
      "44 D5 concept 1 0.0704\n",
      "45 D5 predicts 1 0.0704\n",
      "46 D5 number 1 0.0502\n",
      "47 D5 interesting 1 0.0704\n",
      "48 D5 things 1 0.0704\n",
      "49 D5 .. 1 0.0704\n",
      "50 D5 first, 1 0.0704\n",
      "51 D5 differ 2 0.1408\n",
      "52 D5 simple 2 0.1003\n",
      "53 D5 factors 1 0.0704\n",
      "54 D5 1.5 1 0.0704\n",
      "55 D5 3,. 1 0.0704\n",
      "56 D5 example, 1 0.0704\n",
      "57 D5 flare 4 0.2817\n",
      "58 D5 stabilizers 1 0.0704\n",
      "59 D5 blunt-nosed 2 0.1408\n",
      "60 D5 bodies 1 0.0502\n",
      "61 D5 revolution, 1 0.0704\n",
      "62 D5 lower 1 0.0704\n",
      "63 D5 diminish 1 0.0704\n",
      "64 D5 increasing 1 0.0704\n",
      "65 D5 flight 1 0.0704\n",
      "66 D5 speed 2 0.1003\n",
      "67 D5 range 1 0.0704\n",
      "68 D5 calculated 1 0.0398\n",
      "69 D5 vary 2 0.1408\n",
      "70 D5 result 1 0.0704\n",
      "71 D5 nonuniformity 1 0.0704\n",
      "72 D5 incident 1 0.0704\n",
      "73 D5 stream, 1 0.0704\n",
      "74 D5 depend 1 0.0704\n",
      "75 D5 axial 1 0.0502\n",
      "76 D5 location 1 0.0704\n",
      "77 D5 case 2 0.1408\n",
      "78 D5 flap 2 0.1408\n",
      "79 D5 mounted 1 0.0704\n",
      "80 D5 large-angled 1 0.0704\n",
      "81 D5 cone, 1 0.0704\n",
      "82 D5 coefficients 1 0.0704\n",
      "83 D5 1 1 0.0704\n",
      "84 D5 5 2 0.1408\n",
      "85 D5 variable 1 0.0704\n",
      "86 D5 entropy 1 0.0704\n",
      "87 D5 coefficient 2 0.1408\n",
      "88 D5 greater 1 0.0704\n",
      "89 D5 maximum 1 0.0704\n",
      "90 D5 possible 1 0.0502\n",
      "91 D5 occur 1 0.0704\n",
      "92 D5 process 2 0.1408\n",
      "93 D5 efficient 1 0.0704\n",
      "94 D5 single 1 0.0704\n",
      "95 D5 areas 1 0.0704\n",
      "96 D5 protrude 1 0.0704\n",
      "97 D5 main 1 0.0704\n",
      "98 D5 revert 1 0.0704\n",
      "99 D5 value 1 0.0704\n",
      "100 D5 equations 1 0.0502\n",
      "101 D5 developed 1 0.0502\n",
      "102 D5 initial 1 0.0704\n",
      "103 D5 slopes 1 0.0704\n",
      "104 D5 normal-force 1 0.0704\n",
      "105 D5 pitching-moment 1 0.0704\n",
      "106 D5 curves 1 0.0704\n",
      "107 D5 stabilizer 1 0.0704\n",
      "108 D5 simplest 1 0.0704\n",
      "109 D5 conventional 1 0.0704\n",
      "110 D5 ratio 2 0.1408\n",
      "111 D5 local 1 0.0704\n",
      "112 D5 dynamic 2 0.1408\n",
      "113 D5 free-stream 1 0.0704\n",
      "114 D5 takes 1 0.0704\n",
      "115 D5 values 1 0.0704\n",
      "116 D5 low 1 0.0502\n",
      "117 D5 0.1 1 0.0704\n",
      "118 D5 examples 1 0.0704\n",
      "119 D5 considered 1 0.0398\n"
     ]
    }
   ],
   "source": [
    "get_text_args(\"D5\", False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
