{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import BIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import (\n",
    "    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,\n",
    "    QLineEdit, QPushButton, QRadioButton, QLabel, QGroupBox,\n",
    "    QTableWidget, QTableWidgetItem, QScrollArea, QTextEdit, QStackedWidget, QGridLayout,\n",
    "    QMessageBox,QHeaderView\n",
    ")\n",
    "from PyQt5.QtGui import QIcon\n",
    "from PyQt5.QtCore import Qt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "PORTER_STEMMER = nltk.PorterStemmer()\n",
    "LANCASTER_STEMMER = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processing_args():\n",
    "    tokenization = \"Split\"\n",
    "    normalization = \"None\",\n",
    "    file_type = \"TPD\"\n",
    "    return tokenization, normalization, file_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(doc_path, tokenization, normalization):\n",
    "    with open(doc_path, 'r') as file:\n",
    "        text = file.read()\n",
    "        \n",
    "    # Tokenization\n",
    "    if tokenization == \"Split\":\n",
    "        tokens = text.split()\n",
    "    else:\n",
    "        exp_reg = nltk.RegexpTokenizer(r'\\d+(?:\\.\\d+)?x\\d+|\\d+(?:\\.\\d+)|\\w+(?:-\\w+)*|(?:[A-Z]\\.)+|\\w+')\n",
    "        tokens = exp_reg.tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [term for term in tokens if term.lower() not in STOPWORDS]\n",
    "\n",
    "    # Normalization\n",
    "    if normalization == \"Porter\":\n",
    "        tokens = [PORTER_STEMMER.stem(term) for term in tokens]\n",
    "    elif normalization == \"Lancaster\":\n",
    "        tokens = [LANCASTER_STEMMER.stem(term) for term in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_global_term_frequencies(tokenization, normalization):\n",
    "    global_term_frequencies = defaultdict(int)\n",
    "\n",
    "    for doc_name in os.listdir('Collections'):\n",
    "        doc_path = os.path.join('Collections', doc_name)\n",
    "        tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "        unique_terms = set(tokens)\n",
    "\n",
    "        for term in unique_terms:\n",
    "            global_term_frequencies[term] += 1\n",
    "            \n",
    "    return global_term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TPD_result(query, terms_freq, global_term_frequencies, N):\n",
    "    max_freq = max(terms_freq.values())\n",
    "    results=[]\n",
    "    for idx, (term, freq) in enumerate(terms_freq.items(), start=1):\n",
    "        poids = (freq / max_freq) * math.log10((N / global_term_frequencies[term]) + 1)\n",
    "        results.append((idx, term, query, freq, round(poids, 4)))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_termes_glob(tokenization, normalization):\n",
    "    nb_termes_global = []\n",
    "    for doc_name in os.listdir('Collections'):\n",
    "        doc_path = os.path.join('Collections', doc_name)\n",
    "        # Appliquer le prétraitement pour obtenir les tokens du document\n",
    "        tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "        \n",
    "        # Ajouter les tokens du document à la liste globale\n",
    "        nb_termes_global.extend(tokens)\n",
    "\n",
    "    # Obtenir le nombre de termes uniques\n",
    "    termes_uniques = np.unique(nb_termes_global)\n",
    "    print(\"Termes uniques : \", termes_uniques)  # Optionnel : pour visualiser les termes uniques\n",
    "    \n",
    "    return len(termes_uniques)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termes uniques :  ['0.1' '1' '1.5' '1.6x10' '10' '101' '3' '3.2x10' '300' '5' '704'\n",
      " 'accuracy' 'accurate' 'actual' 'aerodynamic' 'aerodynamic-centre'\n",
      " 'aerodynamics' 'agree' 'algebraic' 'almost' 'also' 'angles' 'another'\n",
      " 'applicability' 'applied' 'approximate' 'approximation' 'arbitrary'\n",
      " 'area' 'areas' 'arises' 'attack' 'axial' 'axially' 'based' 'basis'\n",
      " 'behind' 'blunt-nosed' 'bodies' 'body' 'boundaries' 'boundary'\n",
      " 'boundary-layer' 'boundary-layer-control' 'boundary-value' 'bow'\n",
      " 'calculated' 'calculation' 'capable' 'case' 'cent' 'center'\n",
      " 'characteristics' 'check' 'circulatory' 'classical' 'coefficient'\n",
      " 'coefficients' 'comparative' 'comparison' 'compression' 'computations'\n",
      " 'computed' 'concept' 'concluded' 'cone' 'cones' 'configuration'\n",
      " 'consequently' 'consider' 'considered' 'constant' 'conventional'\n",
      " 'coordinate' 'curved' 'curves' 'dealing' 'define' 'defined' 'depend'\n",
      " 'depending' 'destalling' 'determine' 'developed' 'differ' 'different'\n",
      " 'dimensional' 'diminish' 'discussed' 'discussion' 'distribution'\n",
      " 'disturbance' 'drag' 'due' 'dynamic' 'ease' 'edge' 'edpm' 'effect'\n",
      " 'effects' 'efficient' 'either' 'embedded' 'emitting' 'empirical' 'enough'\n",
      " 'entire' 'entropy' 'equation' 'equations' 'evaluation' 'evidence' 'exact'\n",
      " 'examination' 'example' 'examples' 'exists' 'expected' 'experiment'\n",
      " 'experimental' 'factors' 'feature' 'ferri' 'field' 'fields' 'first'\n",
      " 'flap' 'flare' 'flat' 'flight' 'flow' 'flows' 'fluid' 'found' 'fredholm'\n",
      " 'free' 'free-stream' 'friction' 'general' 'generates' 'give' 'given'\n",
      " 'greater' 'growth' 'high-speed' 'hours' 'hypersonic' 'ibm' 'impact'\n",
      " 'incident' 'incompressible' 'increase' 'increasing' 'increment' 'initial'\n",
      " 'inlet' 'instance' 'integral' 'integrated' 'intended' 'interesting'\n",
      " 'interference' 'internal' 'investigated' 'investigation' 'inviscid'\n",
      " 'involving' 'irrotational' 'karman-pohlhausen' 'kind' 'known' 'laminar'\n",
      " 'large-angled' 'layer' 'layers' 'leading' 'leads' 'libby' 'lift' 'linear'\n",
      " 'little' 'loading' 'local' 'locally' 'located' 'location' 'low'\n",
      " 'low-speed' 'lower' 'made' 'main' 'maximum' 'may' 'measurements'\n",
      " 'mentioned' 'method' 'methods' 'minutes' 'modified' 'mounted' 'must'\n",
      " 'necessary' 'need' 'needs' 'neumann' 'newtonian' 'non' 'nonuniformity'\n",
      " 'normal-force' 'nose' 'novel' 'number' 'numbers' 'obtained' 'occur' 'one'\n",
      " 'order' 'original' 'outside' 'paper' 'part' 'past' 'per'\n",
      " 'pitching-moment' 'plane' 'plate' 'points' 'possible' 'potential'\n",
      " 'prandtl' 'predict' 'predicts' 'presence' 'present' 'presented'\n",
      " 'pressure' 'pressures' 'previously' 'problem' 'problems' 'process'\n",
      " 'produced' 'profile' 'programed' 'propeller' 'protrude' 'provided'\n",
      " 'purely' 'rae' 'ramp' 'range' 'ratio' 'ratios' 'recently' 'refinement'\n",
      " 'region' 'remaining' 'require' 'restricted' 'result' 'results' 'revert'\n",
      " 'revolution' 'reynolds' 'rotational' 'satisfactorily' 'scope' 'second'\n",
      " 'secondary' 'section' 'seidel' 'set' 'several' 'shape' 'shear' 'shock'\n",
      " 'show' 'showed' 'shown' 'simple' 'simplest' 'single' 'situation' 'skin'\n",
      " 'slipstream' 'slopes' 'small' 'solid' 'solid-body' 'solution' 'solutions'\n",
      " 'solve' 'solved' 'solving' 'somewhat' 'source' 'span' 'spanwise'\n",
      " 'specific' 'speed' 'stabilizer' 'stabilizers' 'steady' 'still' 'stream'\n",
      " 'streams' 'study' 'substantial' 'subtracting' 'suction' 'suggests'\n",
      " 'supersonic' 'supporting' 'surface' 'symmetric' 'symmetry' 'takes'\n",
      " 'technique' 'theoretical' 'theory' 'thickness' 'thin' 'things' 'three'\n",
      " 'time' 'together' 'traverses' 'treated' 'treatments' 'turbulent' 'two'\n",
      " 'two-dimensional' 'uniform' 'upon' 'used' 'useful' 'usually' 'value'\n",
      " 'values' 'variable' 'vary' 'velocities' 'velocity' 'viewed' 'viscosity'\n",
      " 'viscous' 'vorticity' 'wave' 'wedges' 'well' 'whose' 'wing' 'within']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = nb_termes_glob(\"split\" ,None)\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(query,tokenization, normalization, file_type):\n",
    "    # tokenization, normalization, file_type = get_processing_args()\n",
    "    nb_terms = 0\n",
    "    global_term_frequencies = build_global_term_frequencies(tokenization, normalization)  # Calculate global term frequencies\n",
    "    N = len(os.listdir('Collections'))\n",
    "    results =[]\n",
    "    if file_type == \"TPD\":\n",
    "        doc_path = os.path.join('Collections', f\"{query}.txt\")\n",
    "        tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "        nb_terms = len(np.unique(tokens))\n",
    "        terms_freq = FreqDist(tokens)\n",
    "        \n",
    "        result = TPD_result(query, terms_freq, global_term_frequencies, N)\n",
    "        \n",
    "        return result , nb_terms\n",
    "        \n",
    "    else :\n",
    "        i=0\n",
    "        for doc_name in os.listdir('Collections'):\n",
    "            doc_path = os.path.join('Collections', doc_name)\n",
    "            Tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "            terms_freq = FreqDist(Tokens)\n",
    "\n",
    "            max_freq = max(terms_freq.values())\n",
    "            for term, freq in terms_freq.items():  \n",
    "                if term == query:  # Check if the term is the specific query term\n",
    "                    poids = ((freq / max_freq) * math.log10((N / global_term_frequencies[term]) + 1))\n",
    "                    i+=1\n",
    "                    results.append((i, term, os.path.splitext(doc_name)[0], freq, round(poids, 4)))\n",
    "        \n",
    "        return results , nb_terms\n",
    "   \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(query):\n",
    "    # if raw:\n",
    "    doc_path = os.path.join('Collections', f\"{query}.txt\")\n",
    "    with open(doc_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "    # elif processed:\n",
    "    #     text_processing(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SearchApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle(\"Document Search and Processing\")\n",
    "        self.setGeometry(100, 100, 900, 700) #8,6\n",
    "        self.setWindowIcon(QIcon(\"./icons/interface_icon.png\")) \n",
    "        self.setFixedSize(900, 700)\n",
    "        \n",
    "        \n",
    "        # Layout principal\n",
    "        central_widget = QWidget()\n",
    "        self.setCentralWidget(central_widget)\n",
    "        self.main_layout = QVBoxLayout(central_widget)\n",
    "\n",
    "        # Barre de recherche\n",
    "        search_layout = QHBoxLayout()\n",
    "        query_label = QLabel(\"Query: \", self)\n",
    "        search_layout.addWidget(query_label)\n",
    "        \n",
    "        self.search_bar = QLineEdit(self)\n",
    "        self.search_bar.setPlaceholderText(\"Enter document name...\")\n",
    "        self.search_button = QPushButton(\"Search\", self)\n",
    "        \n",
    "        search_layout.addWidget(self.search_bar)\n",
    "        search_layout.addWidget(self.search_button)\n",
    "        self.main_layout.addLayout(search_layout)\n",
    "\n",
    "        # Options de radio\n",
    "        radio_layout = QHBoxLayout()\n",
    "        self.raw_text_radio = QRadioButton(\"Raw Text\", self)\n",
    "        self.processed_text_radio = QRadioButton(\"Processed Text\", self)\n",
    "        radio_layout.addWidget(self.raw_text_radio)\n",
    "        radio_layout.addWidget(self.processed_text_radio)\n",
    "        self.main_layout.addLayout(radio_layout)\n",
    "        \n",
    "        # Section Tokenization\n",
    "        tokenization_box = QGroupBox(\"Tokenization\")\n",
    "        tokenization_layout = QVBoxLayout()\n",
    "        self.split_radio = QRadioButton(\"Split\", self)\n",
    "        self.regex_radio = QRadioButton(\"Regex\", self)\n",
    "        tokenization_layout.addWidget(self.split_radio)\n",
    "        tokenization_layout.addWidget(self.regex_radio)\n",
    "        tokenization_box.setLayout(tokenization_layout)\n",
    "        \n",
    "        # Section Normalization\n",
    "        normalization_box = QGroupBox(\"Normalization\")\n",
    "        normalization_layout = QVBoxLayout()\n",
    "        self.no_stem_radio = QRadioButton(\"No Stem\", self)\n",
    "        self.porter_radio = QRadioButton(\"Porter\", self)\n",
    "        self.lancaster_radio = QRadioButton(\"Lancaster\", self)\n",
    "        normalization_layout.addWidget(self.no_stem_radio)\n",
    "        normalization_layout.addWidget(self.porter_radio)\n",
    "        normalization_layout.addWidget(self.lancaster_radio)\n",
    "        normalization_box.setLayout(normalization_layout)\n",
    "        \n",
    "        # Section Indexation\n",
    "        indexation_box = QGroupBox(\"Indexation\")\n",
    "        indexation_layout = QVBoxLayout()\n",
    "        self.doc_per_term_radio = QRadioButton(\"Documents per Term\", self)\n",
    "        self.term_per_doc_radio = QRadioButton(\"Terms per Document\", self)\n",
    "        indexation_layout.addWidget(self.doc_per_term_radio)\n",
    "        indexation_layout.addWidget(self.term_per_doc_radio)\n",
    "        indexation_box.setLayout(indexation_layout)\n",
    "        \n",
    "        # Disposition des sections\n",
    "        sections_layout = QHBoxLayout()\n",
    "        sections_layout.addWidget(tokenization_box)\n",
    "        sections_layout.addWidget(normalization_box)\n",
    "        sections_layout.addWidget(indexation_box)\n",
    "        self.main_layout.addLayout(sections_layout)\n",
    "        \n",
    "        # Zone de résultats (QStackedWidget pour alterner entre texte et tableau)\n",
    "        self.result_label = QLabel(\"Result: \", self)\n",
    "        self.main_layout.addWidget(self.result_label)\n",
    "\n",
    "        self.result_area = QStackedWidget(self)\n",
    "        self.result_area.setFixedHeight(400)  # Taille fixe pour éviter d'étendre la mise en page\n",
    "        self.result_area.setFixedWidth(600)  # Ajustez selon la largeur désirée\n",
    "        \n",
    "        # Widget pour afficher le texte brut\n",
    "        self.raw_text_widget = QTextEdit(self)\n",
    "        self.raw_text_widget.setReadOnly(True)  # Rendre le texte en lecture seule\n",
    "        self.result_area.addWidget(self.raw_text_widget)\n",
    "        \n",
    "        # Widget pour afficher le tableau\n",
    "        self.table = QTableWidget(0, 5, self)  # 5 colonnes pour N°, N° doc, terme, fréquence, poids\n",
    "        self.table.setHorizontalHeaderLabels([\"N°\", \"N° doc\", \"Term\", \"Frequency\", \"Weight\"])\n",
    "        self.table.setShowGrid(False)  # Masquer la grille du tableau\n",
    "        \n",
    "        # Faire en sorte que les colonnes s'étendent pour couvrir toute la largeur\n",
    "        header = self.table.horizontalHeader()\n",
    "        header.setSectionResizeMode(QHeaderView.Stretch)\n",
    "        self.result_area.addWidget(self.table)\n",
    "        \n",
    "        self.main_layout.addWidget(self.result_area)\n",
    "\n",
    "    #    //////////////////////////////////////\n",
    "        Total_terms_layout = QHBoxLayout()\n",
    "        \n",
    "        # Création et configuration des QLabel\n",
    "        self.terms_per_doc = QLabel(self)\n",
    "        self.terms_all_doc = QLabel(self)\n",
    "        \n",
    "        # Appliquer les styles pour enlever le fond et les bordures\n",
    "        style = \"\"\"\n",
    "            QLabel {\n",
    "                margin-left: 20px;\n",
    "                background-color: transparent;\n",
    "                border: none;\n",
    "                font-size: 14px;\n",
    "                font-family: Arial, sans-serif;\n",
    "            }\n",
    "        \"\"\"\n",
    "        self.terms_all_doc.setStyleSheet(style)\n",
    "        self.terms_per_doc.setStyleSheet(style)\n",
    "        \n",
    "        \n",
    "        # Ajout des QLabel au layout horizontal\n",
    "        Total_terms_layout.addWidget(self.terms_per_doc)\n",
    "        Total_terms_layout.addWidget(self.terms_all_doc)\n",
    "        \n",
    "        # Ajout du layout horizontal dans le layout principal\n",
    "        self.main_layout.addLayout(Total_terms_layout)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Ajustements dans le code principal\n",
    "        self.main_layout.setContentsMargins(2, 2, 2, 2)  # Réduire les marges globales\n",
    "        self.main_layout.setSpacing(8)  # Diminuer l'espace entre les sections\n",
    "        self.result_area.setContentsMargins(2, 0, 2, 0)  # Marges gauche et droite de 2px pour le tableau\n",
    "        self.result_area.setFixedWidth(self.width() - 4) \n",
    "                \n",
    "                \n",
    "        \n",
    "        self.search_button.clicked.connect(self.process_search)\n",
    "        self.raw_text_radio.clicked.connect(self.raw_text_radio_process)\n",
    "        self.processed_text_radio.clicked.connect(self.processed_text_radio_process)\n",
    "        \n",
    "\n",
    "    def raw_text_radio_process(self):\n",
    "        self.split_radio.setEnabled(False) \n",
    "        self.regex_radio.setEnabled(False)\n",
    "        self.lancaster_radio.setEnabled(False)\n",
    "        self.porter_radio.setEnabled(False)\n",
    "        self.doc_per_term_radio.setEnabled(False)\n",
    "        self.term_per_doc_radio.setEnabled(False)\n",
    "        self.no_stem_radio.setEnabled(False)\n",
    "        self.terms_per_doc.setText(\"\")\n",
    "        self.terms_all_doc.setText(\"\")\n",
    "       \n",
    "       \n",
    "    def processed_text_radio_process(self):\n",
    "        self.split_radio.setEnabled(True) \n",
    "        self.regex_radio.setEnabled(True)\n",
    "        self.lancaster_radio.setEnabled(True)\n",
    "        self.porter_radio.setEnabled(True)\n",
    "        self.doc_per_term_radio.setEnabled(True)\n",
    "        self.term_per_doc_radio.setEnabled(True)\n",
    "        self.no_stem_radio.setEnabled(True)\n",
    "        \n",
    "         \n",
    "    def display_Total_Terms(self, termes_global, nb_termes ,index):\n",
    "        if nb_termes != 0 and index == 'TPD':\n",
    "            # Afficher le nombre de termes par document\n",
    "            self.terms_per_doc.setText(f\"Terms per document : {nb_termes}\")\n",
    "        else :\n",
    "            self.terms_per_doc.setText(\"\")\n",
    "        self.terms_all_doc.setText(f\"Total terms  : {termes_global}\")\n",
    "\n",
    "        \n",
    "        \n",
    "    def process_search(self):\n",
    "        # Obtenir le numéro de document\n",
    "        document_number = self.search_bar.text()\n",
    "        \n",
    "        if not document_number:\n",
    "            self.show_error(\"Veuillez entrer un numéro de document valide.\")\n",
    "            return\n",
    "\n",
    "        # \n",
    "        # Vérifier le type de texte sélectionné\n",
    "        if self.raw_text_radio.isChecked():\n",
    "            # verification de nom_document\n",
    "            result = get_text(document_number)\n",
    "            self.show_raw_text(result)\n",
    "        else:\n",
    "            # Obtenir les méthodes sélectionnées\n",
    "            tokenization_method = \"Split\" if self.split_radio.isChecked() else \"Regex\"\n",
    "            if self.porter_radio.isChecked() :\n",
    "                normalization_method = \"Porter\" \n",
    "            elif self.no_stem_radio.isChecked():\n",
    "                normalization_method = \"None\" \n",
    "            else :\n",
    "                normalization_method =\"Lancaster\"\n",
    "            indexation_method = \"DPT\" if self.doc_per_term_radio.isChecked() else \"TPD\"\n",
    "            \n",
    "                \n",
    "                \n",
    "            termes_global = nb_termes_glob(tokenization_method, normalization_method)\n",
    "            # Appeler la fonction pour obtenir les données\n",
    "            data , nb_termes = text_processing(document_number, tokenization_method, normalization_method, indexation_method)\n",
    "            print(data)\n",
    "            self.display_results(data)\n",
    "            self.display_Total_Terms(termes_global , nb_termes , indexation_method)\n",
    "\n",
    " \n",
    "\n",
    "    def show_raw_text(self, text):\n",
    "        self.raw_text_widget.setText(text)\n",
    "        self.result_area.setCurrentWidget(self.raw_text_widget)  # Afficher le widget de texte brut\n",
    "\n",
    "        \n",
    "    def display_results(self, data):\n",
    "    # Supprimer l'affichage de l'index de ligne\n",
    "        self.table.verticalHeader().setVisible(False)\n",
    "\n",
    "        # Nettoyer le tableau et ajouter les résultats\n",
    "        self.table.setRowCount(0)\n",
    "        for index, row_data in enumerate(data):\n",
    "            row_position = self.table.rowCount()\n",
    "            self.table.insertRow(row_position)\n",
    "            for column, value in enumerate(row_data):\n",
    "                item = QTableWidgetItem(str(value))\n",
    "                item.setTextAlignment(Qt.AlignCenter)  # Centrer le texte dans chaque cellule\n",
    "                self.table.setItem(row_position, column, item)\n",
    "        \n",
    "        # Afficher le widget de tableau\n",
    "        self.result_area.setCurrentWidget(self.table)\n",
    "    \n",
    "    def show_error(self, message):\n",
    "        error_dialog = QMessageBox(self)\n",
    "        error_dialog.setIcon(QMessageBox.Critical)\n",
    "        error_dialog.setWindowTitle(\"Erreur\")\n",
    "        error_dialog.setText(message)\n",
    "        error_dialog.exec_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termes uniques :  ['0.1' '1' '1.5' '1.6x10' '10' '101' '3' '3.2x10' '300' '5' '704' 'accur'\n",
      " 'accuraci' 'actual' 'aerodynam' 'aerodynamic-centr' 'agre' 'algebra'\n",
      " 'almost' 'also' 'angl' 'anoth' 'appli' 'applic' 'approxim' 'arbitrari'\n",
      " 'area' 'aris' 'attack' 'axial' 'base' 'basi' 'behind' 'blunt-nos' 'bodi'\n",
      " 'boundari' 'boundary-lay' 'boundary-layer-control' 'boundary-valu' 'bow'\n",
      " 'calcul' 'capabl' 'case' 'cent' 'center' 'characterist' 'check'\n",
      " 'circulatori' 'classic' 'coeffici' 'compar' 'comparison' 'compress'\n",
      " 'comput' 'concept' 'conclud' 'cone' 'configur' 'consequ' 'consid'\n",
      " 'constant' 'convent' 'coordin' 'curv' 'deal' 'defin' 'depend' 'destal'\n",
      " 'determin' 'develop' 'differ' 'dimension' 'diminish' 'discuss'\n",
      " 'distribut' 'disturb' 'drag' 'due' 'dynam' 'eas' 'edg' 'edpm' 'effect'\n",
      " 'effici' 'either' 'embed' 'emit' 'empir' 'enough' 'entir' 'entropi'\n",
      " 'equat' 'evalu' 'evid' 'exact' 'examin' 'exampl' 'exist' 'expect'\n",
      " 'experi' 'experiment' 'factor' 'featur' 'ferri' 'field' 'first' 'flap'\n",
      " 'flare' 'flat' 'flight' 'flow' 'fluid' 'found' 'fredholm' 'free'\n",
      " 'free-stream' 'friction' 'gener' 'give' 'given' 'greater' 'growth'\n",
      " 'high-spe' 'hour' 'hyperson' 'ibm' 'impact' 'incid' 'incompress'\n",
      " 'increas' 'increment' 'initi' 'inlet' 'instanc' 'integr' 'intend'\n",
      " 'interest' 'interfer' 'intern' 'investig' 'inviscid' 'involv' 'irrot'\n",
      " 'karman-pohlhausen' 'kind' 'known' 'laminar' 'large-angl' 'layer' 'lead'\n",
      " 'libbi' 'lift' 'linear' 'littl' 'load' 'local' 'locat' 'low' 'low-spe'\n",
      " 'lower' 'made' 'main' 'maximum' 'may' 'measur' 'mention' 'method' 'minut'\n",
      " 'modifi' 'mount' 'must' 'necessari' 'need' 'neumann' 'newtonian' 'non'\n",
      " 'nonuniform' 'normal-forc' 'nose' 'novel' 'number' 'obtain' 'occur' 'one'\n",
      " 'order' 'origin' 'outsid' 'paper' 'part' 'past' 'per' 'pitching-mo'\n",
      " 'plane' 'plate' 'point' 'possibl' 'potenti' 'prandtl' 'predict' 'presenc'\n",
      " 'present' 'pressur' 'previous' 'problem' 'process' 'produc' 'profil'\n",
      " 'program' 'propel' 'protrud' 'provid' 'pure' 'rae' 'ramp' 'rang' 'ratio'\n",
      " 'recent' 'refin' 'region' 'remain' 'requir' 'restrict' 'result' 'revert'\n",
      " 'revolut' 'reynold' 'rotat' 'satisfactorili' 'scope' 'second' 'secondari'\n",
      " 'section' 'seidel' 'set' 'sever' 'shape' 'shear' 'shock' 'show' 'shown'\n",
      " 'simpl' 'simplest' 'singl' 'situat' 'skin' 'slipstream' 'slope' 'small'\n",
      " 'solid' 'solid-bodi' 'solut' 'solv' 'somewhat' 'sourc' 'span' 'spanwis'\n",
      " 'specif' 'speed' 'stabil' 'steadi' 'still' 'stream' 'studi' 'substanti'\n",
      " 'subtract' 'suction' 'suggest' 'superson' 'support' 'surfac' 'symmetr'\n",
      " 'symmetri' 'take' 'techniqu' 'theoret' 'theori' 'thick' 'thin' 'thing'\n",
      " 'three' 'time' 'togeth' 'travers' 'treat' 'treatment' 'turbul' 'two'\n",
      " 'two-dimension' 'uniform' 'upon' 'use' 'usual' 'valu' 'vari' 'variabl'\n",
      " 'veloc' 'view' 'viscos' 'viscou' 'vortic' 'wave' 'wedg' 'well' 'whose'\n",
      " 'wing' 'within']\n",
      "[(1, 'simpl', 'D2', 2, 0.2007), (2, 'shear', 'D2', 2, 0.2007), (3, 'flow', 'D2', 6, 0.3424), (4, 'past', 'D2', 4, 0.5634), (5, 'flat', 'D2', 3, 0.301), (6, 'plate', 'D2', 3, 0.301), (7, 'incompress', 'D2', 2, 0.2007), (8, 'fluid', 'D2', 2, 0.2007), (9, 'small', 'D2', 2, 0.2817), (10, 'viscos', 'D2', 2, 0.2007), (11, 'studi', 'D2', 2, 0.2007), (12, 'high-spe', 'D2', 1, 0.1408), (13, 'viscou', 'D2', 2, 0.2817), (14, 'two-dimension', 'D2', 2, 0.159), (15, 'bodi', 'D2', 2, 0.159), (16, 'usual', 'D2', 1, 0.1003), (17, 'necessari', 'D2', 1, 0.1408), (18, 'consid', 'D2', 2, 0.159), (19, 'curv', 'D2', 1, 0.0795), (20, 'shock', 'D2', 2, 0.2007), (21, 'wave', 'D2', 2, 0.2007), (22, 'emit', 'D2', 1, 0.1408), (23, 'nose', 'D2', 1, 0.1408), (24, 'lead', 'D2', 1, 0.1003), (25, 'edg', 'D2', 1, 0.1408), (26, 'consequ', 'D2', 1, 0.1003), (27, 'exist', 'D2', 1, 0.1408), (28, 'inviscid', 'D2', 3, 0.4225), (29, 'rotat', 'D2', 2, 0.2817), (30, 'region', 'D2', 1, 0.1003), (31, 'boundari', 'D2', 2, 0.1326), (32, 'layer', 'D2', 2, 0.1326), (33, 'situat', 'D2', 2, 0.2817), (34, 'aris', 'D2', 1, 0.1408), (35, 'instanc', 'D2', 1, 0.1408), (36, 'hyperson', 'D2', 2, 0.2007), (37, 'somewhat', 'D2', 1, 0.1408), (38, 'differ', 'D2', 1, 0.0795), (39, 'prandtl', 'D2', 2, 0.2817), (40, 'classic', 'D2', 1, 0.1408), (41, 'boundary-lay', 'D2', 3, 0.2386), (42, 'problem', 'D2', 4, 0.2653), (43, 'origin', 'D2', 1, 0.1408), (44, 'free', 'D2', 3, 0.301), (45, 'stream', 'D2', 3, 0.2386), (46, 'outsid', 'D2', 1, 0.1408), (47, 'irrot', 'D2', 1, 0.1408), (48, 'must', 'D2', 1, 0.1408), (49, 'possibl', 'D2', 1, 0.1003), (50, 'effect', 'D2', 1, 0.0663), (51, 'vortic', 'D2', 2, 0.2007), (52, 'recent', 'D2', 1, 0.1408), (53, 'discuss', 'D2', 2, 0.2817), (54, 'ferri', 'D2', 1, 0.1408), (55, 'libbi', 'D2', 1, 0.1408), (56, 'present', 'D2', 1, 0.1003), (57, 'paper', 'D2', 1, 0.1408), (58, 'investig', 'D2', 1, 0.1003), (59, 'shown', 'D2', 1, 0.1408), (60, 'treat', 'D2', 1, 0.1003), (61, 'approxim', 'D2', 1, 0.0795), (62, 'novel', 'D2', 1, 0.1408), (63, 'featur', 'D2', 1, 0.1408), (64, 'constant', 'D2', 1, 0.1408), (65, 'restrict', 'D2', 1, 0.1408), (66, 'steadi', 'D2', 1, 0.1003)]\n",
      "Termes uniques :  ['0.1' '1' '1.5' '1.6x10' '10' '101' '3' '3.2x10' '300' '5' '704' 'accur'\n",
      " 'accuraci' 'actual' 'aerodynam' 'aerodynamic-centr' 'agre' 'algebra'\n",
      " 'almost' 'also' 'angl' 'anoth' 'appli' 'applic' 'approxim' 'arbitrari'\n",
      " 'area' 'aris' 'attack' 'axial' 'base' 'basi' 'behind' 'blunt-nos' 'bodi'\n",
      " 'boundari' 'boundary-lay' 'boundary-layer-control' 'boundary-valu' 'bow'\n",
      " 'calcul' 'capabl' 'case' 'cent' 'center' 'characterist' 'check'\n",
      " 'circulatori' 'classic' 'coeffici' 'compar' 'comparison' 'compress'\n",
      " 'comput' 'concept' 'conclud' 'cone' 'configur' 'consequ' 'consid'\n",
      " 'constant' 'convent' 'coordin' 'curv' 'deal' 'defin' 'depend' 'destal'\n",
      " 'determin' 'develop' 'differ' 'dimension' 'diminish' 'discuss'\n",
      " 'distribut' 'disturb' 'drag' 'due' 'dynam' 'eas' 'edg' 'edpm' 'effect'\n",
      " 'effici' 'either' 'embed' 'emit' 'empir' 'enough' 'entir' 'entropi'\n",
      " 'equat' 'evalu' 'evid' 'exact' 'examin' 'exampl' 'exist' 'expect'\n",
      " 'experi' 'experiment' 'factor' 'featur' 'ferri' 'field' 'first' 'flap'\n",
      " 'flare' 'flat' 'flight' 'flow' 'fluid' 'found' 'fredholm' 'free'\n",
      " 'free-stream' 'friction' 'gener' 'give' 'given' 'greater' 'growth'\n",
      " 'high-spe' 'hour' 'hyperson' 'ibm' 'impact' 'incid' 'incompress'\n",
      " 'increas' 'increment' 'initi' 'inlet' 'instanc' 'integr' 'intend'\n",
      " 'interest' 'interfer' 'intern' 'investig' 'inviscid' 'involv' 'irrot'\n",
      " 'karman-pohlhausen' 'kind' 'known' 'laminar' 'large-angl' 'layer' 'lead'\n",
      " 'libbi' 'lift' 'linear' 'littl' 'load' 'local' 'locat' 'low' 'low-spe'\n",
      " 'lower' 'made' 'main' 'maximum' 'may' 'measur' 'mention' 'method' 'minut'\n",
      " 'modifi' 'mount' 'must' 'necessari' 'need' 'neumann' 'newtonian' 'non'\n",
      " 'nonuniform' 'normal-forc' 'nose' 'novel' 'number' 'obtain' 'occur' 'one'\n",
      " 'order' 'origin' 'outsid' 'paper' 'part' 'past' 'per' 'pitching-mo'\n",
      " 'plane' 'plate' 'point' 'possibl' 'potenti' 'prandtl' 'predict' 'presenc'\n",
      " 'present' 'pressur' 'previous' 'problem' 'process' 'produc' 'profil'\n",
      " 'program' 'propel' 'protrud' 'provid' 'pure' 'rae' 'ramp' 'rang' 'ratio'\n",
      " 'recent' 'refin' 'region' 'remain' 'requir' 'restrict' 'result' 'revert'\n",
      " 'revolut' 'reynold' 'rotat' 'satisfactorili' 'scope' 'second' 'secondari'\n",
      " 'section' 'seidel' 'set' 'sever' 'shape' 'shear' 'shock' 'show' 'shown'\n",
      " 'simpl' 'simplest' 'singl' 'situat' 'skin' 'slipstream' 'slope' 'small'\n",
      " 'solid' 'solid-bodi' 'solut' 'solv' 'somewhat' 'sourc' 'span' 'spanwis'\n",
      " 'specif' 'speed' 'stabil' 'steadi' 'still' 'stream' 'studi' 'substanti'\n",
      " 'subtract' 'suction' 'suggest' 'superson' 'support' 'surfac' 'symmetr'\n",
      " 'symmetri' 'take' 'techniqu' 'theoret' 'theori' 'thick' 'thin' 'thing'\n",
      " 'three' 'time' 'togeth' 'travers' 'treat' 'treatment' 'turbul' 'two'\n",
      " 'two-dimension' 'uniform' 'upon' 'use' 'usual' 'valu' 'vari' 'variabl'\n",
      " 'veloc' 'view' 'viscos' 'viscou' 'vortic' 'wave' 'wedg' 'well' 'whose'\n",
      " 'wing' 'within']\n",
      "[(1, 'solv', 'D4', 4, 0.4829)]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryan\\anaconda3\\envs\\ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    app.setStyleSheet(\"\"\"\n",
    "    QMainWindow {\n",
    "        background-color: #f5f5f5;\n",
    "    }\n",
    "    QLabel {\n",
    "        color: #333333;\n",
    "        font-size: 14px;\n",
    "    }\n",
    "    QLineEdit {\n",
    "        border: 1px solid #CCCCCC;\n",
    "        border-radius: 5px;\n",
    "        padding: 5px;\n",
    "    }\n",
    "    QPushButton {\n",
    "        background-color: #4CAF50;\n",
    "        color: white;\n",
    "        font-size: 14px;\n",
    "        padding: 5px 10px;\n",
    "        border-radius: 5px;\n",
    "    }\n",
    "    QPushButton:hover {\n",
    "        background-color: #45a049;\n",
    "    }\n",
    "    \n",
    "    QRadioButton {\n",
    "        font-size: 13px;\n",
    "    }\n",
    "    QGroupBox {\n",
    "        font-size: 15px;\n",
    "        color: #333333;\n",
    "        border: 1px solid #CCCCCC;\n",
    "        border-radius: 8px;\n",
    "        margin-top: 10px;\n",
    "        padding: 10px;\n",
    "    }\n",
    "    QTextEdit {\n",
    "        background-color: #f0f0f0;\n",
    "        border: 1px solid #CCCCCC;\n",
    "        border-radius: 5px;\n",
    "        padding: 5px;\n",
    "    }\n",
    "    QTableWidget {\n",
    "        background-color: #FFFFFF;\n",
    "        border: 1px solid #CCCCCC;\n",
    "        border-radius: 5px;\n",
    "        padding: 2px;\n",
    "        gridline-color: #E0E0E0;\n",
    "    }\n",
    "    QTableWidget::item {\n",
    "        padding: 5px;\n",
    "        border-bottom: 1px solid #E0E0E0;\n",
    "    }\n",
    "    QHeaderView::section {\n",
    "        background-color: #f0f0f0;\n",
    "        padding: 5px;\n",
    "        border: 1px solid #CCCCCC;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "\n",
    "    QLabel {\n",
    "        margin-left: 20px;\n",
    "        background-color: transparent;\n",
    "        border: none;\n",
    "        font-size: 14px;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "    window = SearchApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
