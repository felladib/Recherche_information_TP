{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import BIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import (\n",
    "    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,\n",
    "    QLineEdit, QPushButton, QRadioButton, QLabel, QGroupBox,\n",
    "    QTableWidget, QTableWidgetItem, QScrollArea, QTextEdit, QStackedWidget, QGridLayout,\n",
    "    QMessageBox,QHeaderView,QComboBox\n",
    ")\n",
    "from PyQt5.QtGui import QDoubleValidator\n",
    "from PyQt5.QtGui import QIcon\n",
    "from PyQt5.QtCore import Qt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk import FreqDist\n",
    "\n",
    "\n",
    "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
    "PORTER_STEMMER = nltk.PorterStemmer()\n",
    "LANCASTER_STEMMER = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Collestions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_processing_args():\n",
    "#     tokenization = \"Split\"\n",
    "#     normalization = \"None\",\n",
    "#     file_type = \"TPD\"\n",
    "#     return tokenization, normalization, file_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(doc_path, tokenization, normalization):\n",
    "    with open(doc_path, 'r') as file:\n",
    "        text = file.read()\n",
    "        \n",
    "    # Tokenization\n",
    "    if tokenization == \"Split\":\n",
    "        tokens = text.split()\n",
    "    else:\n",
    "        exp_reg = nltk.RegexpTokenizer(r'\\d+(?:\\.\\d+)?x\\d+|\\d+(?:\\.\\d+)|\\w+(?:-\\w+)*|(?:[A-Z]\\.)+|\\w+')\n",
    "        tokens = exp_reg.tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [term for term in tokens if term.lower() not in STOPWORDS]\n",
    "\n",
    "    # Normalization\n",
    "    if normalization == \"Porter\":\n",
    "        tokens = [PORTER_STEMMER.stem(term) for term in tokens]\n",
    "    elif normalization == \"Lancaster\":\n",
    "        tokens = [LANCASTER_STEMMER.stem(term) for term in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_global_term_frequencies(tokenization, normalization):\n",
    "#     global_term_frequencies = defaultdict(int)\n",
    "\n",
    "#     for doc_name in os.listdir('Collections'):\n",
    "#         doc_path = os.path.join('Collections', doc_name)\n",
    "#         tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "#         unique_terms = set(tokens)\n",
    "\n",
    "#         for term in unique_terms:\n",
    "#             global_term_frequencies[term] += 1\n",
    "            \n",
    "#     return global_term_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TPD_result(query, terms_freq, global_term_frequencies, N):\n",
    "#     max_freq = max(terms_freq.values())\n",
    "#     results=[]\n",
    "#     for idx, (term, freq) in enumerate(terms_freq.items(), start=1):\n",
    "#         poids = (freq / max_freq) * math.log10((N / global_term_frequencies[term]) + 1)\n",
    "#         results.append((idx, term, query, freq, round(poids, 4)))\n",
    "        \n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nb_termes_glob(tokenization, normalization):\n",
    "#     nb_termes_global = []\n",
    "#     for doc_name in os.listdir('Collections'):\n",
    "#         doc_path = os.path.join('Collections', doc_name)\n",
    "#         # Appliquer le prétraitement pour obtenir les tokens du document\n",
    "#         tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "        \n",
    "#         # Ajouter les tokens du document à la liste globale\n",
    "#         nb_termes_global.extend(tokens)\n",
    "\n",
    "#     # Obtenir le nombre de termes uniques\n",
    "#     termes_uniques = np.unique(nb_termes_global)\n",
    "#     print(\"Termes uniques : \", termes_uniques)  # Optionnel : pour visualiser les termes uniques\n",
    "    \n",
    "#     return len(termes_uniques)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(query, normalization):\n",
    "    # appliquer le traitement sur la requete\n",
    "    if normalization == \"Porter\":\n",
    "        query = PORTER_STEMMER.stem(query) \n",
    "    elif normalization == \"Lancaster\":\n",
    "        query = LANCASTER_STEMMER.stem(query) \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_processing(query,tokenization, normalization, file_type):\n",
    "#     # tokenization, normalization, file_type = get_processing_args()\n",
    "#     nb_terms = 0\n",
    "#     # calculer la frequence de chaque element\n",
    "#     global_term_frequencies = build_global_term_frequencies(tokenization, normalization)  # Calculate global term frequencies\n",
    "#     N = len(os.listdir('Collections'))\n",
    "#     results =[]\n",
    "#     if file_type == \"TPD\":\n",
    "#         doc_path = os.path.join('Collections', f\"{query}.txt\")\n",
    "#         tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "#         nb_terms = len(np.unique(tokens))\n",
    "#         terms_freq = FreqDist(tokens)\n",
    "        \n",
    "#         results = TPD_result(query, terms_freq, global_term_frequencies, N)\n",
    "#         print(f\"la resultat de chaque requete type {results}\")\n",
    "#         return results , nb_terms\n",
    "        \n",
    "#     else :\n",
    "#         query = process_input(query, normalization)\n",
    "#         i=0\n",
    "#         for doc_name in os.listdir('Collections'):\n",
    "#             doc_path = os.path.join('Collections', doc_name)\n",
    "#             Tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "#             terms_freq = FreqDist(Tokens)\n",
    "\n",
    "#             max_freq = max(terms_freq.values())\n",
    "#             for term, freq in terms_freq.items():  \n",
    "#                 if term == query:  # Check if the term is the specific query term\n",
    "#                     poids = ((freq / max_freq) * math.log10((N / global_term_frequencies[term]) + 1))\n",
    "#                     i+=1\n",
    "#                     results.append((i, term, os.path.splitext(doc_name)[0], freq, round(poids, 4)))\n",
    "#         print(f\"la resultat de chaque requete type {results}\")\n",
    "#         return results , nb_terms\n",
    "   \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(query):\n",
    "    # if raw:\n",
    "    doc_path = os.path.join('Collections', f\"{query}.txt\")\n",
    "    with open(doc_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "    # elif processed:\n",
    "    #     text_processing(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def create_descriptor_and_inverse_files_with_weights(path, tokenization, normalization, output_path=\"output\"):\n",
    "    # Créer un nom unique pour les fichiers en fonction des choix de tokenization et normalization\n",
    "    descriptor_filename = f\"descripteur_{tokenization}_{normalization}.json\"\n",
    "    inverse_index_filename = f\"inverse_index_{tokenization}_{normalization}.json\"\n",
    "    \n",
    "    descriptor_path = os.path.join(output_path, descriptor_filename)\n",
    "    inverse_index_path = os.path.join(output_path, inverse_index_filename)\n",
    "    \n",
    "    # Vérifier si les fichiers existent déjà\n",
    "    if os.path.exists(descriptor_path) and os.path.exists(inverse_index_path):\n",
    "        print(f\"Les fichiers descripteur et inverse existent déjà : {descriptor_path} et {inverse_index_path}\")\n",
    "        \n",
    "        # Charger les fichiers existants\n",
    "        with open(descriptor_path, \"r\", encoding=\"utf-8\") as desc_file:\n",
    "            descripteur = json.load(desc_file)\n",
    "        with open(inverse_index_path, \"r\", encoding=\"utf-8\") as inverse_file:\n",
    "            inverse_index = json.load(inverse_file)\n",
    "        \n",
    "        return descripteur, inverse_index\n",
    "    \n",
    "    # Si les fichiers n'existent pas, les créer\n",
    "    print(\"Création des fichiers descripteur et inverse...\")\n",
    "    \n",
    "    # Initialiser les fichiers descripteur et inverse\n",
    "    descripteur = {}\n",
    "    inverse_index = defaultdict(lambda: defaultdict(lambda: {\"freq\": 0, \"poids\": 0}))\n",
    "    \n",
    "    # Nombre total de documents\n",
    "    documents = os.listdir(path)\n",
    "    N = len(documents)\n",
    "    \n",
    "    # Calcul des fréquences globales pour les poids\n",
    "    global_term_frequencies = defaultdict(int)\n",
    "    for doc_name in documents:\n",
    "        doc_path = os.path.join(path, doc_name)\n",
    "        tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "        unique_terms = set(tokens)\n",
    "        for term in unique_terms:\n",
    "            global_term_frequencies[term] += 1\n",
    "    \n",
    "    # Construire les fichiers descripteur et inverse\n",
    "    for doc_name in documents:\n",
    "        doc_path = os.path.join(path, doc_name)\n",
    "        tokens = preprocessing(doc_path, tokenization, normalization)\n",
    "        terms_freq = FreqDist(tokens)  # Fréquence des termes\n",
    "        max_freq = max(terms_freq.values())  # Fréquence maximale dans le document\n",
    "        doc_key = os.path.splitext(doc_name)[0]\n",
    "        \n",
    "        # Ajouter les termes au fichier descripteur\n",
    "        descripteur[doc_key] = {}\n",
    "        for term, freq in terms_freq.items():\n",
    "            poids = (freq / max_freq) * math.log10((N / global_term_frequencies[term]) + 1)\n",
    "            descripteur[doc_key][term] = {\"freq\": freq, \"poids\": round(poids, 4)}\n",
    "            \n",
    "            # Ajouter les termes au fichier inverse\n",
    "            inverse_index[term][doc_key][\"freq\"] = freq\n",
    "            inverse_index[term][doc_key][\"poids\"] = round(poids, 4)\n",
    "    \n",
    "    # Sauvegarder les fichiers en JSON\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    with open(descriptor_path, \"w\", encoding=\"utf-8\") as desc_file:\n",
    "        json.dump(descripteur, desc_file, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    with open(inverse_index_path, \"w\", encoding=\"utf-8\") as inverse_file:\n",
    "        json.dump(inverse_index, inverse_file, indent=4, ensure_ascii=False)\n",
    "    \n",
    "\n",
    "    return descripteur, inverse_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_terme_per_doc(query, descripteur):\n",
    "    if query in descripteur:\n",
    "        terms = descripteur[query]\n",
    "        total = len(terms)  # Nombre de termes distincts dans le document\n",
    "        return total\n",
    "    else:\n",
    "        return 0  # Si le document n'existe pas dans le fichier descripteur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_termes_descripteur(descripteur):\n",
    "    total = 0\n",
    "    for terms in descripteur.values():  # Parcourt chaque document\n",
    "        total += len(terms)  # Ajoute le nombre de termes distincts dans chaque document\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_descripteur_invers(normalization , tokenization ,output_path):\n",
    "    # Générer les noms des fichiers\n",
    "    descriptor_filename = f\"descripteur_{tokenization}_{normalization}.json\"\n",
    "    inverse_index_filename = f\"inverse_index_{tokenization}_{normalization}.json\"\n",
    "\n",
    "    descriptor_path = os.path.join(output_path, descriptor_filename)\n",
    "    inverse_index_path = os.path.join(output_path, inverse_index_filename)\n",
    "\n",
    "    # Vérifier si les fichiers existent, sinon les créer\n",
    "    if not os.path.exists(descriptor_path) or not os.path.exists(inverse_index_path):\n",
    "        print(f\"Les fichiers pour {tokenization} et {normalization} n'existent pas. Création en cours...\")\n",
    "        create_descriptor_and_inverse_files_with_weights(path, tokenization, normalization, output_path)\n",
    "\n",
    "    # Charger les fichiers descripteur et inverse\n",
    "    with open(descriptor_path, \"r\", encoding=\"utf-8\") as desc_file:\n",
    "        descripteur = json.load(desc_file)\n",
    "    with open(inverse_index_path, \"r\", encoding=\"utf-8\") as inverse_file:\n",
    "        inverse_index = json.load(inverse_file)\n",
    "    return descripteur , inverse_index\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(query, tokenization, normalization, path, output_path=\"output\",methode = 'TPD'):\n",
    "    \n",
    "    descripteur , inverse_index = open_descripteur_invers(normalization , tokenization ,output_path)\n",
    "   \n",
    "    nb_total_terme_per_doc = total_terme_per_doc(query, descripteur)\n",
    "    nb_total_per_collection = total_termes_descripteur(descripteur)\n",
    "    \n",
    "    formatted_results = []\n",
    "    if methode == 'TPD':\n",
    "        if query in descripteur:\n",
    "            terms = descripteur[query]\n",
    "            for i, (term, data) in enumerate(terms.items(), start=1):\n",
    "                formatted_results.append((i, term, query, data['freq'], data['poids']))\n",
    "        \n",
    "    else:\n",
    "        if query in inverse_index:\n",
    "            docs = inverse_index[query]\n",
    "            for i, (doc, data) in enumerate(docs.items(), start=1):\n",
    "                formatted_results.append((i, query, doc, data['freq'], data['poids']))\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    return formatted_results , nb_total_terme_per_doc , nb_total_per_collection\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'experimental', 'D1', 2, 0.2817),\n",
       " (2, 'investigation', 'D1', 1, 0.1408),\n",
       " (3, 'aerodynamics', 'D1', 1, 0.1408),\n",
       " (4, 'wing', 'D1', 3, 0.301),\n",
       " (5, 'slipstream', 'D1', 5, 0.7042),\n",
       " (6, '.', 'D1', 6, 0.301),\n",
       " (7, 'study', 'D1', 1, 0.1003),\n",
       " (8, 'propeller', 'D1', 1, 0.1408),\n",
       " (9, 'made', 'D1', 2, 0.2007),\n",
       " (10, 'order', 'D1', 1, 0.1408),\n",
       " (11, 'determine', 'D1', 1, 0.1408),\n",
       " (12, 'spanwise', 'D1', 1, 0.1408),\n",
       " (13, 'distribution', 'D1', 1, 0.0663),\n",
       " (14, 'lift', 'D1', 3, 0.4225),\n",
       " (15, 'increase', 'D1', 1, 0.1408),\n",
       " (16, 'due', 'D1', 2, 0.2817),\n",
       " (17, 'different', 'D1', 3, 0.301),\n",
       " (18, 'angles', 'D1', 1, 0.1408),\n",
       " (19, 'attack', 'D1', 1, 0.1408),\n",
       " (20, 'free', 'D1', 1, 0.1003),\n",
       " (21, 'stream', 'D1', 1, 0.1003),\n",
       " (22, 'velocity', 'D1', 1, 0.1003),\n",
       " (23, 'ratios', 'D1', 1, 0.1408),\n",
       " (24, 'results', 'D1', 1, 0.1003),\n",
       " (25, 'intended', 'D1', 1, 0.1408),\n",
       " (26, 'part', 'D1', 2, 0.2817),\n",
       " (27, 'evaluation', 'D1', 2, 0.2817),\n",
       " (28, 'basis', 'D1', 1, 0.1003),\n",
       " (29, 'theoretical', 'D1', 1, 0.1408),\n",
       " (30, 'treatments', 'D1', 1, 0.1408),\n",
       " (31, 'problem', 'D1', 1, 0.0663),\n",
       " (32, 'comparative', 'D1', 1, 0.1408),\n",
       " (33, 'span', 'D1', 1, 0.1408),\n",
       " (34, 'loading', 'D1', 1, 0.1408),\n",
       " (35, 'curves,', 'D1', 1, 0.1408),\n",
       " (36, 'together', 'D1', 1, 0.1408),\n",
       " (37, 'supporting', 'D1', 1, 0.1408),\n",
       " (38, 'evidence,', 'D1', 1, 0.1408),\n",
       " (39, 'showed', 'D1', 1, 0.1408),\n",
       " (40, 'substantial', 'D1', 1, 0.1408),\n",
       " (41, 'increment', 'D1', 1, 0.1408),\n",
       " (42, 'produced', 'D1', 1, 0.1408),\n",
       " (43, '/destalling/', 'D1', 1, 0.1408),\n",
       " (44, 'boundary-layer-control', 'D1', 1, 0.1408),\n",
       " (45, 'effect', 'D1', 1, 0.0795),\n",
       " (46, 'integrated', 'D1', 1, 0.1003),\n",
       " (47, 'remaining', 'D1', 1, 0.1408),\n",
       " (48, 'increment,', 'D1', 1, 0.1408),\n",
       " (49, 'subtracting', 'D1', 1, 0.1408),\n",
       " (50, 'destalling', 'D1', 2, 0.2817),\n",
       " (51, 'lift,', 'D1', 1, 0.1003),\n",
       " (52, 'found', 'D1', 1, 0.1408),\n",
       " (53, 'agree', 'D1', 1, 0.1408),\n",
       " (54, 'well', 'D1', 1, 0.1408),\n",
       " (55, 'potential', 'D1', 1, 0.1408),\n",
       " (56, 'flow', 'D1', 1, 0.0571),\n",
       " (57, 'theory', 'D1', 1, 0.1003),\n",
       " (58, 'empirical', 'D1', 1, 0.1408),\n",
       " (59, 'effects', 'D1', 1, 0.0795),\n",
       " (60, 'specific', 'D1', 1, 0.1408),\n",
       " (61, 'configuration', 'D1', 1, 0.1408),\n",
       " (62, 'experiment', 'D1', 1, 0.1408)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_results , nb_total_terme_per_doc , nb_total_per_collection = processing(\"D1\", \"split\", None, path, output_path=\"output\",methode = 'TPD')\n",
    "formatted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculer_relevance_BM25(query, tokenization, normalization, path, k=1.5, b=0.75, output_path=\"output\"):\n",
    "    \n",
    "        \n",
    "    descripteur , inverse_index = open_descripteur_invers(normalization , tokenization ,output_path)\n",
    "\n",
    "    # Calcul des longueurs de documents et de la taille moyenne\n",
    "    doc_lengths = {doc: sum(term_data[\"freq\"] for term_data in terms.values()) for doc, terms in descripteur.items()}\n",
    "\n",
    "    # Nbre total des terms\n",
    "    total_terms = sum(doc_lengths.values())\n",
    "    # Nombre total de documents\n",
    "    N = len(descripteur) \n",
    "    # la taille moyenne des documents \n",
    "    avdl = total_terms / N if N > 0 else 1  # Eviter division par zéro\n",
    "    \n",
    "    # Initialiser les scores de pertinence\n",
    "    relevance_dict = {doc: 0 for doc in descripteur}\n",
    "\n",
    "    # Traiter chaque terme de la requête\n",
    "    for term in query.split():\n",
    "        term = process_input(term, normalization)\n",
    "        \n",
    "        # dans le cas ou le terme n'exist pas dans le fichier inverse\n",
    "        if term not in inverse_index:\n",
    "            continue  # Ignorer les termes absents du fichier inverse\n",
    "\n",
    "        # Nombre de documents contenant le terme\n",
    "        ni = len(inverse_index[term])\n",
    "        # print(f\"nombre de document contenant {term} : {ni}\")\n",
    "\n",
    "        # Calculer l'IDF avec un seuil pour éviter des valeurs négatives ou extrêmes\n",
    "        idf = math.log10(((N - ni + 0.5) / (ni + 0.5)) ) if ni + 0.5 != 0 else 0\n",
    "        # print(idf)\n",
    "        for doc_name, data in inverse_index[term].items():\n",
    "            freq_ti_d = data[\"freq\"]  # Fréquence du terme dans le document\n",
    "            # print(f\"frequant terme {term} dans le document {doc_name} est :{freq_ti_d}\")\n",
    "            dl = doc_lengths.get(doc_name, 0)  # Taille du document d\n",
    "            \n",
    "            if dl == 0:\n",
    "                continue  # Éviter division par zéro\n",
    "\n",
    "            # Calcul du score BM25\n",
    "            # numerator = freq_ti_d * (k + 1)\n",
    "            numerator = freq_ti_d \n",
    "            denominator = freq_ti_d + (k * ((1 - b) + b * (dl / avdl)))\n",
    "            RSV = idf * (numerator / denominator)\n",
    "\n",
    "            \n",
    "            # Ajouter au score total du document\n",
    "            relevance_dict[doc_name] += RSV\n",
    "            \n",
    "    # print(relevance_dict)\n",
    "    \n",
    "    filtered_relevances = {doc: score for doc, score in relevance_dict.items() if score != 0}\n",
    "\n",
    "    # Trier les documents par pertinence décroissante\n",
    "    sorted_relevance = dict(sorted(filtered_relevances.items(), key=lambda item: item[1], reverse=True))\n",
    "    print(sorted_relevance)\n",
    "    return sorted_relevance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D4': -0.08823075947891026, 'D2': -0.09795556690944766, 'D1': -0.2728925083902616, 'D3': -0.27339867077595187, 'D6': -0.3028044304368359}\n",
      "Scores de pertinence : {'D4': -0.08823075947891026, 'D2': -0.09795556690944766, 'D1': -0.2728925083902616, 'D3': -0.27339867077595187, 'D6': -0.3028044304368359}\n"
     ]
    }
   ],
   "source": [
    "tokenization = \"Split\"  # Ou \"Regex\" selon votre choix\n",
    "normalization = \"Lancaster\"  # Ou \"Lancaster\" selon votre choix\n",
    "query = \"effect distribution \"  # Exemple de requête\n",
    "path = \"../Collections\"  # Chemin vers le dossier contenant les documents\n",
    "output_path = \"output\"\n",
    "\n",
    "\n",
    "relevance_scores = calculer_relevance_BM25(query, tokenization, normalization, path, k=1.5, b=0.75, output_path=output_path)\n",
    "\n",
    "if relevance_scores:\n",
    "    print(\"Scores de pertinence :\", relevance_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculer_relevance(query, tokenization, normalization, file_type , path ):\n",
    "    # Créer une liste des documents à partir des fichiers dans le dossier\n",
    "    docs = [doc.split('.')[0] for doc in os.listdir(path)]\n",
    "    \n",
    "\n",
    "    relevance_dict = {doc: 0 for doc in docs}\n",
    "    for term in query.split():\n",
    "        occurrence, _ ,_= processing(term, tokenization, normalization, path, output_path=\"output\",methode =file_type)\n",
    "        print(occurrence)\n",
    "        # print(\"Occurrences:\", occurrence)\n",
    "        # exemple de occurrence : [(1, 'effect', 'D1', 1, 0.0795), (2, 'effect', 'D3', 1, 0.1193), (3, 'effect', 'D6', 1, 0.1193)]\n",
    "        \n",
    "        for occ in occurrence:\n",
    "            doc_name = occ[2]  # Nom du document contenant le terme\n",
    "            poids_terme = occ[4]  # Poids du terme dans ce document\n",
    "            relevance_dict[doc_name] += poids_terme\n",
    "            \n",
    "    return relevance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'effect', 'D1', 2, 0.1326), (2, 'effect', 'D2', 1, 0.0398), (3, 'effect', 'D3', 1, 0.0995), (4, 'effect', 'D6', 3, 0.2985)]\n",
      "[]\n",
      "[(1, 'wing', 'D1', 3, 0.301), (2, 'wing', 'D6', 2, 0.301)]\n",
      "[(1, 'slipstream', 'D1', 5, 0.7042)]\n",
      "[(1, 'experiment', 'D1', 2, 0.2817)]\n",
      "[(1, 'investig', 'D1', 1, 0.1003), (2, 'investig', 'D2', 1, 0.0602)]\n",
      "[(1, 'aerodynam', 'D1', 1, 0.1003), (2, 'aerodynam', 'D6', 1, 0.1505)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'D1': 1.6201,\n",
       " 'D2': 0.1,\n",
       " 'D3': 0.0995,\n",
       " 'D4': 0,\n",
       " 'D5': 0,\n",
       " 'D6': 0.7499999999999999}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance = calculer_relevance('effect distribution wing slipstream experiment investig aerodynam','Split', 'Porter', 'DPT',path)\n",
    "relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "def calculer_relevance_cosinus(query, tokenization, normalization, file_type, path):\n",
    "    descripteur, _ = open_descripteur_invers(normalization, tokenization, output_path)\n",
    "    \n",
    "    # Calcul de la norme des vecteurs des documents (somme des poids au carré)\n",
    "    poids = {doc: sum((term_data[\"poids\"])**2 for term_data in terms.values()) for doc, terms in descripteur.items()}\n",
    "  \n",
    "    \n",
    "    # Création de la liste des documents\n",
    "    docs = [doc.split('.')[0] for doc in os.listdir(path)]\n",
    "    \n",
    "    # Initialisation des vecteurs de documents\n",
    "    doc_vectors = {doc: {} for doc in docs}\n",
    "    \n",
    "    # Remplir les vecteurs des documents\n",
    "    for term in query.split():\n",
    "        occurrence, _, _ = processing(term, tokenization, normalization, path, output_path=\"output\", methode=file_type)\n",
    "        for occ in occurrence:\n",
    "            doc_name = occ[2]  # Nom du document\n",
    "            poids_terme = occ[4]  # Poids du terme\n",
    "            doc_vectors[doc_name][term] = poids_terme\n",
    "    # doc_vectors =>   {'D1': {'effect': 0.0795, 'distribution': 0.0663}, 'D2': {}, 'D3': {'effect': 0.1193, 'distribution': 0.0995}, 'D4': {'distribution': 0.0332}, 'D5': {}, 'D6': {'effect': 0.1193, 'distribution': 0.0995}}\n",
    "    print(f\"doc vectors {doc_vectors}\")\n",
    "    \n",
    "    # Calcul de la similarité cosinus\n",
    "    relevance_dict = {}\n",
    "    for doc_name, doc_vector in doc_vectors.items():\n",
    "        # doc_name, doc_vector => 'D1': {'effect': 0.0795, 'distribution': 0.0663}       \n",
    "        dot_product = sum(doc_vector.get(term, 0) for term in query.split())  # Produit scalaire\n",
    "        norm_query = math.sqrt(len(query.split()))  # Norme de la requête (poids uniformes)\n",
    "        norm_doc = math.sqrt(poids.get(doc_name, 0))  # Norme du document\n",
    "        similarity = dot_product / (norm_query * norm_doc) if norm_query > 0 and norm_doc > 0 else 0\n",
    "        \n",
    "        relevance_dict[doc_name] = similarity\n",
    "\n",
    "    return relevance_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc vectors {'D1': {'effect': 0.0795, 'distribution': 0.0663}, 'D2': {}, 'D3': {'effect': 0.1193, 'distribution': 0.0995}, 'D4': {'distribution': 0.0332}, 'D5': {}, 'D6': {'effect': 0.1193, 'distribution': 0.0995}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'D1': 0.06900726067964397,\n",
       " 'D2': 0.0,\n",
       " 'D3': 0.12320148746796511,\n",
       " 'D4': 0.024022928446014405,\n",
       " 'D5': 0.0,\n",
       " 'D6': 0.08426610754279582}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_dict = calculer_relevance_cosinus('effect distribution','Split', 'None', 'DPT',path)\n",
    "relevance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculer_jaccard_similarity(query, tokenization, normalization, file_type, path):\n",
    "    \n",
    "    descripteur, _ = open_descripteur_invers(normalization, tokenization, output_path)\n",
    "    \n",
    "    poids = {doc: sum((term_data[\"poids\"])**2 for term_data in terms.values()) for doc, terms in descripteur.items()}\n",
    "    \n",
    "    \n",
    "    docs = [doc.split('.')[0] for doc in os.listdir(path)]\n",
    "    \n",
    "    # Initialisation des vecteurs de documents\n",
    "    doc_vectors = {doc: {} for doc in docs}\n",
    "    \n",
    "    # Remplir les vecteurs des documents\n",
    "    for term in query.split():\n",
    "        occurrence, _, _ = processing(term, tokenization, normalization, path, output_path=\"output\", methode=file_type)\n",
    "        for occ in occurrence:\n",
    "            doc_name = occ[2]  # Nom du document\n",
    "            poids_terme = occ[4]  # Poids du terme\n",
    "            doc_vectors[doc_name][term] = poids_terme\n",
    "            \n",
    "\n",
    "    # Calcul de la mesure de Jaccard pour chaque document\n",
    "    relevance_dict = {}\n",
    "    for doc_name, doc_vector in doc_vectors.items():\n",
    "        print(f\"doc_name, doc_vector : {doc_name, doc_vector}\")\n",
    "        # doc_name, doc_vector => 'D1': {'effect': 0.0795, 'distribution': 0.0663}       \n",
    "        dot_product = sum(doc_vector.get(term, 0) for term in query.split())  # Produit scalaire\n",
    "        \n",
    "        norm_query = len(query.split())  # Norme de la requête (poids uniformes)\n",
    "        norm_doc = poids.get(doc_name, 0) # Norme du document\n",
    "        union = norm_doc+norm_query-dot_product\n",
    "        similarity =  (dot_product)/(union)if union > 0 else 0\n",
    "        \n",
    "        relevance_dict[doc_name] = similarity\n",
    "\n",
    "    return relevance_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_name, doc_vector : ('D1', {'effect': 0.0795, 'distribution': 0.0663})\n",
      "doc_name, doc_vector : ('D2', {})\n",
      "doc_name, doc_vector : ('D3', {'effect': 0.1193, 'distribution': 0.0995})\n",
      "doc_name, doc_vector : ('D4', {'distribution': 0.0332})\n",
      "doc_name, doc_vector : ('D5', {})\n",
      "doc_name, doc_vector : ('D6', {'effect': 0.1193, 'distribution': 0.0995})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'D1': 0.035681015160415504,\n",
       " 'D2': 0.0,\n",
       " 'D3': 0.0651538779902336,\n",
       " 'D4': 0.011362936292260204,\n",
       " 'D5': 0.0,\n",
       " 'D6': 0.0424672942054332}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_relevance = calculer_jaccard_similarity('effect distribution', 'Split', 'None', 'DPT', path='../Collections')\n",
    "jaccard_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimental': {'D1': {'freq': 2, 'poids': 0.2817}}, 'investigation': {'D1': {'freq': 1, 'poids': 0.1408}}, 'aerodynamics': {'D1': {'freq': 1, 'poids': 0.1408}}, 'wing': {'D1': {'freq': 3, 'poids': 0.301}, 'D6': {'freq': 2, 'poids': 0.301}}, 'slipstream': {'D1': {'freq': 5, 'poids': 0.7042}}, '.': {'D1': {'freq': 6, 'poids': 0.301}, 'D2': {'freq': 10, 'poids': 0.301}, 'D3': {'freq': 4, 'poids': 0.301}, 'D4': {'freq': 12, 'poids': 0.301}, 'D5': {'freq': 12, 'poids': 0.301}, 'D6': {'freq': 4, 'poids': 0.301}}, 'study': {'D1': {'freq': 1, 'poids': 0.1003}, 'D2': {'freq': 2, 'poids': 0.1204}}, 'propeller': {'D1': {'freq': 1, 'poids': 0.1408}}, 'made': {'D1': {'freq': 2, 'poids': 0.2007}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'order': {'D1': {'freq': 1, 'poids': 0.1408}}, 'determine': {'D1': {'freq': 1, 'poids': 0.1408}}, 'spanwise': {'D1': {'freq': 1, 'poids': 0.1408}}, 'distribution': {'D1': {'freq': 1, 'poids': 0.0663}, 'D3': {'freq': 1, 'poids': 0.0995}, 'D4': {'freq': 1, 'poids': 0.0332}, 'D6': {'freq': 1, 'poids': 0.0995}}, 'lift': {'D1': {'freq': 3, 'poids': 0.4225}}, 'increase': {'D1': {'freq': 1, 'poids': 0.1408}}, 'due': {'D1': {'freq': 2, 'poids': 0.2817}}, 'different': {'D1': {'freq': 3, 'poids': 0.301}, 'D2': {'freq': 1, 'poids': 0.0602}}, 'angles': {'D1': {'freq': 1, 'poids': 0.1408}}, 'attack': {'D1': {'freq': 1, 'poids': 0.1408}}, 'free': {'D1': {'freq': 1, 'poids': 0.1003}, 'D2': {'freq': 3, 'poids': 0.1806}}, 'stream': {'D1': {'freq': 1, 'poids': 0.1003}, 'D2': {'freq': 3, 'poids': 0.1806}}, 'velocity': {'D1': {'freq': 1, 'poids': 0.1003}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'ratios': {'D1': {'freq': 1, 'poids': 0.1408}}, 'results': {'D1': {'freq': 1, 'poids': 0.1003}, 'D6': {'freq': 2, 'poids': 0.301}}, 'intended': {'D1': {'freq': 1, 'poids': 0.1408}}, 'part': {'D1': {'freq': 2, 'poids': 0.2817}}, 'evaluation': {'D1': {'freq': 2, 'poids': 0.2817}}, 'basis': {'D1': {'freq': 1, 'poids': 0.1003}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'theoretical': {'D1': {'freq': 1, 'poids': 0.1408}}, 'treatments': {'D1': {'freq': 1, 'poids': 0.1408}}, 'problem': {'D1': {'freq': 1, 'poids': 0.0663}, 'D2': {'freq': 4, 'poids': 0.1592}, 'D3': {'freq': 1, 'poids': 0.0995}, 'D4': {'freq': 2, 'poids': 0.0663}}, 'comparative': {'D1': {'freq': 1, 'poids': 0.1408}}, 'span': {'D1': {'freq': 1, 'poids': 0.1408}}, 'loading': {'D1': {'freq': 1, 'poids': 0.1408}}, 'curves,': {'D1': {'freq': 1, 'poids': 0.1408}}, 'together': {'D1': {'freq': 1, 'poids': 0.1408}}, 'supporting': {'D1': {'freq': 1, 'poids': 0.1408}}, 'evidence,': {'D1': {'freq': 1, 'poids': 0.1408}}, 'showed': {'D1': {'freq': 1, 'poids': 0.1408}}, 'substantial': {'D1': {'freq': 1, 'poids': 0.1408}}, 'increment': {'D1': {'freq': 1, 'poids': 0.1408}}, 'produced': {'D1': {'freq': 1, 'poids': 0.1408}}, '/destalling/': {'D1': {'freq': 1, 'poids': 0.1408}}, 'boundary-layer-control': {'D1': {'freq': 1, 'poids': 0.1408}}, 'effect': {'D1': {'freq': 1, 'poids': 0.0795}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'integrated': {'D1': {'freq': 1, 'poids': 0.1003}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'remaining': {'D1': {'freq': 1, 'poids': 0.1408}}, 'increment,': {'D1': {'freq': 1, 'poids': 0.1408}}, 'subtracting': {'D1': {'freq': 1, 'poids': 0.1408}}, 'destalling': {'D1': {'freq': 2, 'poids': 0.2817}}, 'lift,': {'D1': {'freq': 1, 'poids': 0.1003}, 'D6': {'freq': 2, 'poids': 0.301}}, 'found': {'D1': {'freq': 1, 'poids': 0.1408}}, 'agree': {'D1': {'freq': 1, 'poids': 0.1408}}, 'well': {'D1': {'freq': 1, 'poids': 0.1408}}, 'potential': {'D1': {'freq': 1, 'poids': 0.1408}}, 'flow': {'D1': {'freq': 1, 'poids': 0.0571}, 'D2': {'freq': 6, 'poids': 0.2055}, 'D3': {'freq': 3, 'poids': 0.2568}, 'D4': {'freq': 4, 'poids': 0.1141}, 'D5': {'freq': 5, 'poids': 0.1427}}, 'theory': {'D1': {'freq': 1, 'poids': 0.1003}, 'D5': {'freq': 4, 'poids': 0.2007}}, 'empirical': {'D1': {'freq': 1, 'poids': 0.1408}}, 'effects': {'D1': {'freq': 1, 'poids': 0.0795}, 'D2': {'freq': 1, 'poids': 0.0477}, 'D6': {'freq': 2, 'poids': 0.2386}}, 'specific': {'D1': {'freq': 1, 'poids': 0.1408}}, 'configuration': {'D1': {'freq': 1, 'poids': 0.1408}}, 'experiment': {'D1': {'freq': 1, 'poids': 0.1408}}, 'simple': {'D2': {'freq': 2, 'poids': 0.1204}, 'D5': {'freq': 2, 'poids': 0.1003}}, 'shear': {'D2': {'freq': 2, 'poids': 0.1204}, 'D3': {'freq': 2, 'poids': 0.301}}, 'past': {'D2': {'freq': 4, 'poids': 0.338}}, 'flat': {'D2': {'freq': 3, 'poids': 0.1806}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'plate': {'D2': {'freq': 3, 'poids': 0.1806}, 'D3': {'freq': 2, 'poids': 0.301}}, 'incompressible': {'D2': {'freq': 2, 'poids': 0.1204}, 'D3': {'freq': 2, 'poids': 0.301}}, 'fluid': {'D2': {'freq': 2, 'poids': 0.1204}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'small': {'D2': {'freq': 2, 'poids': 0.169}}, 'viscosity': {'D2': {'freq': 2, 'poids': 0.1204}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'high-speed': {'D2': {'freq': 1, 'poids': 0.0845}}, 'viscous': {'D2': {'freq': 2, 'poids': 0.169}}, 'two-dimensional': {'D2': {'freq': 2, 'poids': 0.0954}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'body': {'D2': {'freq': 2, 'poids': 0.1204}, 'D4': {'freq': 3, 'poids': 0.1505}}, 'usually': {'D2': {'freq': 1, 'poids': 0.0602}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'necessary': {'D2': {'freq': 1, 'poids': 0.0845}}, 'consider': {'D2': {'freq': 1, 'poids': 0.0845}}, 'curved': {'D2': {'freq': 1, 'poids': 0.0845}}, 'shock': {'D2': {'freq': 2, 'poids': 0.1204}, 'D5': {'freq': 5, 'poids': 0.2509}}, 'wave': {'D2': {'freq': 2, 'poids': 0.1204}, 'D5': {'freq': 2, 'poids': 0.1003}}, 'emitting': {'D2': {'freq': 1, 'poids': 0.0845}}, 'nose': {'D2': {'freq': 1, 'poids': 0.0845}}, 'leading': {'D2': {'freq': 1, 'poids': 0.0845}}, 'edge': {'D2': {'freq': 1, 'poids': 0.0845}}, 'consequently,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'exists': {'D2': {'freq': 1, 'poids': 0.0845}}, 'inviscid': {'D2': {'freq': 3, 'poids': 0.2535}}, 'rotational': {'D2': {'freq': 2, 'poids': 0.169}}, 'region': {'D2': {'freq': 1, 'poids': 0.0602}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'boundary': {'D2': {'freq': 2, 'poids': 0.0954}, 'D3': {'freq': 3, 'poids': 0.3578}, 'D6': {'freq': 3, 'poids': 0.3578}}, 'layer': {'D2': {'freq': 2, 'poids': 0.0796}, 'D3': {'freq': 4, 'poids': 0.3979}, 'D5': {'freq': 2, 'poids': 0.0663}, 'D6': {'freq': 3, 'poids': 0.2985}}, 'situation': {'D2': {'freq': 2, 'poids': 0.169}}, 'arises,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'instance,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'hypersonic': {'D2': {'freq': 2, 'poids': 0.1204}, 'D5': {'freq': 3, 'poids': 0.1505}}, 'somewhat': {'D2': {'freq': 1, 'poids': 0.0845}}, \"prandtl's\": {'D2': {'freq': 2, 'poids': 0.169}}, 'classical': {'D2': {'freq': 1, 'poids': 0.0845}}, 'boundary-layer': {'D2': {'freq': 3, 'poids': 0.1431}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D6': {'freq': 3, 'poids': 0.3578}}, 'original': {'D2': {'freq': 1, 'poids': 0.0845}}, 'outside': {'D2': {'freq': 1, 'poids': 0.0845}}, 'irrotational': {'D2': {'freq': 1, 'poids': 0.0845}}, 'must': {'D2': {'freq': 1, 'poids': 0.0845}}, 'considered': {'D2': {'freq': 1, 'poids': 0.0477}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D5': {'freq': 1, 'poids': 0.0398}}, 'possible': {'D2': {'freq': 1, 'poids': 0.0602}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'vorticity': {'D2': {'freq': 2, 'poids': 0.1204}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'recently': {'D2': {'freq': 1, 'poids': 0.0845}}, 'discussed': {'D2': {'freq': 1, 'poids': 0.0845}}, 'ferri': {'D2': {'freq': 1, 'poids': 0.0845}}, 'libby': {'D2': {'freq': 1, 'poids': 0.0845}}, 'present': {'D2': {'freq': 1, 'poids': 0.0602}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'paper,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'investigated': {'D2': {'freq': 1, 'poids': 0.0845}}, 'shown': {'D2': {'freq': 1, 'poids': 0.0845}}, 'treated': {'D2': {'freq': 1, 'poids': 0.0602}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'approximation,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'novel': {'D2': {'freq': 1, 'poids': 0.0845}}, 'feature': {'D2': {'freq': 1, 'poids': 0.0845}}, 'constant': {'D2': {'freq': 1, 'poids': 0.0845}}, 'discussion': {'D2': {'freq': 1, 'poids': 0.0845}}, 'restricted': {'D2': {'freq': 1, 'poids': 0.0845}}, 'steady': {'D2': {'freq': 1, 'poids': 0.0602}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'approximate': {'D3': {'freq': 1, 'poids': 0.2113}}, 'solutions': {'D3': {'freq': 2, 'poids': 0.301}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'laminar': {'D3': {'freq': 1, 'poids': 0.2113}}, 'equations': {'D3': {'freq': 1, 'poids': 0.1505}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'boundary-': {'D3': {'freq': 1, 'poids': 0.2113}}, 'thickness,': {'D3': {'freq': 1, 'poids': 0.2113}}, 'skin': {'D3': {'freq': 1, 'poids': 0.2113}}, 'friction,': {'D3': {'freq': 1, 'poids': 0.2113}}, 'obtained': {'D3': {'freq': 1, 'poids': 0.2113}}, 'karman-pohlhausen': {'D3': {'freq': 1, 'poids': 0.2113}}, 'technique': {'D3': {'freq': 1, 'poids': 0.2113}}, 'comparison': {'D3': {'freq': 1, 'poids': 0.2113}}, 'uniform': {'D3': {'freq': 1, 'poids': 0.1505}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'also': {'D3': {'freq': 1, 'poids': 0.2113}}, 'show': {'D3': {'freq': 1, 'poids': 0.1505}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'exact': {'D4': {'freq': 2, 'poids': 0.1408}}, 'solution': {'D4': {'freq': 3, 'poids': 0.2113}}, 'neumann': {'D4': {'freq': 2, 'poids': 0.1408}}, 'calculation': {'D4': {'freq': 2, 'poids': 0.1003}, 'D6': {'freq': 2, 'poids': 0.301}}, 'non-': {'D4': {'freq': 1, 'poids': 0.0704}}, 'circulatory': {'D4': {'freq': 1, 'poids': 0.0704}}, 'plane': {'D4': {'freq': 2, 'poids': 0.1408}}, 'axially': {'D4': {'freq': 1, 'poids': 0.0704}}, 'symmetric': {'D4': {'freq': 1, 'poids': 0.0704}}, 'flows': {'D4': {'freq': 3, 'poids': 0.2113}}, 'within': {'D4': {'freq': 2, 'poids': 0.1408}}, 'arbitrary': {'D4': {'freq': 1, 'poids': 0.0704}}, 'boundaries': {'D4': {'freq': 2, 'poids': 0.1408}}, 'general': {'D4': {'freq': 1, 'poids': 0.0704}}, 'method': {'D4': {'freq': 4, 'poids': 0.2817}}, 'solving': {'D4': {'freq': 1, 'poids': 0.0704}}, 'second': {'D4': {'freq': 2, 'poids': 0.1408}}, 'boundary-value': {'D4': {'freq': 1, 'poids': 0.0704}}, 'developed': {'D4': {'freq': 1, 'poids': 0.0502}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'applied': {'D4': {'freq': 1, 'poids': 0.0704}}, 'low-speed': {'D4': {'freq': 1, 'poids': 0.0704}}, 'bodies': {'D4': {'freq': 2, 'poids': 0.1003}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'almost': {'D4': {'freq': 1, 'poids': 0.0704}}, 'shape,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'provided': {'D4': {'freq': 1, 'poids': 0.0704}}, 'either': {'D4': {'freq': 1, 'poids': 0.0704}}, 'axial': {'D4': {'freq': 1, 'poids': 0.0502}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'symmetry': {'D4': {'freq': 1, 'poids': 0.0704}}, 'solid-body,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'inlet,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'purely': {'D4': {'freq': 1, 'poids': 0.0704}}, 'internal': {'D4': {'freq': 1, 'poids': 0.0704}}, 'problems': {'D4': {'freq': 2, 'poids': 0.1408}}, 'solved': {'D4': {'freq': 2, 'poids': 0.1408}}, 'capable': {'D4': {'freq': 1, 'poids': 0.0704}}, 'dealing': {'D4': {'freq': 1, 'poids': 0.0704}}, 'several': {'D4': {'freq': 1, 'poids': 0.0704}}, 'presence': {'D4': {'freq': 1, 'poids': 0.0704}}, 'one': {'D4': {'freq': 1, 'poids': 0.0704}}, 'another,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'consequently': {'D4': {'freq': 1, 'poids': 0.0704}}, 'interference': {'D4': {'freq': 1, 'poids': 0.0704}}, 'ease': {'D4': {'freq': 1, 'poids': 0.0704}}, 'need': {'D4': {'freq': 1, 'poids': 0.0704}}, 'solid,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'is,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'involving': {'D4': {'freq': 1, 'poids': 0.0704}}, 'area': {'D4': {'freq': 1, 'poids': 0.0704}}, 'suction': {'D4': {'freq': 1, 'poids': 0.0704}}, 'calculated': {'D4': {'freq': 1, 'poids': 0.0398}, 'D5': {'freq': 1, 'poids': 0.0398}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'velocities': {'D4': {'freq': 1, 'poids': 0.0704}}, 'computed': {'D4': {'freq': 1, 'poids': 0.0704}}, 'points': {'D4': {'freq': 3, 'poids': 0.2113}}, 'surface': {'D4': {'freq': 2, 'poids': 0.1003}, 'D5': {'freq': 3, 'poids': 0.1505}}, 'entire': {'D4': {'freq': 1, 'poids': 0.0704}}, 'field': {'D4': {'freq': 1, 'poids': 0.0704}}, 'source': {'D4': {'freq': 1, 'poids': 0.0704}}, 'used': {'D4': {'freq': 2, 'poids': 0.1003}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'leads': {'D4': {'freq': 1, 'poids': 0.0704}}, 'fredholm': {'D4': {'freq': 1, 'poids': 0.0704}}, 'integral': {'D4': {'freq': 1, 'poids': 0.0704}}, 'equation': {'D4': {'freq': 1, 'poids': 0.0502}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'kind,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'set': {'D4': {'freq': 1, 'poids': 0.0704}}, 'linear': {'D4': {'freq': 1, 'poids': 0.0704}}, 'algebraic': {'D4': {'freq': 1, 'poids': 0.0704}}, 'equations,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'modified': {'D4': {'freq': 1, 'poids': 0.0704}}, 'seidel': {'D4': {'freq': 1, 'poids': 0.0704}}, 'time': {'D4': {'freq': 1, 'poids': 0.0704}}, 'programed': {'D4': {'freq': 1, 'poids': 0.0704}}, 'ibm': {'D4': {'freq': 1, 'poids': 0.0704}}, '704': {'D4': {'freq': 1, 'poids': 0.0704}}, 'edpm': {'D4': {'freq': 1, 'poids': 0.0704}}, 'solve': {'D4': {'freq': 1, 'poids': 0.0704}}, 'previously': {'D4': {'freq': 1, 'poids': 0.0704}}, 'mentioned': {'D4': {'freq': 1, 'poids': 0.0704}}, 'characteristics': {'D4': {'freq': 1, 'poids': 0.0502}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'whose': {'D4': {'freq': 1, 'poids': 0.0704}}, 'profile': {'D4': {'freq': 1, 'poids': 0.0704}}, 'defined': {'D4': {'freq': 1, 'poids': 0.0704}}, 'satisfactorily': {'D4': {'freq': 1, 'poids': 0.0704}}, '300': {'D4': {'freq': 1, 'poids': 0.0704}}, 'coordinate': {'D4': {'freq': 1, 'poids': 0.0704}}, 'number': {'D4': {'freq': 2, 'poids': 0.1003}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'presented,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'scope': {'D4': {'freq': 1, 'poids': 0.0704}}, 'accuracy': {'D4': {'freq': 1, 'poids': 0.0704}}, 'computations': {'D4': {'freq': 1, 'poids': 0.0704}}, 'require': {'D4': {'freq': 1, 'poids': 0.0704}}, 'three': {'D4': {'freq': 1, 'poids': 0.0704}}, 'minutes': {'D4': {'freq': 1, 'poids': 0.0704}}, 'two': {'D4': {'freq': 1, 'poids': 0.0502}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'hours,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'depending': {'D4': {'freq': 1, 'poids': 0.0704}}, 'upon': {'D4': {'freq': 1, 'poids': 0.0704}}, 'shape': {'D4': {'freq': 1, 'poids': 0.0704}}, 'define': {'D4': {'freq': 1, 'poids': 0.0704}}, 'secondary': {'D5': {'freq': 2, 'poids': 0.1408}}, 'fields': {'D5': {'freq': 1, 'poids': 0.0704}}, 'embedded': {'D5': {'freq': 3, 'poids': 0.2113}}, 'layers': {'D5': {'freq': 1, 'poids': 0.0704}}, 'ramp': {'D5': {'freq': 2, 'poids': 0.1408}}, 'compression': {'D5': {'freq': 2, 'poids': 0.1408}}, 'located': {'D5': {'freq': 1, 'poids': 0.0704}}, 'locally': {'D5': {'freq': 1, 'poids': 0.0704}}, 'supersonic': {'D5': {'freq': 1, 'poids': 0.0704}}, 'behind': {'D5': {'freq': 1, 'poids': 0.0704}}, 'bow': {'D5': {'freq': 2, 'poids': 0.1408}}, 'wave,': {'D5': {'freq': 2, 'poids': 0.1408}}, 'generates': {'D5': {'freq': 1, 'poids': 0.0704}}, 'disturbance': {'D5': {'freq': 1, 'poids': 0.0704}}, 'may': {'D5': {'freq': 1, 'poids': 0.0704}}, 'viewed': {'D5': {'freq': 1, 'poids': 0.0704}}, 'newtonian': {'D5': {'freq': 7, 'poids': 0.493}}, 'impact': {'D5': {'freq': 1, 'poids': 0.0704}}, 'thin': {'D5': {'freq': 1, 'poids': 0.0704}}, 'examination': {'D5': {'freq': 1, 'poids': 0.0704}}, 'applicability': {'D5': {'freq': 1, 'poids': 0.0704}}, 'cones': {'D5': {'freq': 1, 'poids': 0.0704}}, 'wedges': {'D5': {'freq': 1, 'poids': 0.0704}}, 'streams': {'D5': {'freq': 1, 'poids': 0.0704}}, 'suggests': {'D5': {'freq': 1, 'poids': 0.0704}}, 'expected': {'D5': {'freq': 1, 'poids': 0.0704}}, 'give': {'D5': {'freq': 1, 'poids': 0.0502}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'useful': {'D5': {'freq': 1, 'poids': 0.0704}}, 'approximation': {'D5': {'freq': 1, 'poids': 0.0704}}, 'pressures': {'D5': {'freq': 4, 'poids': 0.2817}}, 'pressure': {'D5': {'freq': 6, 'poids': 0.301}, 'D6': {'freq': 4, 'poids': 0.6021}}, 'based': {'D5': {'freq': 1, 'poids': 0.0704}}, 'concept': {'D5': {'freq': 1, 'poids': 0.0704}}, 'predicts': {'D5': {'freq': 1, 'poids': 0.0704}}, 'interesting': {'D5': {'freq': 1, 'poids': 0.0704}}, 'things': {'D5': {'freq': 1, 'poids': 0.0704}}, '..': {'D5': {'freq': 1, 'poids': 0.0704}}, 'first,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'differ': {'D5': {'freq': 2, 'poids': 0.1408}}, 'factors': {'D5': {'freq': 1, 'poids': 0.0704}}, '1.5': {'D5': {'freq': 1, 'poids': 0.0704}}, '3,.': {'D5': {'freq': 1, 'poids': 0.0704}}, 'example,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'flare': {'D5': {'freq': 4, 'poids': 0.2817}}, 'stabilizers': {'D5': {'freq': 1, 'poids': 0.0704}}, 'blunt-nosed': {'D5': {'freq': 2, 'poids': 0.1408}}, 'revolution,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'lower': {'D5': {'freq': 1, 'poids': 0.0704}}, 'diminish': {'D5': {'freq': 1, 'poids': 0.0704}}, 'increasing': {'D5': {'freq': 1, 'poids': 0.0704}}, 'flight': {'D5': {'freq': 1, 'poids': 0.0704}}, 'speed': {'D5': {'freq': 2, 'poids': 0.1003}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'range': {'D5': {'freq': 1, 'poids': 0.0704}}, 'vary': {'D5': {'freq': 2, 'poids': 0.1408}}, 'result': {'D5': {'freq': 1, 'poids': 0.0704}}, 'nonuniformity': {'D5': {'freq': 1, 'poids': 0.0704}}, 'incident': {'D5': {'freq': 1, 'poids': 0.0704}}, 'stream,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'depend': {'D5': {'freq': 1, 'poids': 0.0704}}, 'location': {'D5': {'freq': 1, 'poids': 0.0704}}, 'case': {'D5': {'freq': 2, 'poids': 0.1408}}, 'flap': {'D5': {'freq': 2, 'poids': 0.1408}}, 'mounted': {'D5': {'freq': 1, 'poids': 0.0704}}, 'large-angled': {'D5': {'freq': 1, 'poids': 0.0704}}, 'cone,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'coefficients': {'D5': {'freq': 1, 'poids': 0.0704}}, '1': {'D5': {'freq': 1, 'poids': 0.0704}}, '5': {'D5': {'freq': 2, 'poids': 0.1408}}, 'variable': {'D5': {'freq': 1, 'poids': 0.0704}}, 'entropy': {'D5': {'freq': 1, 'poids': 0.0704}}, 'coefficient': {'D5': {'freq': 2, 'poids': 0.1408}}, 'greater': {'D5': {'freq': 1, 'poids': 0.0704}}, 'maximum': {'D5': {'freq': 1, 'poids': 0.0704}}, 'occur': {'D5': {'freq': 1, 'poids': 0.0704}}, 'process': {'D5': {'freq': 2, 'poids': 0.1408}}, 'efficient': {'D5': {'freq': 1, 'poids': 0.0704}}, 'single': {'D5': {'freq': 1, 'poids': 0.0704}}, 'areas': {'D5': {'freq': 1, 'poids': 0.0704}}, 'protrude': {'D5': {'freq': 1, 'poids': 0.0704}}, 'main': {'D5': {'freq': 1, 'poids': 0.0704}}, 'revert': {'D5': {'freq': 1, 'poids': 0.0704}}, 'value': {'D5': {'freq': 1, 'poids': 0.0704}}, 'initial': {'D5': {'freq': 1, 'poids': 0.0704}}, 'slopes': {'D5': {'freq': 1, 'poids': 0.0704}}, 'normal-force': {'D5': {'freq': 1, 'poids': 0.0704}}, 'pitching-moment': {'D5': {'freq': 1, 'poids': 0.0704}}, 'curves': {'D5': {'freq': 1, 'poids': 0.0704}}, 'stabilizer': {'D5': {'freq': 1, 'poids': 0.0704}}, 'simplest': {'D5': {'freq': 1, 'poids': 0.0704}}, 'conventional': {'D5': {'freq': 1, 'poids': 0.0704}}, 'ratio': {'D5': {'freq': 2, 'poids': 0.1408}}, 'local': {'D5': {'freq': 1, 'poids': 0.0704}}, 'dynamic': {'D5': {'freq': 2, 'poids': 0.1408}}, 'free-stream': {'D5': {'freq': 1, 'poids': 0.0704}}, 'takes': {'D5': {'freq': 1, 'poids': 0.0704}}, 'values': {'D5': {'freq': 1, 'poids': 0.0704}}, 'low': {'D5': {'freq': 1, 'poids': 0.0502}, 'D6': {'freq': 1, 'poids': 0.1505}}, '0.1': {'D5': {'freq': 1, 'poids': 0.0704}}, 'examples': {'D5': {'freq': 1, 'poids': 0.0704}}, 'measurements': {'D6': {'freq': 2, 'poids': 0.4225}}, 'dimensional': {'D6': {'freq': 1, 'poids': 0.2113}}, 'given': {'D6': {'freq': 1, 'poids': 0.2113}}, 'traverses': {'D6': {'freq': 1, 'poids': 0.2113}}, '10': {'D6': {'freq': 1, 'poids': 0.2113}}, 'per': {'D6': {'freq': 1, 'poids': 0.2113}}, 'cent': {'D6': {'freq': 1, 'poids': 0.2113}}, 'rae': {'D6': {'freq': 1, 'poids': 0.2113}}, '101': {'D6': {'freq': 1, 'poids': 0.2113}}, 'section': {'D6': {'freq': 1, 'poids': 0.2113}}, 'reynolds': {'D6': {'freq': 1, 'poids': 0.2113}}, 'numbers': {'D6': {'freq': 1, 'poids': 0.2113}}, '1.6x10': {'D6': {'freq': 1, 'poids': 0.2113}}, '3.2x10': {'D6': {'freq': 1, 'poids': 0.2113}}, 'drag': {'D6': {'freq': 2, 'poids': 0.4225}}, 'aerodynamic-centre': {'D6': {'freq': 1, 'poids': 0.2113}}, 'characteristics,': {'D6': {'freq': 1, 'poids': 0.2113}}, 'check': {'D6': {'freq': 1, 'poids': 0.2113}}, 'methods': {'D6': {'freq': 1, 'poids': 0.2113}}, 'growth': {'D6': {'freq': 1, 'poids': 0.2113}}, 'turbulent': {'D6': {'freq': 1, 'poids': 0.2113}}, 'known': {'D6': {'freq': 2, 'poids': 0.4225}}, 'concluded': {'D6': {'freq': 1, 'poids': 0.2113}}, 'still': {'D6': {'freq': 1, 'poids': 0.2113}}, 'needs': {'D6': {'freq': 1, 'poids': 0.2113}}, 'little': {'D6': {'freq': 1, 'poids': 0.2113}}, 'refinement': {'D6': {'freq': 1, 'poids': 0.2113}}, 'accurate': {'D6': {'freq': 1, 'poids': 0.2113}}, 'enough': {'D6': {'freq': 1, 'poids': 0.2113}}, 'predict': {'D6': {'freq': 1, 'poids': 0.2113}}, 'distribution,': {'D6': {'freq': 1, 'poids': 0.2113}}, 'aerodynamic': {'D6': {'freq': 1, 'poids': 0.2113}}, 'center,.but': {'D6': {'freq': 1, 'poids': 0.2113}}, 'actual': {'D6': {'freq': 1, 'poids': 0.2113}}}\n",
      "{'experimental': {'D1'}, 'investigation': {'D1'}, 'aerodynamics': {'D1'}, 'wing': {'D1', 'D6'}, 'slipstream': {'D1'}, '.': {'D1', 'D6', 'D3', 'D5', 'D4', 'D2'}, 'study': {'D1', 'D2'}, 'propeller': {'D1'}, 'made': {'D3', 'D1'}, 'order': {'D1'}, 'determine': {'D1'}, 'spanwise': {'D1'}, 'distribution': {'D3', 'D4', 'D1', 'D6'}, 'lift': {'D1'}, 'increase': {'D1'}, 'due': {'D1'}, 'different': {'D1', 'D2'}, 'angles': {'D1'}, 'attack': {'D1'}, 'free': {'D1', 'D2'}, 'stream': {'D1', 'D2'}, 'velocity': {'D3', 'D1'}, 'ratios': {'D1'}, 'results': {'D1', 'D6'}, 'intended': {'D1'}, 'part': {'D1'}, 'evaluation': {'D1'}, 'basis': {'D4', 'D1'}, 'theoretical': {'D1'}, 'treatments': {'D1'}, 'problem': {'D3', 'D4', 'D1', 'D2'}, 'comparative': {'D1'}, 'span': {'D1'}, 'loading': {'D1'}, 'curves,': {'D1'}, 'together': {'D1'}, 'supporting': {'D1'}, 'evidence,': {'D1'}, 'showed': {'D1'}, 'substantial': {'D1'}, 'increment': {'D1'}, 'produced': {'D1'}, '/destalling/': {'D1'}, 'boundary-layer-control': {'D1'}, 'effect': {'D3', 'D1', 'D6'}, 'integrated': {'D1', 'D6'}, 'remaining': {'D1'}, 'increment,': {'D1'}, 'subtracting': {'D1'}, 'destalling': {'D1'}, 'lift,': {'D1', 'D6'}, 'found': {'D1'}, 'agree': {'D1'}, 'well': {'D1'}, 'potential': {'D1'}, 'flow': {'D1', 'D3', 'D5', 'D4', 'D2'}, 'theory': {'D5', 'D1'}, 'empirical': {'D1'}, 'effects': {'D1', 'D6', 'D2'}, 'specific': {'D1'}, 'configuration': {'D1'}, 'experiment': {'D1'}, 'simple': {'D5', 'D2'}, 'shear': {'D3', 'D2'}, 'past': {'D2'}, 'flat': {'D3', 'D2'}, 'plate': {'D3', 'D2'}, 'incompressible': {'D3', 'D2'}, 'fluid': {'D3', 'D2'}, 'small': {'D2'}, 'viscosity': {'D6', 'D2'}, 'high-speed': {'D2'}, 'viscous': {'D2'}, 'two-dimensional': {'D3', 'D6', 'D2'}, 'body': {'D4', 'D2'}, 'usually': {'D4', 'D2'}, 'necessary': {'D2'}, 'consider': {'D2'}, 'curved': {'D2'}, 'shock': {'D5', 'D2'}, 'wave': {'D5', 'D2'}, 'emitting': {'D2'}, 'nose': {'D2'}, 'leading': {'D2'}, 'edge': {'D2'}, 'consequently,': {'D2'}, 'exists': {'D2'}, 'inviscid': {'D2'}, 'rotational': {'D2'}, 'region': {'D5', 'D2'}, 'boundary': {'D3', 'D6', 'D2'}, 'layer': {'D3', 'D5', 'D6', 'D2'}, 'situation': {'D2'}, 'arises,': {'D2'}, 'instance,': {'D2'}, 'hypersonic': {'D5', 'D2'}, 'somewhat': {'D2'}, \"prandtl's\": {'D2'}, 'classical': {'D2'}, 'boundary-layer': {'D3', 'D6', 'D2'}, 'original': {'D2'}, 'outside': {'D2'}, 'irrotational': {'D2'}, 'must': {'D2'}, 'considered': {'D3', 'D5', 'D2'}, 'possible': {'D5', 'D2'}, 'vorticity': {'D3', 'D2'}, 'recently': {'D2'}, 'discussed': {'D2'}, 'ferri': {'D2'}, 'libby': {'D2'}, 'present': {'D4', 'D2'}, 'paper,': {'D2'}, 'investigated': {'D2'}, 'shown': {'D2'}, 'treated': {'D4', 'D2'}, 'approximation,': {'D2'}, 'novel': {'D2'}, 'feature': {'D2'}, 'constant': {'D2'}, 'discussion': {'D2'}, 'restricted': {'D2'}, 'steady': {'D3', 'D2'}, 'approximate': {'D3'}, 'solutions': {'D3', 'D4'}, 'laminar': {'D3'}, 'equations': {'D3', 'D5'}, 'boundary-': {'D3'}, 'thickness,': {'D3'}, 'skin': {'D3'}, 'friction,': {'D3'}, 'obtained': {'D3'}, 'karman-pohlhausen': {'D3'}, 'technique': {'D3'}, 'comparison': {'D3'}, 'uniform': {'D3', 'D5'}, 'also': {'D3'}, 'show': {'D3', 'D4'}, 'exact': {'D4'}, 'solution': {'D4'}, 'neumann': {'D4'}, 'calculation': {'D4', 'D6'}, 'non-': {'D4'}, 'circulatory': {'D4'}, 'plane': {'D4'}, 'axially': {'D4'}, 'symmetric': {'D4'}, 'flows': {'D4'}, 'within': {'D4'}, 'arbitrary': {'D4'}, 'boundaries': {'D4'}, 'general': {'D4'}, 'method': {'D4'}, 'solving': {'D4'}, 'second': {'D4'}, 'boundary-value': {'D4'}, 'developed': {'D5', 'D4'}, 'applied': {'D4'}, 'low-speed': {'D4'}, 'bodies': {'D5', 'D4'}, 'almost': {'D4'}, 'shape,': {'D4'}, 'provided': {'D4'}, 'either': {'D4'}, 'axial': {'D5', 'D4'}, 'symmetry': {'D4'}, 'solid-body,': {'D4'}, 'inlet,': {'D4'}, 'purely': {'D4'}, 'internal': {'D4'}, 'problems': {'D4'}, 'solved': {'D4'}, 'capable': {'D4'}, 'dealing': {'D4'}, 'several': {'D4'}, 'presence': {'D4'}, 'one': {'D4'}, 'another,': {'D4'}, 'consequently': {'D4'}, 'interference': {'D4'}, 'ease': {'D4'}, 'need': {'D4'}, 'solid,': {'D4'}, 'is,': {'D4'}, 'involving': {'D4'}, 'area': {'D4'}, 'suction': {'D4'}, 'calculated': {'D5', 'D4', 'D6'}, 'velocities': {'D4'}, 'computed': {'D4'}, 'points': {'D4'}, 'surface': {'D5', 'D4'}, 'entire': {'D4'}, 'field': {'D4'}, 'source': {'D4'}, 'used': {'D4', 'D6'}, 'leads': {'D4'}, 'fredholm': {'D4'}, 'integral': {'D4'}, 'equation': {'D5', 'D4'}, 'kind,': {'D4'}, 'set': {'D4'}, 'linear': {'D4'}, 'algebraic': {'D4'}, 'equations,': {'D4'}, 'modified': {'D4'}, 'seidel': {'D4'}, 'time': {'D4'}, 'programed': {'D4'}, 'ibm': {'D4'}, '704': {'D4'}, 'edpm': {'D4'}, 'solve': {'D4'}, 'previously': {'D4'}, 'mentioned': {'D4'}, 'characteristics': {'D4', 'D6'}, 'whose': {'D4'}, 'profile': {'D4'}, 'defined': {'D4'}, 'satisfactorily': {'D4'}, '300': {'D4'}, 'coordinate': {'D4'}, 'number': {'D5', 'D4'}, 'presented,': {'D4'}, 'scope': {'D4'}, 'accuracy': {'D4'}, 'computations': {'D4'}, 'require': {'D4'}, 'three': {'D4'}, 'minutes': {'D4'}, 'two': {'D4', 'D6'}, 'hours,': {'D4'}, 'depending': {'D4'}, 'upon': {'D4'}, 'shape': {'D4'}, 'define': {'D4'}, 'secondary': {'D5'}, 'fields': {'D5'}, 'embedded': {'D5'}, 'layers': {'D5'}, 'ramp': {'D5'}, 'compression': {'D5'}, 'located': {'D5'}, 'locally': {'D5'}, 'supersonic': {'D5'}, 'behind': {'D5'}, 'bow': {'D5'}, 'wave,': {'D5'}, 'generates': {'D5'}, 'disturbance': {'D5'}, 'may': {'D5'}, 'viewed': {'D5'}, 'newtonian': {'D5'}, 'impact': {'D5'}, 'thin': {'D5'}, 'examination': {'D5'}, 'applicability': {'D5'}, 'cones': {'D5'}, 'wedges': {'D5'}, 'streams': {'D5'}, 'suggests': {'D5'}, 'expected': {'D5'}, 'give': {'D5', 'D6'}, 'useful': {'D5'}, 'approximation': {'D5'}, 'pressures': {'D5'}, 'pressure': {'D5', 'D6'}, 'based': {'D5'}, 'concept': {'D5'}, 'predicts': {'D5'}, 'interesting': {'D5'}, 'things': {'D5'}, '..': {'D5'}, 'first,': {'D5'}, 'differ': {'D5'}, 'factors': {'D5'}, '1.5': {'D5'}, '3,.': {'D5'}, 'example,': {'D5'}, 'flare': {'D5'}, 'stabilizers': {'D5'}, 'blunt-nosed': {'D5'}, 'revolution,': {'D5'}, 'lower': {'D5'}, 'diminish': {'D5'}, 'increasing': {'D5'}, 'flight': {'D5'}, 'speed': {'D5', 'D6'}, 'range': {'D5'}, 'vary': {'D5'}, 'result': {'D5'}, 'nonuniformity': {'D5'}, 'incident': {'D5'}, 'stream,': {'D5'}, 'depend': {'D5'}, 'location': {'D5'}, 'case': {'D5'}, 'flap': {'D5'}, 'mounted': {'D5'}, 'large-angled': {'D5'}, 'cone,': {'D5'}, 'coefficients': {'D5'}, '1': {'D5'}, '5': {'D5'}, 'variable': {'D5'}, 'entropy': {'D5'}, 'coefficient': {'D5'}, 'greater': {'D5'}, 'maximum': {'D5'}, 'occur': {'D5'}, 'process': {'D5'}, 'efficient': {'D5'}, 'single': {'D5'}, 'areas': {'D5'}, 'protrude': {'D5'}, 'main': {'D5'}, 'revert': {'D5'}, 'value': {'D5'}, 'initial': {'D5'}, 'slopes': {'D5'}, 'normal-force': {'D5'}, 'pitching-moment': {'D5'}, 'curves': {'D5'}, 'stabilizer': {'D5'}, 'simplest': {'D5'}, 'conventional': {'D5'}, 'ratio': {'D5'}, 'local': {'D5'}, 'dynamic': {'D5'}, 'free-stream': {'D5'}, 'takes': {'D5'}, 'values': {'D5'}, 'low': {'D5', 'D6'}, '0.1': {'D5'}, 'examples': {'D5'}, 'measurements': {'D6'}, 'dimensional': {'D6'}, 'given': {'D6'}, 'traverses': {'D6'}, '10': {'D6'}, 'per': {'D6'}, 'cent': {'D6'}, 'rae': {'D6'}, '101': {'D6'}, 'section': {'D6'}, 'reynolds': {'D6'}, 'numbers': {'D6'}, '1.6x10': {'D6'}, '3.2x10': {'D6'}, 'drag': {'D6'}, 'aerodynamic-centre': {'D6'}, 'characteristics,': {'D6'}, 'check': {'D6'}, 'methods': {'D6'}, 'growth': {'D6'}, 'turbulent': {'D6'}, 'known': {'D6'}, 'concluded': {'D6'}, 'still': {'D6'}, 'needs': {'D6'}, 'little': {'D6'}, 'refinement': {'D6'}, 'accurate': {'D6'}, 'enough': {'D6'}, 'predict': {'D6'}, 'distribution,': {'D6'}, 'aerodynamic': {'D6'}, 'center,.but': {'D6'}, 'actual': {'D6'}}\n",
      "term avant ['NOT', 'effect', 'AND', 'NOT', 'distribution']\n",
      "term apres ['NOT', 'effect', 'AND', 'NOT', 'distribution']\n",
      "{'D1', 'D6', 'D3', 'D5', 'D4', 'D2'}\n",
      "Résultat : {'D1': False, 'D6': False, 'D3': False, 'D5': False, 'D4': False, 'D2': False}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Valider une requête booléenne\n",
    "def validate_query(query):\n",
    "    \"\"\" Valider une requête booléenne pour une syntaxe appropriée. \"\"\"\n",
    "    BOOLEAN_OPERATORS = {\"AND\", \"OR\", \"NOT\"}\n",
    "    terms = query.split()\n",
    "\n",
    "    if not terms:\n",
    "        return False, \"La requête ne peut pas être vide.\"\n",
    "\n",
    "    if len(terms) == 1:\n",
    "        if terms[0] not in BOOLEAN_OPERATORS and re.match(r'^\\w+$', terms[0]):\n",
    "            return True, \"Requête valide.\"\n",
    "        else:\n",
    "            return False, f\"Terme unique non valide : '{terms[0]}'\"\n",
    "\n",
    "    if terms[0] in {\"AND\", \"OR\"}:\n",
    "        return False, \"La requête ne peut pas commencer par 'AND' ou 'OR'.\"\n",
    "\n",
    "    if terms[-1] in BOOLEAN_OPERATORS:\n",
    "        return False, \"La requête ne peut pas se terminer par un opérateur booléen.\"\n",
    "\n",
    "    for i in range(len(terms) - 1):\n",
    "        if terms[i] not in BOOLEAN_OPERATORS and terms[i + 1] not in BOOLEAN_OPERATORS:\n",
    "            return False, f\"Termes consécutifs non valides : '{terms[i]} {terms[i + 1]}'\"\n",
    "        if terms[i] in {\"AND\", \"OR\"} and terms[i + 1] in {\"AND\", \"OR\"}:\n",
    "            return False, f\"Séquence non valide après l'opérateur : '{terms[i]} {terms[i + 1]}'\"\n",
    "        if terms[i] == \"NOT\" and (i + 1 >= len(terms) or terms[i + 1] in BOOLEAN_OPERATORS):\n",
    "            return False, f\"Séquence non valide après 'NOT' : '{terms[i]} {terms[i + 1]}'\"\n",
    "\n",
    "    return True, \"Requête valide.\"\n",
    "\n",
    "# Évaluer une requête booléenne\n",
    "def evaluate_boolean_query(query, inverted_index,normalization):\n",
    "    \"\"\" Évaluer une requête booléenne par rapport à l'index inversé avec la priorité des opérateurs : NOT > AND > OR. \"\"\"\n",
    "    BOOLEAN_OPERATORS = {\"AND\", \"OR\", \"NOT\"}\n",
    "    \n",
    "    terms = query.split()\n",
    "    # print(f\"term avant {terms_without_process}\")\n",
    "    # terms = []\n",
    "    # for term in terms_without_process:\n",
    "    #     if term not in BOOLEAN_OPERATORS:\n",
    "    #         terms.append(process_input(term , normalization=normalization))\n",
    "            \n",
    "    # print(f\"term apres {terms_without_process}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    all_docs = set(doc for docs in inverted_index.values() for doc in docs)\n",
    "    print(all_docs)\n",
    "    resolve_terms = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(terms):\n",
    "        term = terms[i]\n",
    "        if term == \"NOT\":\n",
    "            i += 1\n",
    "            if i < len(terms):\n",
    "                not_term = terms[i]\n",
    "                not_set = all_docs - inverted_index.get(not_term, set())\n",
    "                resolve_terms.append((not_set, \"NOT\"))\n",
    "        elif term not in BOOLEAN_OPERATORS:\n",
    "            term_set = inverted_index.get(term, set())\n",
    "            resolve_terms.append((term_set, \"TERM\"))\n",
    "        else:\n",
    "            resolve_terms.append((term, \"OPERATOR\"))\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    while i < len(resolve_terms):\n",
    "        if resolve_terms[i][1] == \"OPERATOR\" and resolve_terms[i][0] == \"AND\":\n",
    "            left = resolve_terms[i - 1][0]\n",
    "            right = resolve_terms[i + 1][0]\n",
    "            resolve_terms[i - 1:i + 2] = [(left.intersection(right), \"RESOLVED\")]\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    i = 0\n",
    "    while i < len(resolve_terms):\n",
    "        if resolve_terms[i][1] == \"OPERATOR\" and resolve_terms[i][0] == \"OR\":\n",
    "            left = resolve_terms[i - 1][0]\n",
    "            right = resolve_terms[i + 1][0]\n",
    "            resolve_terms[i - 1:i + 2] = [(left.union(right), \"RESOLVED\")]\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    if resolve_terms and resolve_terms[0][1] == \"RESOLVED\":\n",
    "        result_set = resolve_terms[0][0]\n",
    "        return {doc: doc in result_set for doc in all_docs}\n",
    "    return {doc: False for doc in all_docs}\n",
    "\n",
    "\n",
    "\n",
    "def model_booleen(query, tokenization, normalization,output_path=\"output\"):\n",
    "    _, inverse = open_descripteur_invers(normalization , tokenization ,output_path)\n",
    "    print(inverse)\n",
    "    inverted_index = {}\n",
    "\n",
    "    for keyword, docs in inverse.items():\n",
    "        inverted_index[keyword] = set(docs.keys())\n",
    "\n",
    "    print(inverted_index)\n",
    "    \n",
    "    relevance_scores=evaluate_boolean_query(query, inverted_index,normalization=normalization)\n",
    "    return relevance_scores\n",
    "\n",
    "query = \"NOT effect AND NOT distribution\"\n",
    "valid, message = validate_query(query)\n",
    "if valid:\n",
    "    result = model_booleen(query, tokenization='Split', normalization='None',output_path=\"output\")\n",
    "    print(f\"Résultat : {result}\")\n",
    "else:\n",
    "    print(f\"Erreur : {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SearchApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.path = 'Collections'\n",
    "        self.setWindowTitle(\"Document Search and Processing\")\n",
    "        self.setGeometry(100, 100, 1170, 800) #8,6 => 900?700 \n",
    "        self.setWindowIcon(QIcon(\"./icons/interface_icon.png\")) \n",
    "        self.setFixedSize(1170, 800) #900:700\n",
    "        \n",
    "        \n",
    "        # Layout principal\n",
    "        central_widget = QWidget()\n",
    "        self.setCentralWidget(central_widget)\n",
    "        self.main_layout = QVBoxLayout(central_widget)\n",
    "\n",
    "        # Barre de recherche\n",
    "        search_layout = QHBoxLayout()\n",
    "        query_label = QLabel(\"Query: \", self)\n",
    "        search_layout.addWidget(query_label)\n",
    "        \n",
    "        self.search_bar = QLineEdit(self)\n",
    "        self.search_bar.setPlaceholderText(\"Enter document name...\")\n",
    "        self.search_button = QPushButton(\"Search\", self)\n",
    "        \n",
    "        search_layout.addWidget(self.search_bar)\n",
    "        search_layout.addWidget(self.search_button)\n",
    "        self.main_layout.addLayout(search_layout)\n",
    "\n",
    "        # Options de radio\n",
    "        radio_layout = QHBoxLayout()\n",
    "        self.raw_text_radio = QRadioButton(\"Raw Text\", self)\n",
    "        self.processed_text_radio = QRadioButton(\"Processed Text\", self)\n",
    "        radio_layout.addWidget(self.raw_text_radio)\n",
    "        radio_layout.addWidget(self.processed_text_radio)\n",
    "        self.main_layout.addLayout(radio_layout)\n",
    "        \n",
    "        # Section Tokenization\n",
    "        tokenization_box = QGroupBox(\"Tokenization\")\n",
    "        tokenization_layout = QVBoxLayout()\n",
    "        self.split_radio = QRadioButton(\"Split\", self)\n",
    "        self.regex_radio = QRadioButton(\"Regex\", self)\n",
    "        tokenization_layout.addWidget(self.split_radio)\n",
    "        tokenization_layout.addWidget(self.regex_radio)\n",
    "        tokenization_box.setLayout(tokenization_layout)\n",
    "        \n",
    "        # Section Normalization\n",
    "        normalization_box = QGroupBox(\"Normalization\")\n",
    "        normalization_layout = QVBoxLayout()\n",
    "        self.no_stem_radio = QRadioButton(\"No Stem\", self)\n",
    "        self.porter_radio = QRadioButton(\"Porter\", self)\n",
    "        self.lancaster_radio = QRadioButton(\"Lancaster\", self)\n",
    "        normalization_layout.addWidget(self.no_stem_radio)\n",
    "        normalization_layout.addWidget(self.porter_radio)\n",
    "        normalization_layout.addWidget(self.lancaster_radio)\n",
    "        normalization_box.setLayout(normalization_layout)\n",
    "        \n",
    "        # Section Indexation\n",
    "        indexation_box = QGroupBox(\"Indexation\")\n",
    "        indexation_layout = QVBoxLayout()\n",
    "        self.doc_per_term_radio = QRadioButton(\"Documents per Term\", self)\n",
    "        self.term_per_doc_radio = QRadioButton(\"Terms per Document\", self)\n",
    "        indexation_layout.addWidget(self.doc_per_term_radio)\n",
    "        indexation_layout.addWidget(self.term_per_doc_radio)\n",
    "        indexation_box.setLayout(indexation_layout)\n",
    "        \n",
    "        \n",
    "        matching_box = QGroupBox(\"Matching\")\n",
    "        matching_layout = QGridLayout()\n",
    "\n",
    "        # Boutons radio\n",
    "        self.vector_space_radio = QRadioButton(\"Vector Space Model\")\n",
    "        self.probability_model_radio = QRadioButton(\"Probabilistic Model (BM25)\")\n",
    "        self.boolean_model_radio = QRadioButton(\"Boolean Model\")\n",
    "        self.data_mining_model_radio = QRadioButton(\"Data Mining Model\")\n",
    "\n",
    "        # Menu déroulant pour \"Vector Space Model\"\n",
    "        self.matching_options = QComboBox()\n",
    "        self.matching_options.addItems([\"Scalar Product\", \"Cosine Similarity\", \"Jaccard Index\"])\n",
    "\n",
    "        # Champs de saisie pour k et b sous \"Probabilistic Model\"\n",
    "        self.k_input = QLineEdit()\n",
    "        validator = QDoubleValidator()\n",
    "        validator.setNotation(QDoubleValidator.StandardNotation)  # Autorise les notations standard (pas scientifiques)\n",
    "        validator.setRange(-1000.0, 1000.0, 3)  # Plage de valeurs entre -1000 et 1000 avec 3 décimales max\n",
    "        self.k_input.setValidator(validator)\n",
    "        self.k_input.setPlaceholderText(\"K\")\n",
    "\n",
    "        self.b_input = QLineEdit()\n",
    "        self.b_input.setValidator(validator)  # Utilisez le même validateur pour `b_input`\n",
    "        self.b_input.setPlaceholderText(\"B\")\n",
    "\n",
    "        # Ajout des widgets au layout (organisé par colonnes et lignes)\n",
    "        matching_layout.addWidget(self.vector_space_radio, 0, 0)  # Ligne 0, Colonne 0\n",
    "        matching_layout.addWidget(self.matching_options, 0, 1)     # Ligne 0, Colonne 1\n",
    "        matching_layout.addWidget(self.probability_model_radio, 1, 0)  # Ligne 1, Colonne 0\n",
    "        matching_layout.addWidget(self.k_input, 1, 1)             # Ligne 1, Colonne 1\n",
    "        matching_layout.addWidget(self.b_input, 1, 2)             # Ligne 1, Colonne 2\n",
    "        matching_layout.addWidget(self.boolean_model_radio, 2, 0) # Ligne 2, Colonne 0\n",
    "        matching_layout.addWidget(self.data_mining_model_radio, 3, 0)  # Ligne 3, Colonne 0\n",
    "\n",
    "        # Appliquer le layout au QGroupBox\n",
    "        matching_box.setLayout(matching_layout)\n",
    "\n",
    "       \n",
    "       \n",
    "        \n",
    "        # Disposition des sections\n",
    "        sections_layout = QHBoxLayout()\n",
    "        sections_layout.addWidget(tokenization_box)\n",
    "        sections_layout.addWidget(normalization_box)\n",
    "        sections_layout.addWidget(indexation_box)\n",
    "        sections_layout.addWidget(matching_box) \n",
    "        self.main_layout.addLayout(sections_layout)\n",
    "        \n",
    "        # Zone de résultats (QStackedWidget pour alterner entre texte et tableau)\n",
    "        self.result_label = QLabel(\"Result: \", self)\n",
    "        self.main_layout.addWidget(self.result_label)\n",
    "\n",
    "        self.result_area = QStackedWidget(self)\n",
    "        self.result_area.setFixedHeight(400)  # Taille fixe pour éviter d'étendre la mise en page\n",
    "        self.result_area.setFixedWidth(600)  # Ajustez selon la largeur désirée\n",
    "        \n",
    "        \n",
    "        # Widget pour afficher le texte brut\n",
    "        self.raw_text_widget = QTextEdit(self)\n",
    "        self.raw_text_widget.setReadOnly(True)  # Rendre le texte en lecture seule\n",
    "        self.result_area.addWidget(self.raw_text_widget)\n",
    "        \n",
    "        # Widget pour afficher le tableau\n",
    "        self.table = QTableWidget(0, 5, self)  # 5 colonnes pour N°, N° doc, terme, fréquence, poids\n",
    "        self.table.setHorizontalHeaderLabels([\"N°\", \"N° doc\", \"Term\", \"Frequency\", \"Weight\"])\n",
    "        self.table.setShowGrid(False)  # Masquer la grille du tableau\n",
    "        \n",
    "        # Faire en sorte que les colonnes s'étendent pour couvrir toute la largeur\n",
    "        header = self.table.horizontalHeader()\n",
    "        header.setSectionResizeMode(QHeaderView.Stretch)\n",
    "        self.result_area.addWidget(self.table)\n",
    "        \n",
    "        self.main_layout.addWidget(self.result_area)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #    //////////////////////////////////////\n",
    "        Total_terms_layout = QHBoxLayout()\n",
    "        \n",
    "        # Création et configuration des QLabel\n",
    "        self.terms_per_doc = QLabel(self)\n",
    "        self.terms_all_doc = QLabel(self)\n",
    "        \n",
    "        # Appliquer les styles pour enlever le fond et les bordures\n",
    "        style = \"\"\"\n",
    "            QLabel {\n",
    "                margin-left: 20px;\n",
    "                background-color: transparent;\n",
    "                border: none;\n",
    "                font-size: 14px;\n",
    "                font-family: Arial, sans-serif;\n",
    "            }\n",
    "        \"\"\"\n",
    "        self.terms_all_doc.setStyleSheet(style)\n",
    "        self.terms_per_doc.setStyleSheet(style)\n",
    "        \n",
    "        \n",
    "        # Ajout des QLabel au layout horizontal\n",
    "        Total_terms_layout.addWidget(self.terms_per_doc)\n",
    "        Total_terms_layout.addWidget(self.terms_all_doc)\n",
    "        \n",
    "        # Ajout du layout horizontal dans le layout principal\n",
    "        self.main_layout.addLayout(Total_terms_layout)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Ajustements dans le code principal\n",
    "        self.main_layout.setContentsMargins(2, 2, 2, 2)  # Réduire les marges globales\n",
    "        self.main_layout.setSpacing(8)  # Diminuer l'espace entre les sections\n",
    "        self.result_area.setContentsMargins(2, 0, 2, 0)  # Marges gauche et droite de 2px pour le tableau\n",
    "        self.result_area.setFixedWidth(self.width() - 4) \n",
    "                \n",
    "                \n",
    "        # events\n",
    "        self.search_button.clicked.connect(self.process_search)\n",
    "        self.raw_text_radio.clicked.connect(self.raw_text_radio_process)\n",
    "        self.processed_text_radio.clicked.connect(self.processed_text_radio_process)\n",
    "        self.vector_space_radio.toggled.connect(self.toggle_radio_buttons)\n",
    "        \n",
    "    def toggle_radio_buttons(self,state):\n",
    "        self.doc_per_term_radio.setEnabled(not state) \n",
    "        self.term_per_doc_radio.setEnabled(not state)\n",
    "        \n",
    "    def raw_text_radio_process(self):\n",
    "        self.vector_space_radio.setEnabled(False)\n",
    "        self.matching_options.setEnabled(False)\n",
    "        self.split_radio.setEnabled(False) \n",
    "        self.regex_radio.setEnabled(False)\n",
    "        self.lancaster_radio.setEnabled(False)\n",
    "        self.porter_radio.setEnabled(False)\n",
    "        self.doc_per_term_radio.setEnabled(False)\n",
    "        self.term_per_doc_radio.setEnabled(False)\n",
    "        self.no_stem_radio.setEnabled(False)\n",
    "        self.terms_per_doc.setText(\"\")\n",
    "        self.terms_all_doc.setText(\"\")\n",
    "       \n",
    "       \n",
    "    def processed_text_radio_process(self):\n",
    "        self.vector_space_radio.setEnabled(True)\n",
    "        self.matching_options.setEnabled(True)\n",
    "        self.split_radio.setEnabled(True) \n",
    "        self.regex_radio.setEnabled(True)\n",
    "        self.lancaster_radio.setEnabled(True)\n",
    "        self.porter_radio.setEnabled(True)\n",
    "        self.doc_per_term_radio.setEnabled(True)\n",
    "        self.term_per_doc_radio.setEnabled(True)\n",
    "        self.no_stem_radio.setEnabled(True)\n",
    "        \n",
    "         \n",
    "    def display_Total_Terms(self, termes_global, nb_termes ,index):\n",
    "        if nb_termes != 0 and index == 'TPD':\n",
    "            # Afficher le nombre de termes par document\n",
    "            self.terms_per_doc.setText(f\"Terms per document : {nb_termes}\")\n",
    "        else :\n",
    "            self.terms_per_doc.setText(\"\")\n",
    "        self.terms_all_doc.setText(f\"Total terms  : {termes_global}\")\n",
    "\n",
    "        \n",
    "        \n",
    "    def process_search(self):\n",
    "        # Obtenir le numéro de document\n",
    "        document_number = self.search_bar.text()\n",
    "        \n",
    "        if not document_number:\n",
    "            self.show_error(\"Veuillez entrer un numéro de document valide.\")\n",
    "            return\n",
    "\n",
    "        # \n",
    "        # Vérifier le type de texte sélectionné\n",
    "        if self.raw_text_radio.isChecked():\n",
    "            # verification de nom_document\n",
    "            result = get_text(document_number)\n",
    "            self.show_raw_text(result)\n",
    "        \n",
    "        else:\n",
    "            # Obtenir les méthodes sélectionnées\n",
    "            tokenization_method = \"Split\" if self.split_radio.isChecked() else \"Regex\"\n",
    "            if self.porter_radio.isChecked() :\n",
    "                normalization_method = \"Porter\" \n",
    "            elif self.no_stem_radio.isChecked():\n",
    "                normalization_method = \"None\" \n",
    "            else :\n",
    "                normalization_method =\"Lancaster\"\n",
    "            indexation_method = \"DPT\" if self.doc_per_term_radio.isChecked() else \"TPD\"\n",
    "            \n",
    "            if self.vector_space_radio.isChecked():\n",
    "            # Récupération de la méthode de matching sélectionnée\n",
    "                matching_method = self.matching_options.currentText()\n",
    "                # Utilisation\n",
    "                \n",
    "                if matching_method == \"Scalar Product\":\n",
    "                    print(\"produit scalaire\")\n",
    "                    relevances = calculer_relevance(document_number, tokenization_method, normalization_method, 'DPT',self.path)\n",
    "                    print(relevances)\n",
    "\n",
    "                elif matching_method == \"Cosine Similarity\":\n",
    "                    print(\"produit cosine\")\n",
    "                    relevances = calculer_relevance_cosinus(document_number, tokenization_method, normalization_method, 'DPT',self.path)\n",
    "                    print(relevances)\n",
    "\n",
    "                elif matching_method == \"Jaccard Index\":\n",
    "                    print(\"jacard\")\n",
    "                    relevances = calculer_jaccard_similarity(document_number, tokenization_method, normalization_method, 'DPT',self.path)\n",
    "                    print(relevances)\n",
    "                filtered_relevances = {doc: score for doc, score in relevances.items() if score > 0}\n",
    "                sorted_relevances = sorted(filtered_relevances.items(), key=lambda item: item[1], reverse=True)\n",
    "                print(sorted_relevances)\n",
    "                # Afficher les relevances triées\n",
    "                self.display_relevance(sorted_relevances)\n",
    "            elif self.probability_model_radio.isChecked():\n",
    "                try:\n",
    "                    text = self.k_input.text()\n",
    "                    corrected_text_k = text.replace(\",\", \".\")\n",
    "                    text = self.b_input.text()\n",
    "                    corrected_text_b = text.replace(\",\", \".\")\n",
    "                    k = float(corrected_text_k)  # Convertit en flottant\n",
    "                    b = float(corrected_text_b)\n",
    "                except ValueError:\n",
    "                    QMessageBox.warning(self, \"Invalid Input\", \"Please enter valid numeric values for k and b.\")\n",
    "                    k = 1.5  # Valeur par défaut si erreur\n",
    "                    b = 0.75  # Valeur par défaut si erreur\n",
    "                print(k,b)\n",
    "                relevances = calculer_relevance_BM25(document_number, tokenization_method, normalization_method, self.path ,k ,b,'output')\n",
    "                # filtered_relevances = {doc: score for doc, score in relevances.items() if score > 0}\n",
    "                # sorted_relevances = sorted(filtered_relevances.items(), key=lambda item: item[1], reverse=True)\n",
    "                print(\"BM25\")\n",
    "                print(relevances)\n",
    "                relevances = list(relevances.items())\n",
    "                self.display_relevance(relevances)\n",
    "            elif self.boolean_model_radio.isChecked():\n",
    "                try :\n",
    "                    # print(document_number, tokenization_method, normalization_method)\n",
    "                    # relevances = model_booleen(document_number, tokenization_method, normalization_method, \"DPT\", self.path,output_path=\"output\")\n",
    "                    # self.display_relevance(relevances)\n",
    "                    valid, message = validate_query(query)\n",
    "                    if valid:\n",
    "                        relevances = model_booleen(document_number, tokenization_method, normalization_method,output_path=\"output\")\n",
    "                        print(f\"Résultat : {relevances}\")\n",
    "                        relevances = list(relevances.items())\n",
    "                        self.display_relevance(relevances)\n",
    "                    else:\n",
    "                        QMessageBox.warning(self, \"Invalid Input\", f\"{message}. Please enter valid Expression.\")\n",
    "\n",
    "                except Exception as e :\n",
    "                    print(e)\n",
    "                    QMessageBox.warning(self, \"Invalid Input\", \"Please enter valid Expression.\")\n",
    "                    \n",
    "            else :\n",
    "                # termes_global = nb_termes_glob(tokenization_method, normalization_method)\n",
    "                # Appeler la fonction pour obtenir les données\n",
    "                data , nb_termes , termes_global=processing(document_number, tokenization_method,  normalization_method, path='../Collections', output_path=\"output\",methode = indexation_method)\n",
    "                self.display_results(data)\n",
    "                self.display_Total_Terms(termes_global , nb_termes , indexation_method)\n",
    "                \n",
    "                     \n",
    "\n",
    "    def reset_table(self, column_headers):\n",
    "        \"\"\"\n",
    "        Réinitialise complètement le tableau avec de nouvelles colonnes et leurs en-têtes.\n",
    "\n",
    "        Parameters:\n",
    "            column_headers (list of str): Liste des noms des colonnes.\n",
    "        \"\"\"\n",
    "        self.table.clear()  # Efface tout le contenu (cellules et en-têtes)\n",
    "        self.table.setRowCount(0)  # Réinitialise le nombre de lignes\n",
    "        self.table.setColumnCount(len(column_headers))  # Définir le nombre de colonnes\n",
    "        self.table.setHorizontalHeaderLabels(column_headers)  # Définir les en-têtes de colonnes\n",
    "\n",
    "        # Ajuster les colonnes pour s'étendre uniformément\n",
    "        header = self.table.horizontalHeader()\n",
    "        header.setSectionResizeMode(QHeaderView.Stretch)\n",
    "\n",
    "\n",
    "    def show_raw_text(self, text):\n",
    "        self.raw_text_widget.setText(text)\n",
    "        self.result_area.setCurrentWidget(self.raw_text_widget)  # Afficher le widget de texte brut\n",
    "\n",
    "        \n",
    "    def display_results(self, data):\n",
    "    # Supprimer l'affichage de l'index de ligne\n",
    "        self.table.verticalHeader().setVisible(False)\n",
    "        # Réinitialiser le tableau avec les colonnes spécifiques\n",
    "        column_headers = [\"N°\", \"N° doc\", \"Term\", \"Frequency\", \"Weight\"]\n",
    "        self.reset_table(column_headers)\n",
    "        \n",
    "        # Nettoyer le tableau et ajouter les résultats\n",
    "        self.table.setRowCount(0)\n",
    "        for index, row_data in enumerate(data):\n",
    "            row_position = self.table.rowCount()\n",
    "            self.table.insertRow(row_position)\n",
    "            for column, value in enumerate(row_data):\n",
    "                item = QTableWidgetItem(str(value))\n",
    "                item.setTextAlignment(Qt.AlignCenter)  # Centrer le texte dans chaque cellule\n",
    "                self.table.setItem(row_position, column, item)\n",
    "        \n",
    "        # Afficher le widget de tableau\n",
    "        self.result_area.setCurrentWidget(self.table)\n",
    "    \n",
    "\n",
    "\n",
    "    def display_relevance(self, sorted_relevances):\n",
    "        \"\"\"\n",
    "        Affiche les relevances triées dans le tableau.\n",
    "\n",
    "        Parameters:\n",
    "            sorted_relevances (list of tuples): Une liste de tuples (document, score de pertinence).\n",
    "        \"\"\"\n",
    "        # Réinitialiser le tableau avec deux colonnes\n",
    "        column_headers = [\"Document\", \"Score de Pertinence\"]\n",
    "        self.reset_table(column_headers)\n",
    "\n",
    "        # Ajouter les données triées dans le tableau\n",
    "        for doc_id, score in sorted_relevances:\n",
    "            row_position = self.table.rowCount()\n",
    "            self.table.insertRow(row_position)\n",
    "\n",
    "            # Ajouter l'identifiant du document\n",
    "            doc_item = QTableWidgetItem(doc_id)\n",
    "            doc_item.setTextAlignment(Qt.AlignCenter)\n",
    "            self.table.setItem(row_position, 0, doc_item)\n",
    "\n",
    "            # Ajouter le score de pertinence\n",
    "            if isinstance(score, bool):\n",
    "                score_item = QTableWidgetItem(\"True\" if score else \"False\")\n",
    "            elif isinstance(score, (int, float)):\n",
    "                score_item = QTableWidgetItem(f\"{score:.4f}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Type non pris en charge : {type(score)}\")\n",
    "\n",
    "            score_item.setTextAlignment(Qt.AlignCenter)\n",
    "            self.table.setItem(row_position, 1, score_item)\n",
    "\n",
    "        # Afficher le tableau\n",
    "        self.result_area.setCurrentWidget(self.table)\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    def show_error(self, message):\n",
    "        error_dialog = QMessageBox(self)\n",
    "        error_dialog.setIcon(QMessageBox.Critical)\n",
    "        error_dialog.setWindowTitle(\"Erreur\")\n",
    "        error_dialog.setText(message)\n",
    "        error_dialog.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment': {'D1': {'freq': 2, 'poids': 0.338}}, 'investig': {'D1': {'freq': 1, 'poids': 0.1204}, 'D2': {'freq': 1, 'poids': 0.1003}}, 'aerodynam': {'D1': {'freq': 1, 'poids': 0.1204}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'wing': {'D1': {'freq': 3, 'poids': 0.3612}, 'D6': {'freq': 2, 'poids': 0.301}}, 'slipstream': {'D1': {'freq': 5, 'poids': 0.8451}}, 'studi': {'D1': {'freq': 1, 'poids': 0.1204}, 'D2': {'freq': 2, 'poids': 0.2007}}, 'propel': {'D1': {'freq': 1, 'poids': 0.169}}, 'made': {'D1': {'freq': 2, 'poids': 0.2408}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'order': {'D1': {'freq': 1, 'poids': 0.169}}, 'determin': {'D1': {'freq': 1, 'poids': 0.169}}, 'spanwis': {'D1': {'freq': 1, 'poids': 0.169}}, 'distribut': {'D1': {'freq': 1, 'poids': 0.0796}, 'D3': {'freq': 1, 'poids': 0.0995}, 'D4': {'freq': 1, 'poids': 0.0568}, 'D6': {'freq': 2, 'poids': 0.199}}, 'lift': {'D1': {'freq': 4, 'poids': 0.4816}, 'D6': {'freq': 2, 'poids': 0.301}}, 'increas': {'D1': {'freq': 1, 'poids': 0.1204}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'due': {'D1': {'freq': 2, 'poids': 0.338}}, 'differ': {'D1': {'freq': 3, 'poids': 0.2863}, 'D2': {'freq': 1, 'poids': 0.0795}, 'D5': {'freq': 2, 'poids': 0.0954}}, 'angl': {'D1': {'freq': 1, 'poids': 0.169}}, 'attack': {'D1': {'freq': 1, 'poids': 0.169}}, 'free': {'D1': {'freq': 1, 'poids': 0.1204}, 'D2': {'freq': 3, 'poids': 0.301}}, 'stream': {'D1': {'freq': 1, 'poids': 0.0954}, 'D2': {'freq': 3, 'poids': 0.2386}, 'D5': {'freq': 2, 'poids': 0.0954}}, 'veloc': {'D1': {'freq': 1, 'poids': 0.0954}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D4': {'freq': 1, 'poids': 0.0682}}, 'ratio': {'D1': {'freq': 1, 'poids': 0.1204}, 'D5': {'freq': 2, 'poids': 0.1204}}, 'result': {'D1': {'freq': 1, 'poids': 0.0954}, 'D5': {'freq': 1, 'poids': 0.0477}, 'D6': {'freq': 2, 'poids': 0.2386}}, 'intend': {'D1': {'freq': 1, 'poids': 0.169}}, 'part': {'D1': {'freq': 2, 'poids': 0.338}}, 'evalu': {'D1': {'freq': 2, 'poids': 0.338}}, 'basi': {'D1': {'freq': 1, 'poids': 0.1204}, 'D4': {'freq': 1, 'poids': 0.086}}, 'theoret': {'D1': {'freq': 1, 'poids': 0.169}}, 'treatment': {'D1': {'freq': 1, 'poids': 0.169}}, 'problem': {'D1': {'freq': 1, 'poids': 0.0796}, 'D2': {'freq': 4, 'poids': 0.2653}, 'D3': {'freq': 1, 'poids': 0.0995}, 'D4': {'freq': 4, 'poids': 0.2274}}, 'compar': {'D1': {'freq': 1, 'poids': 0.169}}, 'span': {'D1': {'freq': 1, 'poids': 0.169}}, 'load': {'D1': {'freq': 1, 'poids': 0.169}}, 'curv': {'D1': {'freq': 1, 'poids': 0.0954}, 'D2': {'freq': 1, 'poids': 0.0795}, 'D5': {'freq': 1, 'poids': 0.0477}}, 'togeth': {'D1': {'freq': 1, 'poids': 0.169}}, 'support': {'D1': {'freq': 1, 'poids': 0.169}}, 'evid': {'D1': {'freq': 1, 'poids': 0.169}}, 'show': {'D1': {'freq': 1, 'poids': 0.0954}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D4': {'freq': 1, 'poids': 0.0682}}, 'substanti': {'D1': {'freq': 1, 'poids': 0.169}}, 'increment': {'D1': {'freq': 2, 'poids': 0.338}}, 'produc': {'D1': {'freq': 1, 'poids': 0.169}}, 'destal': {'D1': {'freq': 3, 'poids': 0.5071}}, 'boundary-layer-control': {'D1': {'freq': 1, 'poids': 0.169}}, 'effect': {'D1': {'freq': 2, 'poids': 0.1592}, 'D2': {'freq': 1, 'poids': 0.0663}, 'D3': {'freq': 1, 'poids': 0.0995}, 'D6': {'freq': 3, 'poids': 0.2985}}, 'integr': {'D1': {'freq': 1, 'poids': 0.0954}, 'D4': {'freq': 1, 'poids': 0.0682}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'remain': {'D1': {'freq': 1, 'poids': 0.169}}, 'subtract': {'D1': {'freq': 1, 'poids': 0.169}}, 'found': {'D1': {'freq': 1, 'poids': 0.169}}, 'agre': {'D1': {'freq': 1, 'poids': 0.169}}, 'well': {'D1': {'freq': 1, 'poids': 0.169}}, 'potenti': {'D1': {'freq': 1, 'poids': 0.169}}, 'flow': {'D1': {'freq': 1, 'poids': 0.0685}, 'D2': {'freq': 6, 'poids': 0.3424}, 'D3': {'freq': 3, 'poids': 0.2568}, 'D4': {'freq': 7, 'poids': 0.3424}, 'D5': {'freq': 5, 'poids': 0.1712}}, 'theori': {'D1': {'freq': 1, 'poids': 0.1204}, 'D5': {'freq': 4, 'poids': 0.2408}}, 'empir': {'D1': {'freq': 1, 'poids': 0.169}}, 'specif': {'D1': {'freq': 1, 'poids': 0.169}}, 'configur': {'D1': {'freq': 1, 'poids': 0.169}}, 'experi': {'D1': {'freq': 1, 'poids': 0.169}}, 'simpl': {'D2': {'freq': 2, 'poids': 0.2007}, 'D5': {'freq': 2, 'poids': 0.1204}}, 'shear': {'D2': {'freq': 2, 'poids': 0.2007}, 'D3': {'freq': 2, 'poids': 0.301}}, 'past': {'D2': {'freq': 4, 'poids': 0.5634}}, 'flat': {'D2': {'freq': 3, 'poids': 0.301}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'plate': {'D2': {'freq': 3, 'poids': 0.301}, 'D3': {'freq': 2, 'poids': 0.301}}, 'incompress': {'D2': {'freq': 2, 'poids': 0.2007}, 'D3': {'freq': 2, 'poids': 0.301}}, 'fluid': {'D2': {'freq': 2, 'poids': 0.2007}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'small': {'D2': {'freq': 2, 'poids': 0.2817}}, 'viscos': {'D2': {'freq': 2, 'poids': 0.2007}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'high-spe': {'D2': {'freq': 1, 'poids': 0.1408}}, 'viscou': {'D2': {'freq': 2, 'poids': 0.2817}}, 'two-dimension': {'D2': {'freq': 2, 'poids': 0.159}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'bodi': {'D2': {'freq': 2, 'poids': 0.159}, 'D4': {'freq': 5, 'poids': 0.3408}, 'D5': {'freq': 1, 'poids': 0.0477}}, 'usual': {'D2': {'freq': 1, 'poids': 0.1003}, 'D4': {'freq': 1, 'poids': 0.086}}, 'necessari': {'D2': {'freq': 1, 'poids': 0.1408}}, 'consid': {'D2': {'freq': 2, 'poids': 0.159}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D5': {'freq': 1, 'poids': 0.0477}}, 'shock': {'D2': {'freq': 2, 'poids': 0.2007}, 'D5': {'freq': 5, 'poids': 0.301}}, 'wave': {'D2': {'freq': 2, 'poids': 0.2007}, 'D5': {'freq': 4, 'poids': 0.2408}}, 'emit': {'D2': {'freq': 1, 'poids': 0.1408}}, 'nose': {'D2': {'freq': 1, 'poids': 0.1408}}, 'lead': {'D2': {'freq': 1, 'poids': 0.1003}, 'D4': {'freq': 1, 'poids': 0.086}}, 'edg': {'D2': {'freq': 1, 'poids': 0.1408}}, 'consequ': {'D2': {'freq': 1, 'poids': 0.1003}, 'D4': {'freq': 1, 'poids': 0.086}}, 'exist': {'D2': {'freq': 1, 'poids': 0.1408}}, 'inviscid': {'D2': {'freq': 3, 'poids': 0.4225}}, 'rotat': {'D2': {'freq': 2, 'poids': 0.2817}}, 'region': {'D2': {'freq': 1, 'poids': 0.1003}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'boundari': {'D2': {'freq': 2, 'poids': 0.1326}, 'D3': {'freq': 4, 'poids': 0.3979}, 'D4': {'freq': 2, 'poids': 0.1137}, 'D6': {'freq': 3, 'poids': 0.2985}}, 'layer': {'D2': {'freq': 2, 'poids': 0.1326}, 'D3': {'freq': 4, 'poids': 0.3979}, 'D5': {'freq': 3, 'poids': 0.1194}, 'D6': {'freq': 3, 'poids': 0.2985}}, 'situat': {'D2': {'freq': 2, 'poids': 0.2817}}, 'aris': {'D2': {'freq': 1, 'poids': 0.1408}}, 'instanc': {'D2': {'freq': 1, 'poids': 0.1408}}, 'hyperson': {'D2': {'freq': 2, 'poids': 0.2007}, 'D5': {'freq': 3, 'poids': 0.1806}}, 'somewhat': {'D2': {'freq': 1, 'poids': 0.1408}}, 'prandtl': {'D2': {'freq': 2, 'poids': 0.2817}}, 'classic': {'D2': {'freq': 1, 'poids': 0.1408}}, 'boundary-lay': {'D2': {'freq': 3, 'poids': 0.2386}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D6': {'freq': 3, 'poids': 0.3578}}, 'origin': {'D2': {'freq': 1, 'poids': 0.1408}}, 'outsid': {'D2': {'freq': 1, 'poids': 0.1408}}, 'irrot': {'D2': {'freq': 1, 'poids': 0.1408}}, 'must': {'D2': {'freq': 1, 'poids': 0.1408}}, 'possibl': {'D2': {'freq': 1, 'poids': 0.1003}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'vortic': {'D2': {'freq': 2, 'poids': 0.2007}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'recent': {'D2': {'freq': 1, 'poids': 0.1408}}, 'discuss': {'D2': {'freq': 2, 'poids': 0.2817}}, 'ferri': {'D2': {'freq': 1, 'poids': 0.1408}}, 'libbi': {'D2': {'freq': 1, 'poids': 0.1408}}, 'present': {'D2': {'freq': 1, 'poids': 0.1003}, 'D4': {'freq': 2, 'poids': 0.172}}, 'paper': {'D2': {'freq': 1, 'poids': 0.1408}}, 'shown': {'D2': {'freq': 1, 'poids': 0.1408}}, 'treat': {'D2': {'freq': 1, 'poids': 0.1003}, 'D4': {'freq': 1, 'poids': 0.086}}, 'approxim': {'D2': {'freq': 1, 'poids': 0.0795}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D5': {'freq': 1, 'poids': 0.0477}}, 'novel': {'D2': {'freq': 1, 'poids': 0.1408}}, 'featur': {'D2': {'freq': 1, 'poids': 0.1408}}, 'constant': {'D2': {'freq': 1, 'poids': 0.1408}}, 'restrict': {'D2': {'freq': 1, 'poids': 0.1408}}, 'steadi': {'D2': {'freq': 1, 'poids': 0.1003}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'solut': {'D3': {'freq': 2, 'poids': 0.301}, 'D4': {'freq': 4, 'poids': 0.344}}, 'laminar': {'D3': {'freq': 1, 'poids': 0.2113}}, 'equat': {'D3': {'freq': 1, 'poids': 0.1193}, 'D4': {'freq': 2, 'poids': 0.1363}, 'D5': {'freq': 2, 'poids': 0.0954}}, 'thick': {'D3': {'freq': 1, 'poids': 0.2113}}, 'skin': {'D3': {'freq': 1, 'poids': 0.2113}}, 'friction': {'D3': {'freq': 1, 'poids': 0.2113}}, 'obtain': {'D3': {'freq': 1, 'poids': 0.2113}}, 'karman-pohlhausen': {'D3': {'freq': 1, 'poids': 0.2113}}, 'techniqu': {'D3': {'freq': 1, 'poids': 0.2113}}, 'comparison': {'D3': {'freq': 1, 'poids': 0.2113}}, 'uniform': {'D3': {'freq': 1, 'poids': 0.1505}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'also': {'D3': {'freq': 1, 'poids': 0.2113}}, 'exact': {'D4': {'freq': 2, 'poids': 0.2415}}, 'neumann': {'D4': {'freq': 2, 'poids': 0.2415}}, 'calcul': {'D4': {'freq': 3, 'poids': 0.2045}, 'D5': {'freq': 1, 'poids': 0.0477}, 'D6': {'freq': 3, 'poids': 0.3578}}, 'non': {'D4': {'freq': 1, 'poids': 0.1207}}, 'circulatori': {'D4': {'freq': 1, 'poids': 0.1207}}, 'plane': {'D4': {'freq': 2, 'poids': 0.2415}}, 'axial': {'D4': {'freq': 2, 'poids': 0.172}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'symmetr': {'D4': {'freq': 1, 'poids': 0.1207}}, 'within': {'D4': {'freq': 2, 'poids': 0.2415}}, 'arbitrari': {'D4': {'freq': 1, 'poids': 0.1207}}, 'gener': {'D4': {'freq': 1, 'poids': 0.086}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'method': {'D4': {'freq': 4, 'poids': 0.344}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'solv': {'D4': {'freq': 4, 'poids': 0.4829}}, 'second': {'D4': {'freq': 2, 'poids': 0.2415}}, 'boundary-valu': {'D4': {'freq': 1, 'poids': 0.1207}}, 'develop': {'D4': {'freq': 1, 'poids': 0.086}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'appli': {'D4': {'freq': 1, 'poids': 0.1207}}, 'low-spe': {'D4': {'freq': 1, 'poids': 0.1207}}, 'almost': {'D4': {'freq': 1, 'poids': 0.1207}}, 'shape': {'D4': {'freq': 2, 'poids': 0.2415}}, 'provid': {'D4': {'freq': 1, 'poids': 0.1207}}, 'either': {'D4': {'freq': 1, 'poids': 0.1207}}, 'symmetri': {'D4': {'freq': 1, 'poids': 0.1207}}, 'solid-bodi': {'D4': {'freq': 1, 'poids': 0.1207}}, 'inlet': {'D4': {'freq': 1, 'poids': 0.1207}}, 'pure': {'D4': {'freq': 1, 'poids': 0.1207}}, 'intern': {'D4': {'freq': 1, 'poids': 0.1207}}, 'capabl': {'D4': {'freq': 1, 'poids': 0.1207}}, 'deal': {'D4': {'freq': 1, 'poids': 0.1207}}, 'sever': {'D4': {'freq': 1, 'poids': 0.1207}}, 'presenc': {'D4': {'freq': 1, 'poids': 0.1207}}, 'one': {'D4': {'freq': 1, 'poids': 0.1207}}, 'anoth': {'D4': {'freq': 1, 'poids': 0.1207}}, 'interfer': {'D4': {'freq': 1, 'poids': 0.1207}}, 'eas': {'D4': {'freq': 1, 'poids': 0.1207}}, 'need': {'D4': {'freq': 1, 'poids': 0.086}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'solid': {'D4': {'freq': 1, 'poids': 0.1207}}, 'involv': {'D4': {'freq': 1, 'poids': 0.1207}}, 'area': {'D4': {'freq': 1, 'poids': 0.086}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'suction': {'D4': {'freq': 1, 'poids': 0.1207}}, 'comput': {'D4': {'freq': 2, 'poids': 0.2415}}, 'point': {'D4': {'freq': 3, 'poids': 0.3622}}, 'surfac': {'D4': {'freq': 2, 'poids': 0.172}, 'D5': {'freq': 3, 'poids': 0.1806}}, 'entir': {'D4': {'freq': 1, 'poids': 0.1207}}, 'field': {'D4': {'freq': 1, 'poids': 0.086}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'sourc': {'D4': {'freq': 1, 'poids': 0.1207}}, 'use': {'D4': {'freq': 2, 'poids': 0.1363}, 'D5': {'freq': 1, 'poids': 0.0477}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'fredholm': {'D4': {'freq': 1, 'poids': 0.1207}}, 'kind': {'D4': {'freq': 1, 'poids': 0.1207}}, 'set': {'D4': {'freq': 1, 'poids': 0.1207}}, 'linear': {'D4': {'freq': 1, 'poids': 0.1207}}, 'algebra': {'D4': {'freq': 1, 'poids': 0.1207}}, 'modifi': {'D4': {'freq': 1, 'poids': 0.1207}}, 'seidel': {'D4': {'freq': 1, 'poids': 0.1207}}, 'time': {'D4': {'freq': 1, 'poids': 0.1207}}, 'program': {'D4': {'freq': 1, 'poids': 0.1207}}, 'ibm': {'D4': {'freq': 1, 'poids': 0.1207}}, '704': {'D4': {'freq': 1, 'poids': 0.1207}}, 'edpm': {'D4': {'freq': 1, 'poids': 0.1207}}, 'previous': {'D4': {'freq': 1, 'poids': 0.1207}}, 'mention': {'D4': {'freq': 1, 'poids': 0.1207}}, 'characterist': {'D4': {'freq': 1, 'poids': 0.086}, 'D6': {'freq': 2, 'poids': 0.301}}, 'whose': {'D4': {'freq': 1, 'poids': 0.1207}}, 'profil': {'D4': {'freq': 1, 'poids': 0.1207}}, 'defin': {'D4': {'freq': 2, 'poids': 0.2415}}, 'satisfactorili': {'D4': {'freq': 1, 'poids': 0.1207}}, '300': {'D4': {'freq': 1, 'poids': 0.1207}}, 'coordin': {'D4': {'freq': 1, 'poids': 0.1207}}, 'number': {'D4': {'freq': 2, 'poids': 0.1363}, 'D5': {'freq': 1, 'poids': 0.0477}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'scope': {'D4': {'freq': 1, 'poids': 0.1207}}, 'accuraci': {'D4': {'freq': 1, 'poids': 0.1207}}, 'requir': {'D4': {'freq': 1, 'poids': 0.1207}}, 'three': {'D4': {'freq': 1, 'poids': 0.1207}}, 'minut': {'D4': {'freq': 1, 'poids': 0.1207}}, 'two': {'D4': {'freq': 1, 'poids': 0.086}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'hour': {'D4': {'freq': 1, 'poids': 0.1207}}, 'depend': {'D4': {'freq': 1, 'poids': 0.086}, 'D5': {'freq': 1, 'poids': 0.0602}}, 'upon': {'D4': {'freq': 1, 'poids': 0.1207}}, 'secondari': {'D5': {'freq': 2, 'poids': 0.169}}, 'embed': {'D5': {'freq': 3, 'poids': 0.2535}}, 'ramp': {'D5': {'freq': 2, 'poids': 0.169}}, 'compress': {'D5': {'freq': 2, 'poids': 0.169}}, 'locat': {'D5': {'freq': 2, 'poids': 0.169}}, 'local': {'D5': {'freq': 2, 'poids': 0.169}}, 'superson': {'D5': {'freq': 1, 'poids': 0.0845}}, 'behind': {'D5': {'freq': 1, 'poids': 0.0845}}, 'bow': {'D5': {'freq': 2, 'poids': 0.169}}, 'disturb': {'D5': {'freq': 1, 'poids': 0.0845}}, 'may': {'D5': {'freq': 1, 'poids': 0.0845}}, 'view': {'D5': {'freq': 1, 'poids': 0.0845}}, 'newtonian': {'D5': {'freq': 7, 'poids': 0.5916}}, 'impact': {'D5': {'freq': 1, 'poids': 0.0845}}, 'thin': {'D5': {'freq': 1, 'poids': 0.0845}}, 'examin': {'D5': {'freq': 1, 'poids': 0.0845}}, 'applic': {'D5': {'freq': 1, 'poids': 0.0845}}, 'cone': {'D5': {'freq': 2, 'poids': 0.169}}, 'wedg': {'D5': {'freq': 1, 'poids': 0.0845}}, 'suggest': {'D5': {'freq': 1, 'poids': 0.0845}}, 'expect': {'D5': {'freq': 1, 'poids': 0.0845}}, 'give': {'D5': {'freq': 1, 'poids': 0.0602}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'pressur': {'D5': {'freq': 10, 'poids': 0.6021}, 'D6': {'freq': 4, 'poids': 0.6021}}, 'base': {'D5': {'freq': 1, 'poids': 0.0845}}, 'concept': {'D5': {'freq': 1, 'poids': 0.0845}}, 'predict': {'D5': {'freq': 1, 'poids': 0.0602}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'interest': {'D5': {'freq': 1, 'poids': 0.0845}}, 'thing': {'D5': {'freq': 1, 'poids': 0.0845}}, 'first': {'D5': {'freq': 1, 'poids': 0.0845}}, 'factor': {'D5': {'freq': 1, 'poids': 0.0845}}, '1.5': {'D5': {'freq': 1, 'poids': 0.0845}}, '3': {'D5': {'freq': 1, 'poids': 0.0845}}, 'exampl': {'D5': {'freq': 2, 'poids': 0.169}}, 'flare': {'D5': {'freq': 4, 'poids': 0.338}}, 'stabil': {'D5': {'freq': 2, 'poids': 0.169}}, 'blunt-nos': {'D5': {'freq': 2, 'poids': 0.169}}, 'revolut': {'D5': {'freq': 1, 'poids': 0.0845}}, 'lower': {'D5': {'freq': 1, 'poids': 0.0845}}, 'diminish': {'D5': {'freq': 1, 'poids': 0.0845}}, 'flight': {'D5': {'freq': 1, 'poids': 0.0845}}, 'speed': {'D5': {'freq': 2, 'poids': 0.1204}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'rang': {'D5': {'freq': 1, 'poids': 0.0845}}, 'vari': {'D5': {'freq': 2, 'poids': 0.169}}, 'nonuniform': {'D5': {'freq': 1, 'poids': 0.0845}}, 'incid': {'D5': {'freq': 1, 'poids': 0.0845}}, 'case': {'D5': {'freq': 2, 'poids': 0.169}}, 'flap': {'D5': {'freq': 2, 'poids': 0.169}}, 'mount': {'D5': {'freq': 1, 'poids': 0.0845}}, 'large-angl': {'D5': {'freq': 1, 'poids': 0.0845}}, 'coeffici': {'D5': {'freq': 3, 'poids': 0.2535}}, '1': {'D5': {'freq': 1, 'poids': 0.0845}}, '5': {'D5': {'freq': 2, 'poids': 0.169}}, 'variabl': {'D5': {'freq': 1, 'poids': 0.0845}}, 'entropi': {'D5': {'freq': 1, 'poids': 0.0845}}, 'greater': {'D5': {'freq': 1, 'poids': 0.0845}}, 'maximum': {'D5': {'freq': 1, 'poids': 0.0845}}, 'occur': {'D5': {'freq': 1, 'poids': 0.0845}}, 'process': {'D5': {'freq': 2, 'poids': 0.169}}, 'effici': {'D5': {'freq': 1, 'poids': 0.0845}}, 'singl': {'D5': {'freq': 1, 'poids': 0.0845}}, 'protrud': {'D5': {'freq': 1, 'poids': 0.0845}}, 'main': {'D5': {'freq': 1, 'poids': 0.0845}}, 'revert': {'D5': {'freq': 1, 'poids': 0.0845}}, 'valu': {'D5': {'freq': 2, 'poids': 0.169}}, 'initi': {'D5': {'freq': 1, 'poids': 0.0845}}, 'slope': {'D5': {'freq': 1, 'poids': 0.0845}}, 'normal-forc': {'D5': {'freq': 1, 'poids': 0.0845}}, 'pitching-mo': {'D5': {'freq': 1, 'poids': 0.0845}}, 'simplest': {'D5': {'freq': 1, 'poids': 0.0845}}, 'convent': {'D5': {'freq': 1, 'poids': 0.0845}}, 'dynam': {'D5': {'freq': 2, 'poids': 0.169}}, 'free-stream': {'D5': {'freq': 1, 'poids': 0.0845}}, 'take': {'D5': {'freq': 1, 'poids': 0.0845}}, 'low': {'D5': {'freq': 1, 'poids': 0.0602}, 'D6': {'freq': 1, 'poids': 0.1505}}, '0.1': {'D5': {'freq': 1, 'poids': 0.0845}}, 'measur': {'D6': {'freq': 2, 'poids': 0.4225}}, 'dimension': {'D6': {'freq': 1, 'poids': 0.2113}}, 'given': {'D6': {'freq': 1, 'poids': 0.2113}}, 'travers': {'D6': {'freq': 1, 'poids': 0.2113}}, '10': {'D6': {'freq': 1, 'poids': 0.2113}}, 'per': {'D6': {'freq': 1, 'poids': 0.2113}}, 'cent': {'D6': {'freq': 1, 'poids': 0.2113}}, 'rae': {'D6': {'freq': 1, 'poids': 0.2113}}, '101': {'D6': {'freq': 1, 'poids': 0.2113}}, 'section': {'D6': {'freq': 1, 'poids': 0.2113}}, 'reynold': {'D6': {'freq': 1, 'poids': 0.2113}}, '1.6x10': {'D6': {'freq': 1, 'poids': 0.2113}}, '3.2x10': {'D6': {'freq': 1, 'poids': 0.2113}}, 'drag': {'D6': {'freq': 2, 'poids': 0.4225}}, 'aerodynamic-centr': {'D6': {'freq': 1, 'poids': 0.2113}}, 'check': {'D6': {'freq': 1, 'poids': 0.2113}}, 'growth': {'D6': {'freq': 1, 'poids': 0.2113}}, 'turbul': {'D6': {'freq': 1, 'poids': 0.2113}}, 'known': {'D6': {'freq': 2, 'poids': 0.4225}}, 'conclud': {'D6': {'freq': 1, 'poids': 0.2113}}, 'still': {'D6': {'freq': 1, 'poids': 0.2113}}, 'littl': {'D6': {'freq': 1, 'poids': 0.2113}}, 'refin': {'D6': {'freq': 1, 'poids': 0.2113}}, 'accur': {'D6': {'freq': 1, 'poids': 0.2113}}, 'enough': {'D6': {'freq': 1, 'poids': 0.2113}}, 'center': {'D6': {'freq': 1, 'poids': 0.2113}}, 'actual': {'D6': {'freq': 1, 'poids': 0.2113}}}\n",
      "{'experiment': {'D1'}, 'investig': {'D1', 'D2'}, 'aerodynam': {'D1', 'D6'}, 'wing': {'D1', 'D6'}, 'slipstream': {'D1'}, 'studi': {'D1', 'D2'}, 'propel': {'D1'}, 'made': {'D3', 'D1'}, 'order': {'D1'}, 'determin': {'D1'}, 'spanwis': {'D1'}, 'distribut': {'D3', 'D4', 'D1', 'D6'}, 'lift': {'D1', 'D6'}, 'increas': {'D5', 'D1'}, 'due': {'D1'}, 'differ': {'D5', 'D1', 'D2'}, 'angl': {'D1'}, 'attack': {'D1'}, 'free': {'D1', 'D2'}, 'stream': {'D5', 'D1', 'D2'}, 'veloc': {'D3', 'D4', 'D1'}, 'ratio': {'D5', 'D1'}, 'result': {'D5', 'D1', 'D6'}, 'intend': {'D1'}, 'part': {'D1'}, 'evalu': {'D1'}, 'basi': {'D4', 'D1'}, 'theoret': {'D1'}, 'treatment': {'D1'}, 'problem': {'D3', 'D4', 'D1', 'D2'}, 'compar': {'D1'}, 'span': {'D1'}, 'load': {'D1'}, 'curv': {'D5', 'D1', 'D2'}, 'togeth': {'D1'}, 'support': {'D1'}, 'evid': {'D1'}, 'show': {'D3', 'D4', 'D1'}, 'substanti': {'D1'}, 'increment': {'D1'}, 'produc': {'D1'}, 'destal': {'D1'}, 'boundary-layer-control': {'D1'}, 'effect': {'D3', 'D1', 'D6', 'D2'}, 'integr': {'D4', 'D1', 'D6'}, 'remain': {'D1'}, 'subtract': {'D1'}, 'found': {'D1'}, 'agre': {'D1'}, 'well': {'D1'}, 'potenti': {'D1'}, 'flow': {'D1', 'D3', 'D5', 'D4', 'D2'}, 'theori': {'D5', 'D1'}, 'empir': {'D1'}, 'specif': {'D1'}, 'configur': {'D1'}, 'experi': {'D1'}, 'simpl': {'D5', 'D2'}, 'shear': {'D3', 'D2'}, 'past': {'D2'}, 'flat': {'D3', 'D2'}, 'plate': {'D3', 'D2'}, 'incompress': {'D3', 'D2'}, 'fluid': {'D3', 'D2'}, 'small': {'D2'}, 'viscos': {'D6', 'D2'}, 'high-spe': {'D2'}, 'viscou': {'D2'}, 'two-dimension': {'D3', 'D6', 'D2'}, 'bodi': {'D5', 'D4', 'D2'}, 'usual': {'D4', 'D2'}, 'necessari': {'D2'}, 'consid': {'D3', 'D5', 'D2'}, 'shock': {'D5', 'D2'}, 'wave': {'D5', 'D2'}, 'emit': {'D2'}, 'nose': {'D2'}, 'lead': {'D4', 'D2'}, 'edg': {'D2'}, 'consequ': {'D4', 'D2'}, 'exist': {'D2'}, 'inviscid': {'D2'}, 'rotat': {'D2'}, 'region': {'D5', 'D2'}, 'boundari': {'D3', 'D4', 'D6', 'D2'}, 'layer': {'D3', 'D5', 'D6', 'D2'}, 'situat': {'D2'}, 'aris': {'D2'}, 'instanc': {'D2'}, 'hyperson': {'D5', 'D2'}, 'somewhat': {'D2'}, 'prandtl': {'D2'}, 'classic': {'D2'}, 'boundary-lay': {'D3', 'D6', 'D2'}, 'origin': {'D2'}, 'outsid': {'D2'}, 'irrot': {'D2'}, 'must': {'D2'}, 'possibl': {'D5', 'D2'}, 'vortic': {'D3', 'D2'}, 'recent': {'D2'}, 'discuss': {'D2'}, 'ferri': {'D2'}, 'libbi': {'D2'}, 'present': {'D4', 'D2'}, 'paper': {'D2'}, 'shown': {'D2'}, 'treat': {'D4', 'D2'}, 'approxim': {'D3', 'D5', 'D2'}, 'novel': {'D2'}, 'featur': {'D2'}, 'constant': {'D2'}, 'restrict': {'D2'}, 'steadi': {'D3', 'D2'}, 'solut': {'D3', 'D4'}, 'laminar': {'D3'}, 'equat': {'D3', 'D4', 'D5'}, 'thick': {'D3'}, 'skin': {'D3'}, 'friction': {'D3'}, 'obtain': {'D3'}, 'karman-pohlhausen': {'D3'}, 'techniqu': {'D3'}, 'comparison': {'D3'}, 'uniform': {'D3', 'D5'}, 'also': {'D3'}, 'exact': {'D4'}, 'neumann': {'D4'}, 'calcul': {'D5', 'D4', 'D6'}, 'non': {'D4'}, 'circulatori': {'D4'}, 'plane': {'D4'}, 'axial': {'D5', 'D4'}, 'symmetr': {'D4'}, 'within': {'D4'}, 'arbitrari': {'D4'}, 'gener': {'D5', 'D4'}, 'method': {'D4', 'D6'}, 'solv': {'D4'}, 'second': {'D4'}, 'boundary-valu': {'D4'}, 'develop': {'D5', 'D4'}, 'appli': {'D4'}, 'low-spe': {'D4'}, 'almost': {'D4'}, 'shape': {'D4'}, 'provid': {'D4'}, 'either': {'D4'}, 'symmetri': {'D4'}, 'solid-bodi': {'D4'}, 'inlet': {'D4'}, 'pure': {'D4'}, 'intern': {'D4'}, 'capabl': {'D4'}, 'deal': {'D4'}, 'sever': {'D4'}, 'presenc': {'D4'}, 'one': {'D4'}, 'anoth': {'D4'}, 'interfer': {'D4'}, 'eas': {'D4'}, 'need': {'D4', 'D6'}, 'solid': {'D4'}, 'involv': {'D4'}, 'area': {'D5', 'D4'}, 'suction': {'D4'}, 'comput': {'D4'}, 'point': {'D4'}, 'surfac': {'D5', 'D4'}, 'entir': {'D4'}, 'field': {'D5', 'D4'}, 'sourc': {'D4'}, 'use': {'D5', 'D4', 'D6'}, 'fredholm': {'D4'}, 'kind': {'D4'}, 'set': {'D4'}, 'linear': {'D4'}, 'algebra': {'D4'}, 'modifi': {'D4'}, 'seidel': {'D4'}, 'time': {'D4'}, 'program': {'D4'}, 'ibm': {'D4'}, '704': {'D4'}, 'edpm': {'D4'}, 'previous': {'D4'}, 'mention': {'D4'}, 'characterist': {'D4', 'D6'}, 'whose': {'D4'}, 'profil': {'D4'}, 'defin': {'D4'}, 'satisfactorili': {'D4'}, '300': {'D4'}, 'coordin': {'D4'}, 'number': {'D5', 'D4', 'D6'}, 'scope': {'D4'}, 'accuraci': {'D4'}, 'requir': {'D4'}, 'three': {'D4'}, 'minut': {'D4'}, 'two': {'D4', 'D6'}, 'hour': {'D4'}, 'depend': {'D5', 'D4'}, 'upon': {'D4'}, 'secondari': {'D5'}, 'embed': {'D5'}, 'ramp': {'D5'}, 'compress': {'D5'}, 'locat': {'D5'}, 'local': {'D5'}, 'superson': {'D5'}, 'behind': {'D5'}, 'bow': {'D5'}, 'disturb': {'D5'}, 'may': {'D5'}, 'view': {'D5'}, 'newtonian': {'D5'}, 'impact': {'D5'}, 'thin': {'D5'}, 'examin': {'D5'}, 'applic': {'D5'}, 'cone': {'D5'}, 'wedg': {'D5'}, 'suggest': {'D5'}, 'expect': {'D5'}, 'give': {'D5', 'D6'}, 'pressur': {'D5', 'D6'}, 'base': {'D5'}, 'concept': {'D5'}, 'predict': {'D5', 'D6'}, 'interest': {'D5'}, 'thing': {'D5'}, 'first': {'D5'}, 'factor': {'D5'}, '1.5': {'D5'}, '3': {'D5'}, 'exampl': {'D5'}, 'flare': {'D5'}, 'stabil': {'D5'}, 'blunt-nos': {'D5'}, 'revolut': {'D5'}, 'lower': {'D5'}, 'diminish': {'D5'}, 'flight': {'D5'}, 'speed': {'D5', 'D6'}, 'rang': {'D5'}, 'vari': {'D5'}, 'nonuniform': {'D5'}, 'incid': {'D5'}, 'case': {'D5'}, 'flap': {'D5'}, 'mount': {'D5'}, 'large-angl': {'D5'}, 'coeffici': {'D5'}, '1': {'D5'}, '5': {'D5'}, 'variabl': {'D5'}, 'entropi': {'D5'}, 'greater': {'D5'}, 'maximum': {'D5'}, 'occur': {'D5'}, 'process': {'D5'}, 'effici': {'D5'}, 'singl': {'D5'}, 'protrud': {'D5'}, 'main': {'D5'}, 'revert': {'D5'}, 'valu': {'D5'}, 'initi': {'D5'}, 'slope': {'D5'}, 'normal-forc': {'D5'}, 'pitching-mo': {'D5'}, 'simplest': {'D5'}, 'convent': {'D5'}, 'dynam': {'D5'}, 'free-stream': {'D5'}, 'take': {'D5'}, 'low': {'D5', 'D6'}, '0.1': {'D5'}, 'measur': {'D6'}, 'dimension': {'D6'}, 'given': {'D6'}, 'travers': {'D6'}, '10': {'D6'}, 'per': {'D6'}, 'cent': {'D6'}, 'rae': {'D6'}, '101': {'D6'}, 'section': {'D6'}, 'reynold': {'D6'}, '1.6x10': {'D6'}, '3.2x10': {'D6'}, 'drag': {'D6'}, 'aerodynamic-centr': {'D6'}, 'check': {'D6'}, 'growth': {'D6'}, 'turbul': {'D6'}, 'known': {'D6'}, 'conclud': {'D6'}, 'still': {'D6'}, 'littl': {'D6'}, 'refin': {'D6'}, 'accur': {'D6'}, 'enough': {'D6'}, 'center': {'D6'}, 'actual': {'D6'}}\n",
      "term avant ['effect', 'AND', 'distribution']\n",
      "term apres ['effect', 'AND', 'distribution']\n",
      "{'D1', 'D6', 'D3', 'D5', 'D4', 'D2'}\n",
      "Résultat : {'D1': False, 'D6': False, 'D3': False, 'D5': False, 'D4': False, 'D2': False}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    app.setStyleSheet(\"\"\"\n",
    "    QMainWindow {\n",
    "        background-color: #f5f5f5;\n",
    "    }\n",
    "    QLabel {\n",
    "        color: #333333;\n",
    "        font-size: 14px;\n",
    "    }\n",
    "    QLineEdit {\n",
    "        border: 1px solid #CCCCCC;\n",
    "        border-radius: 5px;\n",
    "        padding: 5px;\n",
    "    }\n",
    "    QPushButton {\n",
    "        background-color: #4CAF50;\n",
    "        color: white;\n",
    "        font-size: 14px;\n",
    "        padding: 5px 10px;\n",
    "        border-radius: 5px;\n",
    "    }\n",
    "    QPushButton:hover {\n",
    "        background-color: #45a049;\n",
    "    }\n",
    "    \n",
    "    QRadioButton {\n",
    "        font-size: 13px;\n",
    "    }\n",
    "    QGroupBox {\n",
    "        font-size: 15px;\n",
    "        color: #333333;\n",
    "        border: 1px solid #CCCCCC;\n",
    "        border-radius: 8px;\n",
    "        margin-top: 10px;\n",
    "        padding: 10px;\n",
    "    }\n",
    "    QTextEdit {\n",
    "        background-color: #f0f0f0;\n",
    "        border: 1px solid #CCCCCC;\n",
    "        border-radius: 5px;\n",
    "        padding: 5px;\n",
    "    }\n",
    "    QTableWidget {\n",
    "        background-color: #FFFFFF;\n",
    "        border: 1px solid #CCCCCC;\n",
    "        border-radius: 5px;\n",
    "        padding: 2px;\n",
    "        gridline-color: #E0E0E0;\n",
    "    }\n",
    "    QTableWidget::item {\n",
    "        padding: 5px;\n",
    "        border-bottom: 1px solid #E0E0E0;\n",
    "    }\n",
    "    QHeaderView::section {\n",
    "        background-color: #f0f0f0;\n",
    "        padding: 5px;\n",
    "        border: 1px solid #CCCCCC;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "\n",
    "    QLabel {\n",
    "        margin-left: 20px;\n",
    "        background-color: transparent;\n",
    "        border: none;\n",
    "        font-size: 14px;\n",
    "        font-family: Arial, sans-serif;\n",
    "    }\n",
    "    \n",
    "\"\"\")\n",
    "\n",
    "    window = SearchApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experimental': {'D1': {'freq': 2, 'poids': 0.2817}}, 'investigation': {'D1': {'freq': 1, 'poids': 0.1408}}, 'aerodynamics': {'D1': {'freq': 1, 'poids': 0.1408}}, 'wing': {'D1': {'freq': 3, 'poids': 0.301}, 'D6': {'freq': 2, 'poids': 0.301}}, 'slipstream': {'D1': {'freq': 5, 'poids': 0.7042}}, '.': {'D1': {'freq': 6, 'poids': 0.301}, 'D2': {'freq': 10, 'poids': 0.301}, 'D3': {'freq': 4, 'poids': 0.301}, 'D4': {'freq': 12, 'poids': 0.301}, 'D5': {'freq': 12, 'poids': 0.301}, 'D6': {'freq': 4, 'poids': 0.301}}, 'study': {'D1': {'freq': 1, 'poids': 0.1003}, 'D2': {'freq': 2, 'poids': 0.1204}}, 'propeller': {'D1': {'freq': 1, 'poids': 0.1408}}, 'made': {'D1': {'freq': 2, 'poids': 0.2007}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'order': {'D1': {'freq': 1, 'poids': 0.1408}}, 'determine': {'D1': {'freq': 1, 'poids': 0.1408}}, 'spanwise': {'D1': {'freq': 1, 'poids': 0.1408}}, 'distribution': {'D1': {'freq': 1, 'poids': 0.0663}, 'D3': {'freq': 1, 'poids': 0.0995}, 'D4': {'freq': 1, 'poids': 0.0332}, 'D6': {'freq': 1, 'poids': 0.0995}}, 'lift': {'D1': {'freq': 3, 'poids': 0.4225}}, 'increase': {'D1': {'freq': 1, 'poids': 0.1408}}, 'due': {'D1': {'freq': 2, 'poids': 0.2817}}, 'different': {'D1': {'freq': 3, 'poids': 0.301}, 'D2': {'freq': 1, 'poids': 0.0602}}, 'angles': {'D1': {'freq': 1, 'poids': 0.1408}}, 'attack': {'D1': {'freq': 1, 'poids': 0.1408}}, 'free': {'D1': {'freq': 1, 'poids': 0.1003}, 'D2': {'freq': 3, 'poids': 0.1806}}, 'stream': {'D1': {'freq': 1, 'poids': 0.1003}, 'D2': {'freq': 3, 'poids': 0.1806}}, 'velocity': {'D1': {'freq': 1, 'poids': 0.1003}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'ratios': {'D1': {'freq': 1, 'poids': 0.1408}}, 'results': {'D1': {'freq': 1, 'poids': 0.1003}, 'D6': {'freq': 2, 'poids': 0.301}}, 'intended': {'D1': {'freq': 1, 'poids': 0.1408}}, 'part': {'D1': {'freq': 2, 'poids': 0.2817}}, 'evaluation': {'D1': {'freq': 2, 'poids': 0.2817}}, 'basis': {'D1': {'freq': 1, 'poids': 0.1003}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'theoretical': {'D1': {'freq': 1, 'poids': 0.1408}}, 'treatments': {'D1': {'freq': 1, 'poids': 0.1408}}, 'problem': {'D1': {'freq': 1, 'poids': 0.0663}, 'D2': {'freq': 4, 'poids': 0.1592}, 'D3': {'freq': 1, 'poids': 0.0995}, 'D4': {'freq': 2, 'poids': 0.0663}}, 'comparative': {'D1': {'freq': 1, 'poids': 0.1408}}, 'span': {'D1': {'freq': 1, 'poids': 0.1408}}, 'loading': {'D1': {'freq': 1, 'poids': 0.1408}}, 'curves,': {'D1': {'freq': 1, 'poids': 0.1408}}, 'together': {'D1': {'freq': 1, 'poids': 0.1408}}, 'supporting': {'D1': {'freq': 1, 'poids': 0.1408}}, 'evidence,': {'D1': {'freq': 1, 'poids': 0.1408}}, 'showed': {'D1': {'freq': 1, 'poids': 0.1408}}, 'substantial': {'D1': {'freq': 1, 'poids': 0.1408}}, 'increment': {'D1': {'freq': 1, 'poids': 0.1408}}, 'produced': {'D1': {'freq': 1, 'poids': 0.1408}}, '/destalling/': {'D1': {'freq': 1, 'poids': 0.1408}}, 'boundary-layer-control': {'D1': {'freq': 1, 'poids': 0.1408}}, 'effect': {'D1': {'freq': 1, 'poids': 0.0795}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'integrated': {'D1': {'freq': 1, 'poids': 0.1003}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'remaining': {'D1': {'freq': 1, 'poids': 0.1408}}, 'increment,': {'D1': {'freq': 1, 'poids': 0.1408}}, 'subtracting': {'D1': {'freq': 1, 'poids': 0.1408}}, 'destalling': {'D1': {'freq': 2, 'poids': 0.2817}}, 'lift,': {'D1': {'freq': 1, 'poids': 0.1003}, 'D6': {'freq': 2, 'poids': 0.301}}, 'found': {'D1': {'freq': 1, 'poids': 0.1408}}, 'agree': {'D1': {'freq': 1, 'poids': 0.1408}}, 'well': {'D1': {'freq': 1, 'poids': 0.1408}}, 'potential': {'D1': {'freq': 1, 'poids': 0.1408}}, 'flow': {'D1': {'freq': 1, 'poids': 0.0571}, 'D2': {'freq': 6, 'poids': 0.2055}, 'D3': {'freq': 3, 'poids': 0.2568}, 'D4': {'freq': 4, 'poids': 0.1141}, 'D5': {'freq': 5, 'poids': 0.1427}}, 'theory': {'D1': {'freq': 1, 'poids': 0.1003}, 'D5': {'freq': 4, 'poids': 0.2007}}, 'empirical': {'D1': {'freq': 1, 'poids': 0.1408}}, 'effects': {'D1': {'freq': 1, 'poids': 0.0795}, 'D2': {'freq': 1, 'poids': 0.0477}, 'D6': {'freq': 2, 'poids': 0.2386}}, 'specific': {'D1': {'freq': 1, 'poids': 0.1408}}, 'configuration': {'D1': {'freq': 1, 'poids': 0.1408}}, 'experiment': {'D1': {'freq': 1, 'poids': 0.1408}}, 'simple': {'D2': {'freq': 2, 'poids': 0.1204}, 'D5': {'freq': 2, 'poids': 0.1003}}, 'shear': {'D2': {'freq': 2, 'poids': 0.1204}, 'D3': {'freq': 2, 'poids': 0.301}}, 'past': {'D2': {'freq': 4, 'poids': 0.338}}, 'flat': {'D2': {'freq': 3, 'poids': 0.1806}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'plate': {'D2': {'freq': 3, 'poids': 0.1806}, 'D3': {'freq': 2, 'poids': 0.301}}, 'incompressible': {'D2': {'freq': 2, 'poids': 0.1204}, 'D3': {'freq': 2, 'poids': 0.301}}, 'fluid': {'D2': {'freq': 2, 'poids': 0.1204}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'small': {'D2': {'freq': 2, 'poids': 0.169}}, 'viscosity': {'D2': {'freq': 2, 'poids': 0.1204}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'high-speed': {'D2': {'freq': 1, 'poids': 0.0845}}, 'viscous': {'D2': {'freq': 2, 'poids': 0.169}}, 'two-dimensional': {'D2': {'freq': 2, 'poids': 0.0954}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'body': {'D2': {'freq': 2, 'poids': 0.1204}, 'D4': {'freq': 3, 'poids': 0.1505}}, 'usually': {'D2': {'freq': 1, 'poids': 0.0602}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'necessary': {'D2': {'freq': 1, 'poids': 0.0845}}, 'consider': {'D2': {'freq': 1, 'poids': 0.0845}}, 'curved': {'D2': {'freq': 1, 'poids': 0.0845}}, 'shock': {'D2': {'freq': 2, 'poids': 0.1204}, 'D5': {'freq': 5, 'poids': 0.2509}}, 'wave': {'D2': {'freq': 2, 'poids': 0.1204}, 'D5': {'freq': 2, 'poids': 0.1003}}, 'emitting': {'D2': {'freq': 1, 'poids': 0.0845}}, 'nose': {'D2': {'freq': 1, 'poids': 0.0845}}, 'leading': {'D2': {'freq': 1, 'poids': 0.0845}}, 'edge': {'D2': {'freq': 1, 'poids': 0.0845}}, 'consequently,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'exists': {'D2': {'freq': 1, 'poids': 0.0845}}, 'inviscid': {'D2': {'freq': 3, 'poids': 0.2535}}, 'rotational': {'D2': {'freq': 2, 'poids': 0.169}}, 'region': {'D2': {'freq': 1, 'poids': 0.0602}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'boundary': {'D2': {'freq': 2, 'poids': 0.0954}, 'D3': {'freq': 3, 'poids': 0.3578}, 'D6': {'freq': 3, 'poids': 0.3578}}, 'layer': {'D2': {'freq': 2, 'poids': 0.0796}, 'D3': {'freq': 4, 'poids': 0.3979}, 'D5': {'freq': 2, 'poids': 0.0663}, 'D6': {'freq': 3, 'poids': 0.2985}}, 'situation': {'D2': {'freq': 2, 'poids': 0.169}}, 'arises,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'instance,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'hypersonic': {'D2': {'freq': 2, 'poids': 0.1204}, 'D5': {'freq': 3, 'poids': 0.1505}}, 'somewhat': {'D2': {'freq': 1, 'poids': 0.0845}}, \"prandtl's\": {'D2': {'freq': 2, 'poids': 0.169}}, 'classical': {'D2': {'freq': 1, 'poids': 0.0845}}, 'boundary-layer': {'D2': {'freq': 3, 'poids': 0.1431}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D6': {'freq': 3, 'poids': 0.3578}}, 'original': {'D2': {'freq': 1, 'poids': 0.0845}}, 'outside': {'D2': {'freq': 1, 'poids': 0.0845}}, 'irrotational': {'D2': {'freq': 1, 'poids': 0.0845}}, 'must': {'D2': {'freq': 1, 'poids': 0.0845}}, 'considered': {'D2': {'freq': 1, 'poids': 0.0477}, 'D3': {'freq': 1, 'poids': 0.1193}, 'D5': {'freq': 1, 'poids': 0.0398}}, 'possible': {'D2': {'freq': 1, 'poids': 0.0602}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'vorticity': {'D2': {'freq': 2, 'poids': 0.1204}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'recently': {'D2': {'freq': 1, 'poids': 0.0845}}, 'discussed': {'D2': {'freq': 1, 'poids': 0.0845}}, 'ferri': {'D2': {'freq': 1, 'poids': 0.0845}}, 'libby': {'D2': {'freq': 1, 'poids': 0.0845}}, 'present': {'D2': {'freq': 1, 'poids': 0.0602}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'paper,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'investigated': {'D2': {'freq': 1, 'poids': 0.0845}}, 'shown': {'D2': {'freq': 1, 'poids': 0.0845}}, 'treated': {'D2': {'freq': 1, 'poids': 0.0602}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'approximation,': {'D2': {'freq': 1, 'poids': 0.0845}}, 'novel': {'D2': {'freq': 1, 'poids': 0.0845}}, 'feature': {'D2': {'freq': 1, 'poids': 0.0845}}, 'constant': {'D2': {'freq': 1, 'poids': 0.0845}}, 'discussion': {'D2': {'freq': 1, 'poids': 0.0845}}, 'restricted': {'D2': {'freq': 1, 'poids': 0.0845}}, 'steady': {'D2': {'freq': 1, 'poids': 0.0602}, 'D3': {'freq': 1, 'poids': 0.1505}}, 'approximate': {'D3': {'freq': 1, 'poids': 0.2113}}, 'solutions': {'D3': {'freq': 2, 'poids': 0.301}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'laminar': {'D3': {'freq': 1, 'poids': 0.2113}}, 'equations': {'D3': {'freq': 1, 'poids': 0.1505}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'boundary-': {'D3': {'freq': 1, 'poids': 0.2113}}, 'thickness,': {'D3': {'freq': 1, 'poids': 0.2113}}, 'skin': {'D3': {'freq': 1, 'poids': 0.2113}}, 'friction,': {'D3': {'freq': 1, 'poids': 0.2113}}, 'obtained': {'D3': {'freq': 1, 'poids': 0.2113}}, 'karman-pohlhausen': {'D3': {'freq': 1, 'poids': 0.2113}}, 'technique': {'D3': {'freq': 1, 'poids': 0.2113}}, 'comparison': {'D3': {'freq': 1, 'poids': 0.2113}}, 'uniform': {'D3': {'freq': 1, 'poids': 0.1505}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'also': {'D3': {'freq': 1, 'poids': 0.2113}}, 'show': {'D3': {'freq': 1, 'poids': 0.1505}, 'D4': {'freq': 1, 'poids': 0.0502}}, 'exact': {'D4': {'freq': 2, 'poids': 0.1408}}, 'solution': {'D4': {'freq': 3, 'poids': 0.2113}}, 'neumann': {'D4': {'freq': 2, 'poids': 0.1408}}, 'calculation': {'D4': {'freq': 2, 'poids': 0.1003}, 'D6': {'freq': 2, 'poids': 0.301}}, 'non-': {'D4': {'freq': 1, 'poids': 0.0704}}, 'circulatory': {'D4': {'freq': 1, 'poids': 0.0704}}, 'plane': {'D4': {'freq': 2, 'poids': 0.1408}}, 'axially': {'D4': {'freq': 1, 'poids': 0.0704}}, 'symmetric': {'D4': {'freq': 1, 'poids': 0.0704}}, 'flows': {'D4': {'freq': 3, 'poids': 0.2113}}, 'within': {'D4': {'freq': 2, 'poids': 0.1408}}, 'arbitrary': {'D4': {'freq': 1, 'poids': 0.0704}}, 'boundaries': {'D4': {'freq': 2, 'poids': 0.1408}}, 'general': {'D4': {'freq': 1, 'poids': 0.0704}}, 'method': {'D4': {'freq': 4, 'poids': 0.2817}}, 'solving': {'D4': {'freq': 1, 'poids': 0.0704}}, 'second': {'D4': {'freq': 2, 'poids': 0.1408}}, 'boundary-value': {'D4': {'freq': 1, 'poids': 0.0704}}, 'developed': {'D4': {'freq': 1, 'poids': 0.0502}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'applied': {'D4': {'freq': 1, 'poids': 0.0704}}, 'low-speed': {'D4': {'freq': 1, 'poids': 0.0704}}, 'bodies': {'D4': {'freq': 2, 'poids': 0.1003}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'almost': {'D4': {'freq': 1, 'poids': 0.0704}}, 'shape,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'provided': {'D4': {'freq': 1, 'poids': 0.0704}}, 'either': {'D4': {'freq': 1, 'poids': 0.0704}}, 'axial': {'D4': {'freq': 1, 'poids': 0.0502}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'symmetry': {'D4': {'freq': 1, 'poids': 0.0704}}, 'solid-body,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'inlet,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'purely': {'D4': {'freq': 1, 'poids': 0.0704}}, 'internal': {'D4': {'freq': 1, 'poids': 0.0704}}, 'problems': {'D4': {'freq': 2, 'poids': 0.1408}}, 'solved': {'D4': {'freq': 2, 'poids': 0.1408}}, 'capable': {'D4': {'freq': 1, 'poids': 0.0704}}, 'dealing': {'D4': {'freq': 1, 'poids': 0.0704}}, 'several': {'D4': {'freq': 1, 'poids': 0.0704}}, 'presence': {'D4': {'freq': 1, 'poids': 0.0704}}, 'one': {'D4': {'freq': 1, 'poids': 0.0704}}, 'another,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'consequently': {'D4': {'freq': 1, 'poids': 0.0704}}, 'interference': {'D4': {'freq': 1, 'poids': 0.0704}}, 'ease': {'D4': {'freq': 1, 'poids': 0.0704}}, 'need': {'D4': {'freq': 1, 'poids': 0.0704}}, 'solid,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'is,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'involving': {'D4': {'freq': 1, 'poids': 0.0704}}, 'area': {'D4': {'freq': 1, 'poids': 0.0704}}, 'suction': {'D4': {'freq': 1, 'poids': 0.0704}}, 'calculated': {'D4': {'freq': 1, 'poids': 0.0398}, 'D5': {'freq': 1, 'poids': 0.0398}, 'D6': {'freq': 1, 'poids': 0.1193}}, 'velocities': {'D4': {'freq': 1, 'poids': 0.0704}}, 'computed': {'D4': {'freq': 1, 'poids': 0.0704}}, 'points': {'D4': {'freq': 3, 'poids': 0.2113}}, 'surface': {'D4': {'freq': 2, 'poids': 0.1003}, 'D5': {'freq': 3, 'poids': 0.1505}}, 'entire': {'D4': {'freq': 1, 'poids': 0.0704}}, 'field': {'D4': {'freq': 1, 'poids': 0.0704}}, 'source': {'D4': {'freq': 1, 'poids': 0.0704}}, 'used': {'D4': {'freq': 2, 'poids': 0.1003}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'leads': {'D4': {'freq': 1, 'poids': 0.0704}}, 'fredholm': {'D4': {'freq': 1, 'poids': 0.0704}}, 'integral': {'D4': {'freq': 1, 'poids': 0.0704}}, 'equation': {'D4': {'freq': 1, 'poids': 0.0502}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'kind,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'set': {'D4': {'freq': 1, 'poids': 0.0704}}, 'linear': {'D4': {'freq': 1, 'poids': 0.0704}}, 'algebraic': {'D4': {'freq': 1, 'poids': 0.0704}}, 'equations,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'modified': {'D4': {'freq': 1, 'poids': 0.0704}}, 'seidel': {'D4': {'freq': 1, 'poids': 0.0704}}, 'time': {'D4': {'freq': 1, 'poids': 0.0704}}, 'programed': {'D4': {'freq': 1, 'poids': 0.0704}}, 'ibm': {'D4': {'freq': 1, 'poids': 0.0704}}, '704': {'D4': {'freq': 1, 'poids': 0.0704}}, 'edpm': {'D4': {'freq': 1, 'poids': 0.0704}}, 'solve': {'D4': {'freq': 1, 'poids': 0.0704}}, 'previously': {'D4': {'freq': 1, 'poids': 0.0704}}, 'mentioned': {'D4': {'freq': 1, 'poids': 0.0704}}, 'characteristics': {'D4': {'freq': 1, 'poids': 0.0502}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'whose': {'D4': {'freq': 1, 'poids': 0.0704}}, 'profile': {'D4': {'freq': 1, 'poids': 0.0704}}, 'defined': {'D4': {'freq': 1, 'poids': 0.0704}}, 'satisfactorily': {'D4': {'freq': 1, 'poids': 0.0704}}, '300': {'D4': {'freq': 1, 'poids': 0.0704}}, 'coordinate': {'D4': {'freq': 1, 'poids': 0.0704}}, 'number': {'D4': {'freq': 2, 'poids': 0.1003}, 'D5': {'freq': 1, 'poids': 0.0502}}, 'presented,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'scope': {'D4': {'freq': 1, 'poids': 0.0704}}, 'accuracy': {'D4': {'freq': 1, 'poids': 0.0704}}, 'computations': {'D4': {'freq': 1, 'poids': 0.0704}}, 'require': {'D4': {'freq': 1, 'poids': 0.0704}}, 'three': {'D4': {'freq': 1, 'poids': 0.0704}}, 'minutes': {'D4': {'freq': 1, 'poids': 0.0704}}, 'two': {'D4': {'freq': 1, 'poids': 0.0502}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'hours,': {'D4': {'freq': 1, 'poids': 0.0704}}, 'depending': {'D4': {'freq': 1, 'poids': 0.0704}}, 'upon': {'D4': {'freq': 1, 'poids': 0.0704}}, 'shape': {'D4': {'freq': 1, 'poids': 0.0704}}, 'define': {'D4': {'freq': 1, 'poids': 0.0704}}, 'secondary': {'D5': {'freq': 2, 'poids': 0.1408}}, 'fields': {'D5': {'freq': 1, 'poids': 0.0704}}, 'embedded': {'D5': {'freq': 3, 'poids': 0.2113}}, 'layers': {'D5': {'freq': 1, 'poids': 0.0704}}, 'ramp': {'D5': {'freq': 2, 'poids': 0.1408}}, 'compression': {'D5': {'freq': 2, 'poids': 0.1408}}, 'located': {'D5': {'freq': 1, 'poids': 0.0704}}, 'locally': {'D5': {'freq': 1, 'poids': 0.0704}}, 'supersonic': {'D5': {'freq': 1, 'poids': 0.0704}}, 'behind': {'D5': {'freq': 1, 'poids': 0.0704}}, 'bow': {'D5': {'freq': 2, 'poids': 0.1408}}, 'wave,': {'D5': {'freq': 2, 'poids': 0.1408}}, 'generates': {'D5': {'freq': 1, 'poids': 0.0704}}, 'disturbance': {'D5': {'freq': 1, 'poids': 0.0704}}, 'may': {'D5': {'freq': 1, 'poids': 0.0704}}, 'viewed': {'D5': {'freq': 1, 'poids': 0.0704}}, 'newtonian': {'D5': {'freq': 7, 'poids': 0.493}}, 'impact': {'D5': {'freq': 1, 'poids': 0.0704}}, 'thin': {'D5': {'freq': 1, 'poids': 0.0704}}, 'examination': {'D5': {'freq': 1, 'poids': 0.0704}}, 'applicability': {'D5': {'freq': 1, 'poids': 0.0704}}, 'cones': {'D5': {'freq': 1, 'poids': 0.0704}}, 'wedges': {'D5': {'freq': 1, 'poids': 0.0704}}, 'streams': {'D5': {'freq': 1, 'poids': 0.0704}}, 'suggests': {'D5': {'freq': 1, 'poids': 0.0704}}, 'expected': {'D5': {'freq': 1, 'poids': 0.0704}}, 'give': {'D5': {'freq': 1, 'poids': 0.0502}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'useful': {'D5': {'freq': 1, 'poids': 0.0704}}, 'approximation': {'D5': {'freq': 1, 'poids': 0.0704}}, 'pressures': {'D5': {'freq': 4, 'poids': 0.2817}}, 'pressure': {'D5': {'freq': 6, 'poids': 0.301}, 'D6': {'freq': 4, 'poids': 0.6021}}, 'based': {'D5': {'freq': 1, 'poids': 0.0704}}, 'concept': {'D5': {'freq': 1, 'poids': 0.0704}}, 'predicts': {'D5': {'freq': 1, 'poids': 0.0704}}, 'interesting': {'D5': {'freq': 1, 'poids': 0.0704}}, 'things': {'D5': {'freq': 1, 'poids': 0.0704}}, '..': {'D5': {'freq': 1, 'poids': 0.0704}}, 'first,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'differ': {'D5': {'freq': 2, 'poids': 0.1408}}, 'factors': {'D5': {'freq': 1, 'poids': 0.0704}}, '1.5': {'D5': {'freq': 1, 'poids': 0.0704}}, '3,.': {'D5': {'freq': 1, 'poids': 0.0704}}, 'example,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'flare': {'D5': {'freq': 4, 'poids': 0.2817}}, 'stabilizers': {'D5': {'freq': 1, 'poids': 0.0704}}, 'blunt-nosed': {'D5': {'freq': 2, 'poids': 0.1408}}, 'revolution,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'lower': {'D5': {'freq': 1, 'poids': 0.0704}}, 'diminish': {'D5': {'freq': 1, 'poids': 0.0704}}, 'increasing': {'D5': {'freq': 1, 'poids': 0.0704}}, 'flight': {'D5': {'freq': 1, 'poids': 0.0704}}, 'speed': {'D5': {'freq': 2, 'poids': 0.1003}, 'D6': {'freq': 1, 'poids': 0.1505}}, 'range': {'D5': {'freq': 1, 'poids': 0.0704}}, 'vary': {'D5': {'freq': 2, 'poids': 0.1408}}, 'result': {'D5': {'freq': 1, 'poids': 0.0704}}, 'nonuniformity': {'D5': {'freq': 1, 'poids': 0.0704}}, 'incident': {'D5': {'freq': 1, 'poids': 0.0704}}, 'stream,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'depend': {'D5': {'freq': 1, 'poids': 0.0704}}, 'location': {'D5': {'freq': 1, 'poids': 0.0704}}, 'case': {'D5': {'freq': 2, 'poids': 0.1408}}, 'flap': {'D5': {'freq': 2, 'poids': 0.1408}}, 'mounted': {'D5': {'freq': 1, 'poids': 0.0704}}, 'large-angled': {'D5': {'freq': 1, 'poids': 0.0704}}, 'cone,': {'D5': {'freq': 1, 'poids': 0.0704}}, 'coefficients': {'D5': {'freq': 1, 'poids': 0.0704}}, '1': {'D5': {'freq': 1, 'poids': 0.0704}}, '5': {'D5': {'freq': 2, 'poids': 0.1408}}, 'variable': {'D5': {'freq': 1, 'poids': 0.0704}}, 'entropy': {'D5': {'freq': 1, 'poids': 0.0704}}, 'coefficient': {'D5': {'freq': 2, 'poids': 0.1408}}, 'greater': {'D5': {'freq': 1, 'poids': 0.0704}}, 'maximum': {'D5': {'freq': 1, 'poids': 0.0704}}, 'occur': {'D5': {'freq': 1, 'poids': 0.0704}}, 'process': {'D5': {'freq': 2, 'poids': 0.1408}}, 'efficient': {'D5': {'freq': 1, 'poids': 0.0704}}, 'single': {'D5': {'freq': 1, 'poids': 0.0704}}, 'areas': {'D5': {'freq': 1, 'poids': 0.0704}}, 'protrude': {'D5': {'freq': 1, 'poids': 0.0704}}, 'main': {'D5': {'freq': 1, 'poids': 0.0704}}, 'revert': {'D5': {'freq': 1, 'poids': 0.0704}}, 'value': {'D5': {'freq': 1, 'poids': 0.0704}}, 'initial': {'D5': {'freq': 1, 'poids': 0.0704}}, 'slopes': {'D5': {'freq': 1, 'poids': 0.0704}}, 'normal-force': {'D5': {'freq': 1, 'poids': 0.0704}}, 'pitching-moment': {'D5': {'freq': 1, 'poids': 0.0704}}, 'curves': {'D5': {'freq': 1, 'poids': 0.0704}}, 'stabilizer': {'D5': {'freq': 1, 'poids': 0.0704}}, 'simplest': {'D5': {'freq': 1, 'poids': 0.0704}}, 'conventional': {'D5': {'freq': 1, 'poids': 0.0704}}, 'ratio': {'D5': {'freq': 2, 'poids': 0.1408}}, 'local': {'D5': {'freq': 1, 'poids': 0.0704}}, 'dynamic': {'D5': {'freq': 2, 'poids': 0.1408}}, 'free-stream': {'D5': {'freq': 1, 'poids': 0.0704}}, 'takes': {'D5': {'freq': 1, 'poids': 0.0704}}, 'values': {'D5': {'freq': 1, 'poids': 0.0704}}, 'low': {'D5': {'freq': 1, 'poids': 0.0502}, 'D6': {'freq': 1, 'poids': 0.1505}}, '0.1': {'D5': {'freq': 1, 'poids': 0.0704}}, 'examples': {'D5': {'freq': 1, 'poids': 0.0704}}, 'measurements': {'D6': {'freq': 2, 'poids': 0.4225}}, 'dimensional': {'D6': {'freq': 1, 'poids': 0.2113}}, 'given': {'D6': {'freq': 1, 'poids': 0.2113}}, 'traverses': {'D6': {'freq': 1, 'poids': 0.2113}}, '10': {'D6': {'freq': 1, 'poids': 0.2113}}, 'per': {'D6': {'freq': 1, 'poids': 0.2113}}, 'cent': {'D6': {'freq': 1, 'poids': 0.2113}}, 'rae': {'D6': {'freq': 1, 'poids': 0.2113}}, '101': {'D6': {'freq': 1, 'poids': 0.2113}}, 'section': {'D6': {'freq': 1, 'poids': 0.2113}}, 'reynolds': {'D6': {'freq': 1, 'poids': 0.2113}}, 'numbers': {'D6': {'freq': 1, 'poids': 0.2113}}, '1.6x10': {'D6': {'freq': 1, 'poids': 0.2113}}, '3.2x10': {'D6': {'freq': 1, 'poids': 0.2113}}, 'drag': {'D6': {'freq': 2, 'poids': 0.4225}}, 'aerodynamic-centre': {'D6': {'freq': 1, 'poids': 0.2113}}, 'characteristics,': {'D6': {'freq': 1, 'poids': 0.2113}}, 'check': {'D6': {'freq': 1, 'poids': 0.2113}}, 'methods': {'D6': {'freq': 1, 'poids': 0.2113}}, 'growth': {'D6': {'freq': 1, 'poids': 0.2113}}, 'turbulent': {'D6': {'freq': 1, 'poids': 0.2113}}, 'known': {'D6': {'freq': 2, 'poids': 0.4225}}, 'concluded': {'D6': {'freq': 1, 'poids': 0.2113}}, 'still': {'D6': {'freq': 1, 'poids': 0.2113}}, 'needs': {'D6': {'freq': 1, 'poids': 0.2113}}, 'little': {'D6': {'freq': 1, 'poids': 0.2113}}, 'refinement': {'D6': {'freq': 1, 'poids': 0.2113}}, 'accurate': {'D6': {'freq': 1, 'poids': 0.2113}}, 'enough': {'D6': {'freq': 1, 'poids': 0.2113}}, 'predict': {'D6': {'freq': 1, 'poids': 0.2113}}, 'distribution,': {'D6': {'freq': 1, 'poids': 0.2113}}, 'aerodynamic': {'D6': {'freq': 1, 'poids': 0.2113}}, 'center,.but': {'D6': {'freq': 1, 'poids': 0.2113}}, 'actual': {'D6': {'freq': 1, 'poids': 0.2113}}}\n",
      "{'experimental': {'D1'}, 'investigation': {'D1'}, 'aerodynamics': {'D1'}, 'wing': {'D1', 'D6'}, 'slipstream': {'D1'}, '.': {'D3', 'D2', 'D4', 'D5', 'D1', 'D6'}, 'study': {'D1', 'D2'}, 'propeller': {'D1'}, 'made': {'D1', 'D3'}, 'order': {'D1'}, 'determine': {'D1'}, 'spanwise': {'D1'}, 'distribution': {'D1', 'D6', 'D3', 'D4'}, 'lift': {'D1'}, 'increase': {'D1'}, 'due': {'D1'}, 'different': {'D1', 'D2'}, 'angles': {'D1'}, 'attack': {'D1'}, 'free': {'D1', 'D2'}, 'stream': {'D1', 'D2'}, 'velocity': {'D1', 'D3'}, 'ratios': {'D1'}, 'results': {'D1', 'D6'}, 'intended': {'D1'}, 'part': {'D1'}, 'evaluation': {'D1'}, 'basis': {'D1', 'D4'}, 'theoretical': {'D1'}, 'treatments': {'D1'}, 'problem': {'D1', 'D2', 'D3', 'D4'}, 'comparative': {'D1'}, 'span': {'D1'}, 'loading': {'D1'}, 'curves,': {'D1'}, 'together': {'D1'}, 'supporting': {'D1'}, 'evidence,': {'D1'}, 'showed': {'D1'}, 'substantial': {'D1'}, 'increment': {'D1'}, 'produced': {'D1'}, '/destalling/': {'D1'}, 'boundary-layer-control': {'D1'}, 'effect': {'D1', 'D6', 'D3'}, 'integrated': {'D1', 'D6'}, 'remaining': {'D1'}, 'increment,': {'D1'}, 'subtracting': {'D1'}, 'destalling': {'D1'}, 'lift,': {'D1', 'D6'}, 'found': {'D1'}, 'agree': {'D1'}, 'well': {'D1'}, 'potential': {'D1'}, 'flow': {'D3', 'D2', 'D4', 'D5', 'D1'}, 'theory': {'D1', 'D5'}, 'empirical': {'D1'}, 'effects': {'D1', 'D2', 'D6'}, 'specific': {'D1'}, 'configuration': {'D1'}, 'experiment': {'D1'}, 'simple': {'D2', 'D5'}, 'shear': {'D2', 'D3'}, 'past': {'D2'}, 'flat': {'D2', 'D3'}, 'plate': {'D2', 'D3'}, 'incompressible': {'D2', 'D3'}, 'fluid': {'D2', 'D3'}, 'small': {'D2'}, 'viscosity': {'D2', 'D6'}, 'high-speed': {'D2'}, 'viscous': {'D2'}, 'two-dimensional': {'D2', 'D6', 'D3'}, 'body': {'D2', 'D4'}, 'usually': {'D2', 'D4'}, 'necessary': {'D2'}, 'consider': {'D2'}, 'curved': {'D2'}, 'shock': {'D2', 'D5'}, 'wave': {'D2', 'D5'}, 'emitting': {'D2'}, 'nose': {'D2'}, 'leading': {'D2'}, 'edge': {'D2'}, 'consequently,': {'D2'}, 'exists': {'D2'}, 'inviscid': {'D2'}, 'rotational': {'D2'}, 'region': {'D2', 'D5'}, 'boundary': {'D2', 'D6', 'D3'}, 'layer': {'D2', 'D6', 'D3', 'D5'}, 'situation': {'D2'}, 'arises,': {'D2'}, 'instance,': {'D2'}, 'hypersonic': {'D2', 'D5'}, 'somewhat': {'D2'}, \"prandtl's\": {'D2'}, 'classical': {'D2'}, 'boundary-layer': {'D2', 'D6', 'D3'}, 'original': {'D2'}, 'outside': {'D2'}, 'irrotational': {'D2'}, 'must': {'D2'}, 'considered': {'D2', 'D3', 'D5'}, 'possible': {'D2', 'D5'}, 'vorticity': {'D2', 'D3'}, 'recently': {'D2'}, 'discussed': {'D2'}, 'ferri': {'D2'}, 'libby': {'D2'}, 'present': {'D2', 'D4'}, 'paper,': {'D2'}, 'investigated': {'D2'}, 'shown': {'D2'}, 'treated': {'D2', 'D4'}, 'approximation,': {'D2'}, 'novel': {'D2'}, 'feature': {'D2'}, 'constant': {'D2'}, 'discussion': {'D2'}, 'restricted': {'D2'}, 'steady': {'D2', 'D3'}, 'approximate': {'D3'}, 'solutions': {'D3', 'D4'}, 'laminar': {'D3'}, 'equations': {'D3', 'D5'}, 'boundary-': {'D3'}, 'thickness,': {'D3'}, 'skin': {'D3'}, 'friction,': {'D3'}, 'obtained': {'D3'}, 'karman-pohlhausen': {'D3'}, 'technique': {'D3'}, 'comparison': {'D3'}, 'uniform': {'D3', 'D5'}, 'also': {'D3'}, 'show': {'D3', 'D4'}, 'exact': {'D4'}, 'solution': {'D4'}, 'neumann': {'D4'}, 'calculation': {'D6', 'D4'}, 'non-': {'D4'}, 'circulatory': {'D4'}, 'plane': {'D4'}, 'axially': {'D4'}, 'symmetric': {'D4'}, 'flows': {'D4'}, 'within': {'D4'}, 'arbitrary': {'D4'}, 'boundaries': {'D4'}, 'general': {'D4'}, 'method': {'D4'}, 'solving': {'D4'}, 'second': {'D4'}, 'boundary-value': {'D4'}, 'developed': {'D5', 'D4'}, 'applied': {'D4'}, 'low-speed': {'D4'}, 'bodies': {'D5', 'D4'}, 'almost': {'D4'}, 'shape,': {'D4'}, 'provided': {'D4'}, 'either': {'D4'}, 'axial': {'D5', 'D4'}, 'symmetry': {'D4'}, 'solid-body,': {'D4'}, 'inlet,': {'D4'}, 'purely': {'D4'}, 'internal': {'D4'}, 'problems': {'D4'}, 'solved': {'D4'}, 'capable': {'D4'}, 'dealing': {'D4'}, 'several': {'D4'}, 'presence': {'D4'}, 'one': {'D4'}, 'another,': {'D4'}, 'consequently': {'D4'}, 'interference': {'D4'}, 'ease': {'D4'}, 'need': {'D4'}, 'solid,': {'D4'}, 'is,': {'D4'}, 'involving': {'D4'}, 'area': {'D4'}, 'suction': {'D4'}, 'calculated': {'D6', 'D5', 'D4'}, 'velocities': {'D4'}, 'computed': {'D4'}, 'points': {'D4'}, 'surface': {'D5', 'D4'}, 'entire': {'D4'}, 'field': {'D4'}, 'source': {'D4'}, 'used': {'D6', 'D4'}, 'leads': {'D4'}, 'fredholm': {'D4'}, 'integral': {'D4'}, 'equation': {'D5', 'D4'}, 'kind,': {'D4'}, 'set': {'D4'}, 'linear': {'D4'}, 'algebraic': {'D4'}, 'equations,': {'D4'}, 'modified': {'D4'}, 'seidel': {'D4'}, 'time': {'D4'}, 'programed': {'D4'}, 'ibm': {'D4'}, '704': {'D4'}, 'edpm': {'D4'}, 'solve': {'D4'}, 'previously': {'D4'}, 'mentioned': {'D4'}, 'characteristics': {'D6', 'D4'}, 'whose': {'D4'}, 'profile': {'D4'}, 'defined': {'D4'}, 'satisfactorily': {'D4'}, '300': {'D4'}, 'coordinate': {'D4'}, 'number': {'D5', 'D4'}, 'presented,': {'D4'}, 'scope': {'D4'}, 'accuracy': {'D4'}, 'computations': {'D4'}, 'require': {'D4'}, 'three': {'D4'}, 'minutes': {'D4'}, 'two': {'D6', 'D4'}, 'hours,': {'D4'}, 'depending': {'D4'}, 'upon': {'D4'}, 'shape': {'D4'}, 'define': {'D4'}, 'secondary': {'D5'}, 'fields': {'D5'}, 'embedded': {'D5'}, 'layers': {'D5'}, 'ramp': {'D5'}, 'compression': {'D5'}, 'located': {'D5'}, 'locally': {'D5'}, 'supersonic': {'D5'}, 'behind': {'D5'}, 'bow': {'D5'}, 'wave,': {'D5'}, 'generates': {'D5'}, 'disturbance': {'D5'}, 'may': {'D5'}, 'viewed': {'D5'}, 'newtonian': {'D5'}, 'impact': {'D5'}, 'thin': {'D5'}, 'examination': {'D5'}, 'applicability': {'D5'}, 'cones': {'D5'}, 'wedges': {'D5'}, 'streams': {'D5'}, 'suggests': {'D5'}, 'expected': {'D5'}, 'give': {'D6', 'D5'}, 'useful': {'D5'}, 'approximation': {'D5'}, 'pressures': {'D5'}, 'pressure': {'D6', 'D5'}, 'based': {'D5'}, 'concept': {'D5'}, 'predicts': {'D5'}, 'interesting': {'D5'}, 'things': {'D5'}, '..': {'D5'}, 'first,': {'D5'}, 'differ': {'D5'}, 'factors': {'D5'}, '1.5': {'D5'}, '3,.': {'D5'}, 'example,': {'D5'}, 'flare': {'D5'}, 'stabilizers': {'D5'}, 'blunt-nosed': {'D5'}, 'revolution,': {'D5'}, 'lower': {'D5'}, 'diminish': {'D5'}, 'increasing': {'D5'}, 'flight': {'D5'}, 'speed': {'D6', 'D5'}, 'range': {'D5'}, 'vary': {'D5'}, 'result': {'D5'}, 'nonuniformity': {'D5'}, 'incident': {'D5'}, 'stream,': {'D5'}, 'depend': {'D5'}, 'location': {'D5'}, 'case': {'D5'}, 'flap': {'D5'}, 'mounted': {'D5'}, 'large-angled': {'D5'}, 'cone,': {'D5'}, 'coefficients': {'D5'}, '1': {'D5'}, '5': {'D5'}, 'variable': {'D5'}, 'entropy': {'D5'}, 'coefficient': {'D5'}, 'greater': {'D5'}, 'maximum': {'D5'}, 'occur': {'D5'}, 'process': {'D5'}, 'efficient': {'D5'}, 'single': {'D5'}, 'areas': {'D5'}, 'protrude': {'D5'}, 'main': {'D5'}, 'revert': {'D5'}, 'value': {'D5'}, 'initial': {'D5'}, 'slopes': {'D5'}, 'normal-force': {'D5'}, 'pitching-moment': {'D5'}, 'curves': {'D5'}, 'stabilizer': {'D5'}, 'simplest': {'D5'}, 'conventional': {'D5'}, 'ratio': {'D5'}, 'local': {'D5'}, 'dynamic': {'D5'}, 'free-stream': {'D5'}, 'takes': {'D5'}, 'values': {'D5'}, 'low': {'D6', 'D5'}, '0.1': {'D5'}, 'examples': {'D5'}, 'measurements': {'D6'}, 'dimensional': {'D6'}, 'given': {'D6'}, 'traverses': {'D6'}, '10': {'D6'}, 'per': {'D6'}, 'cent': {'D6'}, 'rae': {'D6'}, '101': {'D6'}, 'section': {'D6'}, 'reynolds': {'D6'}, 'numbers': {'D6'}, '1.6x10': {'D6'}, '3.2x10': {'D6'}, 'drag': {'D6'}, 'aerodynamic-centre': {'D6'}, 'characteristics,': {'D6'}, 'check': {'D6'}, 'methods': {'D6'}, 'growth': {'D6'}, 'turbulent': {'D6'}, 'known': {'D6'}, 'concluded': {'D6'}, 'still': {'D6'}, 'needs': {'D6'}, 'little': {'D6'}, 'refinement': {'D6'}, 'accurate': {'D6'}, 'enough': {'D6'}, 'predict': {'D6'}, 'distribution,': {'D6'}, 'aerodynamic': {'D6'}, 'center,.but': {'D6'}, 'actual': {'D6'}}\n",
      "les terms de query ['NOT', 'effect', 'AND', 'NOT', 'distribution']\n",
      "{'D3', 'D2', 'D4', 'D5', 'D1', 'D6'}\n",
      "Résultat : {'D3': False, 'D2': True, 'D4': False, 'D5': True, 'D1': False, 'D6': False}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
